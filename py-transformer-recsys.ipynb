{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amondal/recsys/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import math\n",
    "import os\n",
    "import urllib.request\n",
    "from functools import partial\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.set_cmap(\"cividis\")\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30, 60])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(0, 99, (128, 30, 10))\n",
    "b = nn.Embedding(100, 60)\n",
    "c = b(a)\n",
    "d = torch.mean(c, dim=2)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(seq_len, d_model) # (seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # sin(position * (10000 ** (2i / d_model)) # (seq_len, d_model)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # cos(position * (10000 ** (2i / d_model)) # (seq_len, d_model)\n",
    "        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "        self.register_buffer('pe', pe, persistent=False)\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False) # (batch, seq_len, d_model)   \n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q:torch.Tensor, k:torch.Tensor, v:torch.Tensor, ratings:torch.Tensor, mask=None):\n",
    "    d_k = q.size()[-1] # q,k,v : (batch, head, seq_len, embed_size_per_head)\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1)) # (batch, head, seq_len, seq_len)\n",
    "    if ratings is not None:\n",
    "        attn_logits = attn_logits*ratings.unsqueeze(1).unsqueeze(2)\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attn_logits, v) # (batch, head, seq_len, embed_size_per_head)\n",
    "    return values, attention\n",
    "\n",
    "def init_weights(x:nn.Linear):\n",
    "    with torch.no_grad():\n",
    "        nn.init.xavier_uniform_(x.weight)\n",
    "        x.bias.data.fill_(0)\n",
    "\n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self, input_dim:int, d_model: int, h: int) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "\n",
    "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
    "\n",
    "        self.d_k = d_model // h\n",
    "\n",
    "        self.w_q = nn.Linear(input_dim, d_model) # Wq\n",
    "        self.w_k = nn.Linear(input_dim, d_model) # Wk\n",
    "        self.w_v = nn.Linear(input_dim, d_model) # Wv\n",
    "        self.w_o = nn.Linear(d_model, d_model) # Wo\n",
    "\n",
    "        init_weights(self.w_q)\n",
    "        init_weights(self.w_k)\n",
    "        init_weights(self.w_v)\n",
    "        init_weights(self.w_o)\n",
    "\n",
    "    def forward(self, q_x:torch.Tensor, k_x:torch.Tensor, v_x:torch.Tensor, ratings:torch.Tensor, mask=None):\n",
    "        q:torch.Tensor = self.w_q(q_x) # (batch, seq_len, d_model)\n",
    "        k:torch.Tensor = self.w_k(k_x) # (batch, seq_len, d_model)\n",
    "        v:torch.Tensor = self.w_v(v_x) # (batch, seq_len, d_model)\n",
    "\n",
    "        q_h = q.reshape(q.shape[0], q.shape[1], self.h, self.d_k).transpose(1, 2) # (batch, head, seq_len, d_k)\n",
    "        k_h = k.reshape(k.shape[0], k.shape[1], self.h, self.d_k).transpose(1, 2) # (batch, head, seq_len, d_k)\n",
    "        v_h = v.reshape(v.shape[0], v.shape[1], self.h, self.d_k).transpose(1, 2) # (batch, head, seq_len, d_k)\n",
    "\n",
    "        attn_out, _ = attention(q_h, k_h, v_h, ratings, mask) # (batch, head, seq_len, embed_size_per_head)\n",
    "        attn_out = attn_out.transpose(1, 2) # (batch, seq_len, head, embed_size_per_head)\n",
    "        attn_out = attn_out.reshape(attn_out.shape[0], attn_out.shape[1], attn_out.shape[2]*attn_out.shape[3]) # (batch, seq_len, d_model)\n",
    "\n",
    "        return self.w_o(attn_out) # (batch, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadAttentionBlock(input_dim, input_dim, num_heads)\n",
    "\n",
    "        self.ffn_1 = nn.Linear(input_dim, dim_feedforward)\n",
    "        self.ffn_2 = nn.Linear(dim_feedforward, input_dim)\n",
    "\n",
    "        init_weights(self.ffn_1)\n",
    "        init_weights(self.ffn_2)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            self.ffn_1,\n",
    "            nn.Dropout(dropout),\n",
    "            nn.GELU(),\n",
    "            self.ffn_2,\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, ratings, mask=None):\n",
    "        attn_out = self.self_attn(x, x, x, ratings, mask=mask) # (batch, seq_len, input_dim)\n",
    "        x = x + self.dropout(attn_out) # (batch, seq_len, input_dim)\n",
    "        x = self.norm1(x) # (batch, seq_len, input_dim)\n",
    "\n",
    "        ffn_out = self.ffn(x) # (batch, seq_len, input_dim)\n",
    "        x = x + self.dropout(ffn_out) # (batch, seq_len, input_dim)\n",
    "        x = self.norm2(x) # (batch, seq_len, input_dim)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dim_feedforward, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderBlock(d_model, num_heads, dim_feedforward, dropout) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, ratings, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, ratings, mask=mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0)->None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadAttentionBlock(input_dim, input_dim, num_heads)\n",
    "        self.crss_attn = MultiHeadAttentionBlock(input_dim, input_dim, num_heads)\n",
    "\n",
    "        self.ffn_1 = nn.Linear(input_dim, dim_feedforward)\n",
    "        self.ffn_2 = nn.Linear(dim_feedforward, input_dim)\n",
    "\n",
    "        init_weights(self.ffn_1)\n",
    "        init_weights(self.ffn_2)\n",
    "        \n",
    "        self.ffn = nn.Sequential(\n",
    "            self.ffn_1,\n",
    "            nn.Dropout(dropout),\n",
    "            nn.GELU(),\n",
    "            self.ffn_2,\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.norm3 = nn.LayerNorm(input_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_ratings, encoder_output, pred_mask, pad_mask):\n",
    "        self_attn_out = self.self_attn(x, x, x, None, mask=pred_mask) # (batch, seq_len, input_dim)\n",
    "        x = x + self.dropout(self_attn_out) # (batch, seq_len, input_dim)\n",
    "        x = self.norm1(x) # (batch, seq_len, input_dim)\n",
    "\n",
    "        crss_attn_out = self.crss_attn(x, encoder_output, encoder_output, enc_ratings, mask=pad_mask) # (batch, seq_len, input_dim)\n",
    "        x = x + self.dropout(crss_attn_out) # (batch, seq_len, input_dim)\n",
    "        x = self.norm2(x) # (batch, seq_len, input_dim)\n",
    "\n",
    "        ffn_out = self.ffn(x) # (batch, seq_len, input_dim)\n",
    "        x = x + self.dropout(ffn_out) # (batch, seq_len, input_dim)\n",
    "        x = self.norm3(x) # (batch, seq_len, input_dim)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([DecoderBlock(d_model, num_heads, dim_feedforward, dropout) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, enc_ratings, encoder_output, pred_mask=None, pad_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_ratings, encoder_output, pred_mask, pad_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, user_vocab_size, interval_vocab_size, genres_vocab_size, years_vocab_size, src_movie_vocab_size, tgt_movie_vocab_size, src_seq_len, tgt_seq_len, d_model, num_heads, dim_feedforward, num_encoder_layers, num_decoder_layers, dropout=0.0) -> None:\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.user_embedding = nn.Embedding(user_vocab_size, d_model)\n",
    "        self.interval_embedding = nn.Embedding(interval_vocab_size, d_model)\n",
    "        self.years_embedding = nn.Embedding(years_vocab_size, d_model)\n",
    "        self.encoder_embedding = nn.Embedding(src_movie_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_movie_vocab_size, d_model)\n",
    "\n",
    "        self.src_positional_encoding = PositionalEncoding(d_model, src_seq_len, dropout)\n",
    "        self.tgt_positional_encoding = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
    "\n",
    "        self.encoder_block = Encoder(num_encoder_layers, d_model, num_heads, dim_feedforward, dropout)\n",
    "        self.decoder_block = Decoder(num_decoder_layers, d_model, num_heads, dim_feedforward, dropout)\n",
    "\n",
    "        self.genres_encoder = nn.Linear(genres_vocab_size, d_model)\n",
    "        init_weights(self.genres_encoder)\n",
    "\n",
    "        self.fc_encoder = nn.Linear(5*d_model, d_model)\n",
    "        init_weights(self.fc_encoder)\n",
    "\n",
    "        self.fc_decoder = nn.Linear(5*d_model, d_model)\n",
    "        init_weights(self.fc_decoder)\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_movie_vocab_size)\n",
    "        init_weights(self.fc)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)       \n",
    "\n",
    "\n",
    "    def generate_mask(self, src:torch.Tensor, tgt:torch.Tensor):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2) # (batch, 1, 1, seq_len)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3) # (batch, 1, seq_len, 1)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device=device) # (1, seq_len, seq_len)\n",
    "        tgt_mask = tgt_mask & nopeak_mask # (batch, 1, seq_len, seq_len)\n",
    "        return src_mask, tgt_mask\n",
    "    \n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            user_ids:torch.Tensor, \n",
    "            interval:torch.Tensor, \n",
    "            genres:torch.Tensor, \n",
    "            years:torch.Tensor,\n",
    "            ratings:torch.Tensor, \n",
    "            src_movie_ids:torch.Tensor, \n",
    "            tgt_movie_ids:torch.Tensor):\n",
    "        \n",
    "        src_mask, tgt_mask = self.generate_mask(src_movie_ids, tgt_movie_ids)\n",
    "\n",
    "        src_movie_embedding = self.encoder_embedding(src_movie_ids) # (batch, seq_len, d_model)\n",
    "        tgt_movie_embedding = self.decoder_embedding(tgt_movie_ids) # (batch, seq_len, d_model)\n",
    "\n",
    "        interval_embedding = self.interval_embedding(interval) # (batch, seq_len, d_model)\n",
    "        years_embedding = self.years_embedding(years) # (batch, seq_len, d_model)\n",
    "        genres_embedding = self.genres_encoder(genres) # (batch, seq_len, d_model)\n",
    "        user_embed = self.user_embedding(user_ids) # (batch, seq_len, d_model)\n",
    "\n",
    "        src_movie_embedding = torch.concat([src_movie_embedding, user_embed, interval_embedding, years_embedding, genres_embedding], dim=2) # (batch, seq_len, 5*d_model)\n",
    "        src_movie_embedding = self.fc_encoder(src_movie_embedding) # (batch, seq_len, d_model)\n",
    "\n",
    "        src_movie_embedding = self.src_positional_encoding(src_movie_embedding) # (batch, seq_len, d_model)\n",
    "        tgt_movie_embedding = self.tgt_positional_encoding(tgt_movie_embedding) # (batch, seq_len, d_model)\n",
    "\n",
    "        src_movie_embedding = self.dropout(src_movie_embedding) # (batch, seq_len, d_model)\n",
    "        tgt_movie_embedding = self.dropout(tgt_movie_embedding) # (batch, seq_len, d_model)\n",
    "\n",
    "        enc_output = self.encoder_block(src_movie_embedding, ratings, src_mask) # (batch, seq_len, d_model)\n",
    "        dec_output = self.decoder_block(tgt_movie_embedding, ratings, enc_output, tgt_mask, src_mask) # (batch, seq_len,d_model)\n",
    "\n",
    "        return self.fc(dec_output) # (batch, seq_len, tgt_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup, max_iters):\n",
    "        self.warmup = warmup\n",
    "        self.max_num_iters = max_iters\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
    "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
    "\n",
    "    def get_lr_factor(self, epoch):\n",
    "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))\n",
    "        if epoch <= self.warmup:\n",
    "            lr_factor *= epoch * 1.0 / self.warmup\n",
    "        return lr_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings_path = '/Users/amondal/recsys/datasets/ml-32m/ratings.csv'\n",
    "genres_path = '/Users/amondal/recsys/datasets/ml-32m/movies.csv'\n",
    "\n",
    "rating_column_names = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "genres_column_names = ['movieId', 'title', 'genres']\n",
    "\n",
    "df_rating = pd.read_csv(ratings_path, sep=',', names=rating_column_names, dtype={'userId':'int32', 'movieId':'int32', 'rating':float, 'timestamp':'int64'}, header=0)\n",
    "df_genres = pd.read_csv(genres_path, sep=',', names=genres_column_names, dtype={'movieId':'int32', 'title':'object', 'genres':'object'}, header=0)\n",
    "\n",
    "df_rating.dropna(inplace=True, subset=['userId', 'movieId', 'rating'])\n",
    "df_genres.dropna(inplace=True, subset=['movieId', 'title', 'genres'])\n",
    "\n",
    "df_genres['genres'] = df_genres['genres'].apply(lambda x: x.split('|'))\n",
    "df_genres['movie_year'] = df_genres['title'].str.extract(r'\\((\\d{4})\\)').fillna(\"1\").astype('int')\n",
    "df_genres.drop(columns=['title'], inplace=True)\n",
    "\n",
    "df = df_rating.merge(df_genres, on=['movieId'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "      <td>[Adventure, Drama, Fantasy, Mystery, Sci-Fi]</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "      <td>[Crime, Drama]</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "      <td>[Mystery, Sci-Fi, Thriller]</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000199</th>\n",
       "      <td>200948</td>\n",
       "      <td>79702</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1294412589</td>\n",
       "      <td>[Action, Comedy, Fantasy, Musical, Romance]</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000200</th>\n",
       "      <td>200948</td>\n",
       "      <td>79796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1287216292</td>\n",
       "      <td>[Action, Adventure, Drama, Thriller, War]</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000201</th>\n",
       "      <td>200948</td>\n",
       "      <td>80350</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1294412671</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000202</th>\n",
       "      <td>200948</td>\n",
       "      <td>80463</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1350423800</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000203</th>\n",
       "      <td>200948</td>\n",
       "      <td>87304</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1350423523</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000204 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating   timestamp  \\\n",
       "0              1       17     4.0   944249077   \n",
       "1              1       25     1.0   944250228   \n",
       "2              1       29     2.0   943230976   \n",
       "3              1       30     5.0   944249077   \n",
       "4              1       32     5.0   943228858   \n",
       "...          ...      ...     ...         ...   \n",
       "32000199  200948    79702     4.5  1294412589   \n",
       "32000200  200948    79796     1.0  1287216292   \n",
       "32000201  200948    80350     0.5  1294412671   \n",
       "32000202  200948    80463     3.5  1350423800   \n",
       "32000203  200948    87304     4.5  1350423523   \n",
       "\n",
       "                                                genres  movie_year  \n",
       "0                                     [Drama, Romance]        1995  \n",
       "1                                     [Drama, Romance]        1995  \n",
       "2         [Adventure, Drama, Fantasy, Mystery, Sci-Fi]        1995  \n",
       "3                                       [Crime, Drama]        1995  \n",
       "4                          [Mystery, Sci-Fi, Thriller]        1995  \n",
       "...                                                ...         ...  \n",
       "32000199   [Action, Comedy, Fantasy, Musical, Romance]        2010  \n",
       "32000200     [Action, Adventure, Drama, Thriller, War]        2010  \n",
       "32000201                                      [Comedy]        2010  \n",
       "32000202                                       [Drama]        2010  \n",
       "32000203                                       [Drama]        2010  \n",
       "\n",
       "[32000204 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = df['genres'].tolist()\n",
    "\n",
    "genres_set = set()\n",
    "for x in all_genres:\n",
    "    genres_set.update(set(x))\n",
    "\n",
    "genres_set = list(genres_set)\n",
    "inv_idx = {genres_set[i]:i for i in range(len(genres_set))}\n",
    "\n",
    "genres_mh = []\n",
    "for x in all_genres:\n",
    "    h = [0]*len(genres_set)\n",
    "    for y in x:\n",
    "        h[inv_idx[y]] = 1\n",
    "    genres_mh += [h]\n",
    "\n",
    "df['genres_mh'] = genres_mh\n",
    "df.drop(columns=['genres'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>genres_mh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "      <td>1995</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "      <td>1995</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "      <td>1995</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "      <td>1995</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "      <td>1995</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000199</th>\n",
       "      <td>200948</td>\n",
       "      <td>79702</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1294412589</td>\n",
       "      <td>2010</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000200</th>\n",
       "      <td>200948</td>\n",
       "      <td>79796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1287216292</td>\n",
       "      <td>2010</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000201</th>\n",
       "      <td>200948</td>\n",
       "      <td>80350</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1294412671</td>\n",
       "      <td>2010</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000202</th>\n",
       "      <td>200948</td>\n",
       "      <td>80463</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1350423800</td>\n",
       "      <td>2010</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000203</th>\n",
       "      <td>200948</td>\n",
       "      <td>87304</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1350423523</td>\n",
       "      <td>2010</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000204 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating   timestamp  movie_year  \\\n",
       "0              1       17     4.0   944249077        1995   \n",
       "1              1       25     1.0   944250228        1995   \n",
       "2              1       29     2.0   943230976        1995   \n",
       "3              1       30     5.0   944249077        1995   \n",
       "4              1       32     5.0   943228858        1995   \n",
       "...          ...      ...     ...         ...         ...   \n",
       "32000199  200948    79702     4.5  1294412589        2010   \n",
       "32000200  200948    79796     1.0  1287216292        2010   \n",
       "32000201  200948    80350     0.5  1294412671        2010   \n",
       "32000202  200948    80463     3.5  1350423800        2010   \n",
       "32000203  200948    87304     4.5  1350423523        2010   \n",
       "\n",
       "                                                  genres_mh  \n",
       "0         [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1         [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2         [0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, ...  \n",
       "3         [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "4         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
       "...                                                     ...  \n",
       "32000199  [0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
       "32000200  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, ...  \n",
       "32000201  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "32000202  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "32000203  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[32000204 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# path = '/Users/amondal/recsys/datasets/ml-1m/ratings.dat'\n",
    "# user_ids, movie_ids, ratings, timestamps = [], [], [], []\n",
    "# with open(path) as f:\n",
    "#     data = f.readlines()\n",
    "#     data = [x.rstrip().split('::') for x in data]\n",
    "#     for x in data:\n",
    "#         user_ids += [int(x[0])]\n",
    "#         movie_ids += [int(x[1])]\n",
    "#         ratings += [float(x[2])]\n",
    "#         timestamps += [int(x[3])]\n",
    "\n",
    "# df = pd.DataFrame(data={'userId':user_ids, 'movieId':movie_ids, 'rating':ratings, 'timestamp':timestamps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='timestamp')\n",
    "df2 = df[[\"userId\", \"movieId\"]].groupby(by=[\"userId\"]).agg(list).reset_index()\n",
    "df2 = df2[df2.movieId.apply(len) > 20]\n",
    "df = df.merge(df2, on=[\"userId\"], how=\"inner\", suffixes=(\"\", \"_right\"))\n",
    "df['timestamp'] = df['timestamp']/86400\n",
    "df['timestamp'] = df['timestamp'].astype(int)\n",
    "df.drop(columns=['movieId_right'], inplace=True)\n",
    "\n",
    "n = df.shape[0]\n",
    "m = int(0.8*n)\n",
    "\n",
    "df_train = df[:m]\n",
    "df_test = df[m:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>genres_mh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85028</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9524</td>\n",
       "      <td>1995</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85028</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9533</td>\n",
       "      <td>1995</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85028</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9547</td>\n",
       "      <td>1995</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85028</td>\n",
       "      <td>111</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9548</td>\n",
       "      <td>1976</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35011</td>\n",
       "      <td>446</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9556</td>\n",
       "      <td>1993</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567279</th>\n",
       "      <td>150312</td>\n",
       "      <td>3114</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17814</td>\n",
       "      <td>1999</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567280</th>\n",
       "      <td>150312</td>\n",
       "      <td>74580</td>\n",
       "      <td>3.5</td>\n",
       "      <td>17814</td>\n",
       "      <td>2010</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567281</th>\n",
       "      <td>150312</td>\n",
       "      <td>8372</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17814</td>\n",
       "      <td>2004</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567282</th>\n",
       "      <td>150312</td>\n",
       "      <td>4340</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17814</td>\n",
       "      <td>2001</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567283</th>\n",
       "      <td>150312</td>\n",
       "      <td>88356</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17814</td>\n",
       "      <td>2011</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2557684 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  rating  timestamp  movie_year  \\\n",
       "0         85028       32     5.0       9524        1995   \n",
       "1         85028       39     5.0       9533        1995   \n",
       "2         85028       25     5.0       9547        1995   \n",
       "3         85028      111     5.0       9548        1976   \n",
       "4         35011      446     4.0       9556        1993   \n",
       "...         ...      ...     ...        ...         ...   \n",
       "2567279  150312     3114     3.0      17814        1999   \n",
       "2567280  150312    74580     3.5      17814        2010   \n",
       "2567281  150312     8372     0.5      17814        2004   \n",
       "2567282  150312     4340     2.0      17814        2001   \n",
       "2567283  150312    88356     0.5      17814        2011   \n",
       "\n",
       "                                                 genres_mh  \n",
       "0        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "3        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...  \n",
       "4        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "...                                                    ...  \n",
       "2567279  [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...  \n",
       "2567280  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2567281  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "2567282  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2567283  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2557684 rows x 6 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4. , 3. , 5. , 1. , 2. , 4.5, 3.5, 2.5, 1.5, 0.5])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "src_seq_len = 20\n",
    "tgt_seq_len = 5\n",
    "max_len = src_seq_len + tgt_seq_len\n",
    "\n",
    "def get_movies_data(df:pd.DataFrame):\n",
    "    df2 = df.groupby(by=[\"userId\"]).agg(list).reset_index()\n",
    "\n",
    "    user_ids = []\n",
    "    intervals = []\n",
    "    genres = []\n",
    "    ratings = []\n",
    "    years = []\n",
    "    movie_ids_src, movie_ids_tgt = [], []\n",
    "    interval_vocab_size = 0\n",
    "\n",
    "    for i in range(df2.shape[0]):\n",
    "        movie_ids_seq = df2.loc[i, 'movieId']\n",
    "        user_id = df2.loc[i, 'userId']\n",
    "        ts_seq = df2.loc[i, 'timestamp']\n",
    "        genres_seq = df2.loc[i, 'genres_mh']\n",
    "        ratings_seq = df2.loc[i, 'rating']\n",
    "        years_seq = df2.loc[i, 'movie_year']\n",
    "\n",
    "        for j in range(len(movie_ids_seq)-src_seq_len-1):\n",
    "            m_src = movie_ids_seq[j:j+src_seq_len]\n",
    "            m_tgt = movie_ids_seq[j+src_seq_len:min(len(movie_ids_seq), j+max_len)]\n",
    "            m_tgt += [0]*(tgt_seq_len-len(m_tgt))\n",
    "\n",
    "            user_ids += [[user_id]*src_seq_len]\n",
    "            genres += [genres_seq[j:j+src_seq_len]]\n",
    "            ratings += [ratings_seq[j:j+src_seq_len]]\n",
    "            years += [years_seq[j:j+src_seq_len]]\n",
    "\n",
    "            u = ts_seq[j:j+src_seq_len]\n",
    "            v = u[:]\n",
    "            k = len(u)-1\n",
    "            while k >= 0:\n",
    "                if k == len(u)-1:\n",
    "                    u[k] = 1\n",
    "                else:\n",
    "                    u[k] = v[-1]-v[k]+1\n",
    "                k -= 1\n",
    "            \n",
    "            interval_vocab_size = max(interval_vocab_size, max(u)+1)\n",
    "\n",
    "            movie_ids_src += [m_src]\n",
    "            movie_ids_tgt += [m_tgt]\n",
    "            intervals += [u]\n",
    "        \n",
    "    movie_ids_src = torch.tensor(movie_ids_src, dtype=torch.int32)\n",
    "    movie_ids_tgt = torch.tensor(movie_ids_tgt, dtype=torch.int32)\n",
    "    user_ids = torch.tensor(user_ids, dtype=torch.int32)\n",
    "    intervals = torch.tensor(intervals, dtype=torch.int64)\n",
    "    ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "    genres = torch.tensor(genres, dtype=torch.int8)\n",
    "    years = torch.tensor(years, dtype=torch.int32)\n",
    "\n",
    "    return user_ids, intervals, ratings, genres, years, movie_ids_src, movie_ids_tgt, interval_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_vocab_size = int(df_train[\"userId\"].max()+1)\n",
    "movie_id_vocab_size = int(df_train[\"movieId\"].max()+1)\n",
    "genres_vocab_size = len(genres_set)\n",
    "years_vocab_size = int(df_train[\"movie_year\"].max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "user_ids_train, intervals_train, ratings_train, genres_train, years_train, movie_ids_src_train, movie_ids_tgt_train, interval_vocab_size_train = get_movies_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_test, intervals_test, ratings_test, genres_test, years_test, movie_ids_src_test, movie_ids_tgt_test, interval_vocab_size_test = get_movies_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_vocab_size = interval_vocab_size_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4704"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 256\n",
    "num_heads = 8\n",
    "num_layers = 1\n",
    "d_ff = 32\n",
    "src_seq_length = 20\n",
    "tgt_seq_length = 5\n",
    "dropout = 0.0\n",
    "\n",
    "transformer = Transformer(user_id_vocab_size, interval_vocab_size, genres_vocab_size, years_vocab_size, movie_id_vocab_size, movie_id_vocab_size, src_seq_length, tgt_seq_length, d_model, num_heads, d_ff, num_layers, num_layers, dropout).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 1, Loss: 12.185012817382812\n",
      "Epoch: 1, Batch: 2, Loss: 12.18105411529541\n",
      "Epoch: 1, Batch: 3, Loss: 12.181358337402344\n",
      "Epoch: 1, Batch: 4, Loss: 12.179984092712402\n",
      "Epoch: 1, Batch: 5, Loss: 12.173215866088867\n",
      "Epoch: 1, Batch: 6, Loss: 12.1746244430542\n",
      "Epoch: 1, Batch: 7, Loss: 12.17248821258545\n",
      "Epoch: 1, Batch: 8, Loss: 12.163264274597168\n",
      "Epoch: 1, Batch: 9, Loss: 12.160335540771484\n",
      "Epoch: 1, Batch: 10, Loss: 12.142532348632812\n",
      "Epoch: 1, Batch: 11, Loss: 12.130736351013184\n",
      "Epoch: 1, Batch: 12, Loss: 12.096434593200684\n",
      "Epoch: 1, Batch: 13, Loss: 12.074976921081543\n",
      "Epoch: 1, Batch: 14, Loss: 12.013662338256836\n",
      "Epoch: 1, Batch: 15, Loss: 11.977794647216797\n",
      "Epoch: 1, Batch: 16, Loss: 11.897197723388672\n",
      "Epoch: 1, Batch: 17, Loss: 11.833232879638672\n",
      "Epoch: 1, Batch: 18, Loss: 11.759215354919434\n",
      "Epoch: 1, Batch: 19, Loss: 11.63644790649414\n",
      "Epoch: 1, Batch: 20, Loss: 11.540830612182617\n",
      "Epoch: 1, Batch: 21, Loss: 11.456860542297363\n",
      "Epoch: 1, Batch: 22, Loss: 11.394157409667969\n",
      "Epoch: 1, Batch: 23, Loss: 11.27469539642334\n",
      "Epoch: 1, Batch: 24, Loss: 11.101299285888672\n",
      "Epoch: 1, Batch: 25, Loss: 10.930638313293457\n",
      "Epoch: 1, Batch: 26, Loss: 10.727333068847656\n",
      "Epoch: 1, Batch: 27, Loss: 10.680413246154785\n",
      "Epoch: 1, Batch: 28, Loss: 10.58697509765625\n",
      "Epoch: 1, Batch: 29, Loss: 10.379329681396484\n",
      "Epoch: 1, Batch: 30, Loss: 10.155460357666016\n",
      "Epoch: 1, Batch: 31, Loss: 10.158939361572266\n",
      "Epoch: 1, Batch: 32, Loss: 9.879189491271973\n",
      "Epoch: 1, Batch: 33, Loss: 9.771015167236328\n",
      "Epoch: 1, Batch: 34, Loss: 9.5949068069458\n",
      "Epoch: 1, Batch: 35, Loss: 9.525972366333008\n",
      "Epoch: 1, Batch: 36, Loss: 9.242907524108887\n",
      "Epoch: 1, Batch: 37, Loss: 9.158605575561523\n",
      "Epoch: 1, Batch: 38, Loss: 9.320594787597656\n",
      "Epoch: 1, Batch: 39, Loss: 8.990951538085938\n",
      "Epoch: 1, Batch: 40, Loss: 9.046886444091797\n",
      "Epoch: 1, Batch: 41, Loss: 8.874929428100586\n",
      "Epoch: 1, Batch: 42, Loss: 8.679841995239258\n",
      "Epoch: 1, Batch: 43, Loss: 8.79059886932373\n",
      "Epoch: 1, Batch: 44, Loss: 8.720743179321289\n",
      "Epoch: 1, Batch: 45, Loss: 8.837689399719238\n",
      "Epoch: 1, Batch: 46, Loss: 8.897075653076172\n",
      "Epoch: 1, Batch: 47, Loss: 8.756621360778809\n",
      "Epoch: 1, Batch: 48, Loss: 8.797557830810547\n",
      "Epoch: 1, Batch: 49, Loss: 8.624049186706543\n",
      "Epoch: 1, Batch: 50, Loss: 8.934175491333008\n",
      "Epoch: 1, Batch: 51, Loss: 9.08411979675293\n",
      "Epoch: 1, Batch: 52, Loss: 8.601649284362793\n",
      "Epoch: 1, Batch: 53, Loss: 8.896587371826172\n",
      "Epoch: 1, Batch: 54, Loss: 8.403275489807129\n",
      "Epoch: 1, Batch: 55, Loss: 8.622459411621094\n",
      "Epoch: 1, Batch: 56, Loss: 8.581710815429688\n",
      "Epoch: 1, Batch: 57, Loss: 8.683531761169434\n",
      "Epoch: 1, Batch: 58, Loss: 8.862277030944824\n",
      "Epoch: 1, Batch: 59, Loss: 8.885982513427734\n",
      "Epoch: 1, Batch: 60, Loss: 8.741737365722656\n",
      "Epoch: 1, Batch: 61, Loss: 8.628375053405762\n",
      "Epoch: 1, Batch: 62, Loss: 8.46964168548584\n",
      "Epoch: 1, Batch: 63, Loss: 8.790181159973145\n",
      "Epoch: 1, Batch: 64, Loss: 8.55698013305664\n",
      "Epoch: 1, Batch: 65, Loss: 8.813014030456543\n",
      "Epoch: 1, Batch: 66, Loss: 8.70867919921875\n",
      "Epoch: 1, Batch: 67, Loss: 8.711230278015137\n",
      "Epoch: 1, Batch: 68, Loss: 8.576637268066406\n",
      "Epoch: 1, Batch: 69, Loss: 8.444658279418945\n",
      "Epoch: 1, Batch: 70, Loss: 8.733656883239746\n",
      "Epoch: 1, Batch: 71, Loss: 8.628646850585938\n",
      "Epoch: 1, Batch: 72, Loss: 8.473094940185547\n",
      "Epoch: 1, Batch: 73, Loss: 8.546616554260254\n",
      "Epoch: 1, Batch: 74, Loss: 8.568009376525879\n",
      "Epoch: 1, Batch: 75, Loss: 8.894058227539062\n",
      "Epoch: 1, Batch: 76, Loss: 8.782297134399414\n",
      "Epoch: 1, Batch: 77, Loss: 8.638553619384766\n",
      "Epoch: 1, Batch: 78, Loss: 8.46695327758789\n",
      "Epoch: 1, Batch: 79, Loss: 8.606245994567871\n",
      "Epoch: 1, Batch: 80, Loss: 8.650742530822754\n",
      "Epoch: 1, Batch: 81, Loss: 8.718852043151855\n",
      "Epoch: 1, Batch: 82, Loss: 8.562692642211914\n",
      "Epoch: 1, Batch: 83, Loss: 8.576678276062012\n",
      "Epoch: 1, Batch: 84, Loss: 8.576278686523438\n",
      "Epoch: 1, Batch: 85, Loss: 8.849366188049316\n",
      "Epoch: 1, Batch: 86, Loss: 8.775777816772461\n",
      "Epoch: 1, Batch: 87, Loss: 8.73730182647705\n",
      "Epoch: 1, Batch: 88, Loss: 8.519960403442383\n",
      "Epoch: 1, Batch: 89, Loss: 8.77862548828125\n",
      "Epoch: 1, Batch: 90, Loss: 8.354193687438965\n",
      "Epoch: 1, Batch: 91, Loss: 8.719472885131836\n",
      "Epoch: 1, Batch: 92, Loss: 8.54893684387207\n",
      "Epoch: 1, Batch: 93, Loss: 8.763679504394531\n",
      "Epoch: 1, Batch: 94, Loss: 8.627827644348145\n",
      "Epoch: 1, Batch: 95, Loss: 8.584440231323242\n",
      "Epoch: 1, Batch: 96, Loss: 8.691585540771484\n",
      "Epoch: 1, Batch: 97, Loss: 8.43725872039795\n",
      "Epoch: 1, Batch: 98, Loss: 8.471484184265137\n",
      "Epoch: 1, Batch: 99, Loss: 8.881227493286133\n",
      "Epoch: 1, Batch: 100, Loss: 8.79443359375\n",
      "Epoch: 1, Batch: 101, Loss: 8.55603313446045\n",
      "Epoch: 1, Batch: 102, Loss: 8.486634254455566\n",
      "Epoch: 1, Batch: 103, Loss: 8.637406349182129\n",
      "Epoch: 1, Batch: 104, Loss: 8.716639518737793\n",
      "Epoch: 1, Batch: 105, Loss: 8.58683967590332\n",
      "Epoch: 1, Batch: 106, Loss: 8.690315246582031\n",
      "Epoch: 1, Batch: 107, Loss: 8.886003494262695\n",
      "Epoch: 1, Batch: 108, Loss: 8.697403907775879\n",
      "Epoch: 1, Batch: 109, Loss: 8.661276817321777\n",
      "Epoch: 1, Batch: 110, Loss: 8.343314170837402\n",
      "Epoch: 1, Batch: 111, Loss: 8.493417739868164\n",
      "Epoch: 1, Batch: 112, Loss: 8.73929214477539\n",
      "Epoch: 1, Batch: 113, Loss: 8.522093772888184\n",
      "Epoch: 1, Batch: 114, Loss: 8.61225414276123\n",
      "Epoch: 1, Batch: 115, Loss: 8.665349960327148\n",
      "Epoch: 1, Batch: 116, Loss: 8.51573657989502\n",
      "Epoch: 1, Batch: 117, Loss: 8.602180480957031\n",
      "Epoch: 1, Batch: 118, Loss: 8.510180473327637\n",
      "Epoch: 1, Batch: 119, Loss: 8.448702812194824\n",
      "Epoch: 1, Batch: 120, Loss: 8.25490951538086\n",
      "Epoch: 1, Batch: 121, Loss: 8.471625328063965\n",
      "Epoch: 1, Batch: 122, Loss: 8.653542518615723\n",
      "Epoch: 1, Batch: 123, Loss: 8.55197525024414\n",
      "Epoch: 1, Batch: 124, Loss: 8.677982330322266\n",
      "Epoch: 1, Batch: 125, Loss: 8.63757610321045\n",
      "Epoch: 1, Batch: 126, Loss: 8.49797534942627\n",
      "Epoch: 1, Batch: 127, Loss: 8.44701862335205\n",
      "Epoch: 1, Batch: 128, Loss: 8.772019386291504\n",
      "Epoch: 1, Batch: 129, Loss: 8.603875160217285\n",
      "Epoch: 1, Batch: 130, Loss: 8.1974458694458\n",
      "Epoch: 1, Batch: 131, Loss: 8.440147399902344\n",
      "Epoch: 1, Batch: 132, Loss: 8.630949020385742\n",
      "Epoch: 1, Batch: 133, Loss: 8.51219654083252\n",
      "Epoch: 1, Batch: 134, Loss: 8.368216514587402\n",
      "Epoch: 1, Batch: 135, Loss: 8.32230281829834\n",
      "Epoch: 1, Batch: 136, Loss: 8.413419723510742\n",
      "Epoch: 1, Batch: 137, Loss: 8.358168601989746\n",
      "Epoch: 1, Batch: 138, Loss: 8.481148719787598\n",
      "Epoch: 1, Batch: 139, Loss: 8.480574607849121\n",
      "Epoch: 1, Batch: 140, Loss: 8.526538848876953\n",
      "Epoch: 1, Batch: 141, Loss: 8.268427848815918\n",
      "Epoch: 1, Batch: 142, Loss: 8.208024978637695\n",
      "Epoch: 1, Batch: 143, Loss: 8.460744857788086\n",
      "Epoch: 1, Batch: 144, Loss: 8.558754920959473\n",
      "Epoch: 1, Batch: 145, Loss: 8.561039924621582\n",
      "Epoch: 1, Batch: 146, Loss: 8.549396514892578\n",
      "Epoch: 1, Batch: 147, Loss: 8.244470596313477\n",
      "Epoch: 1, Batch: 148, Loss: 8.35031509399414\n",
      "Epoch: 1, Batch: 149, Loss: 8.532539367675781\n",
      "Epoch: 1, Batch: 150, Loss: 8.36021900177002\n",
      "Epoch: 1, Batch: 151, Loss: 8.426277160644531\n",
      "Epoch: 1, Batch: 152, Loss: 8.543546676635742\n",
      "Epoch: 1, Batch: 153, Loss: 8.516642570495605\n",
      "Epoch: 1, Batch: 154, Loss: 8.560675621032715\n",
      "Epoch: 1, Batch: 155, Loss: 8.263819694519043\n",
      "Epoch: 1, Batch: 156, Loss: 8.40842056274414\n",
      "Epoch: 1, Batch: 157, Loss: 8.212080001831055\n",
      "Epoch: 1, Batch: 158, Loss: 8.268386840820312\n",
      "Epoch: 1, Batch: 159, Loss: 8.549951553344727\n",
      "Epoch: 1, Batch: 160, Loss: 8.285547256469727\n",
      "Epoch: 1, Batch: 161, Loss: 8.17326831817627\n",
      "Epoch: 1, Batch: 162, Loss: 8.677633285522461\n",
      "Epoch: 1, Batch: 163, Loss: 8.483135223388672\n",
      "Epoch: 1, Batch: 164, Loss: 8.326645851135254\n",
      "Epoch: 1, Batch: 165, Loss: 8.339166641235352\n",
      "Epoch: 1, Batch: 166, Loss: 8.427535057067871\n",
      "Epoch: 1, Batch: 167, Loss: 8.171216011047363\n",
      "Epoch: 1, Batch: 168, Loss: 8.282941818237305\n",
      "Epoch: 1, Batch: 169, Loss: 8.259710311889648\n",
      "Epoch: 1, Batch: 170, Loss: 8.704782485961914\n",
      "Epoch: 1, Batch: 171, Loss: 8.221187591552734\n",
      "Epoch: 1, Batch: 172, Loss: 8.193920135498047\n",
      "Epoch: 1, Batch: 173, Loss: 8.354191780090332\n",
      "Epoch: 1, Batch: 174, Loss: 8.234457969665527\n",
      "Epoch: 1, Batch: 175, Loss: 8.201947212219238\n",
      "Epoch: 1, Batch: 176, Loss: 8.212726593017578\n",
      "Epoch: 1, Batch: 177, Loss: 8.318069458007812\n",
      "Epoch: 1, Batch: 178, Loss: 8.240984916687012\n",
      "Epoch: 1, Batch: 179, Loss: 8.258439064025879\n",
      "Epoch: 1, Batch: 180, Loss: 8.001842498779297\n",
      "Epoch: 1, Batch: 181, Loss: 8.396646499633789\n",
      "Epoch: 1, Batch: 182, Loss: 8.304802894592285\n",
      "Epoch: 1, Batch: 183, Loss: 8.308422088623047\n",
      "Epoch: 1, Batch: 184, Loss: 8.083462715148926\n",
      "Epoch: 1, Batch: 185, Loss: 8.137761116027832\n",
      "Epoch: 1, Batch: 186, Loss: 8.398113250732422\n",
      "Epoch: 1, Batch: 187, Loss: 8.109197616577148\n",
      "Epoch: 1, Batch: 188, Loss: 8.368451118469238\n",
      "Epoch: 1, Batch: 189, Loss: 8.232059478759766\n",
      "Epoch: 1, Batch: 190, Loss: 8.156997680664062\n",
      "Epoch: 1, Batch: 191, Loss: 8.298810958862305\n",
      "Epoch: 1, Batch: 192, Loss: 8.259716033935547\n",
      "Epoch: 1, Batch: 193, Loss: 8.211772918701172\n",
      "Epoch: 1, Batch: 194, Loss: 8.024718284606934\n",
      "Epoch: 1, Batch: 195, Loss: 8.180665969848633\n",
      "Epoch: 1, Batch: 196, Loss: 8.162163734436035\n",
      "Epoch: 1, Batch: 197, Loss: 8.162622451782227\n",
      "Epoch: 1, Batch: 198, Loss: 8.184540748596191\n",
      "Epoch: 1, Batch: 199, Loss: 7.905324935913086\n",
      "Epoch: 1, Batch: 200, Loss: 8.143598556518555\n",
      "Epoch: 1, Batch: 201, Loss: 8.119954109191895\n",
      "Epoch: 1, Batch: 202, Loss: 8.178297996520996\n",
      "Epoch: 1, Batch: 203, Loss: 8.241220474243164\n",
      "Epoch: 1, Batch: 204, Loss: 7.979249000549316\n",
      "Epoch: 1, Batch: 205, Loss: 8.21378231048584\n",
      "Epoch: 1, Batch: 206, Loss: 8.252948760986328\n",
      "Epoch: 1, Batch: 207, Loss: 8.130922317504883\n",
      "Epoch: 1, Batch: 208, Loss: 7.74000358581543\n",
      "Epoch: 1, Batch: 209, Loss: 8.260278701782227\n",
      "Epoch: 1, Batch: 210, Loss: 8.14469051361084\n",
      "Epoch: 1, Batch: 211, Loss: 8.282114028930664\n",
      "Epoch: 1, Batch: 212, Loss: 8.132315635681152\n",
      "Epoch: 1, Batch: 213, Loss: 8.014874458312988\n",
      "Epoch: 1, Batch: 214, Loss: 8.086073875427246\n",
      "Epoch: 1, Batch: 215, Loss: 8.002866744995117\n",
      "Epoch: 1, Batch: 216, Loss: 8.216684341430664\n",
      "Epoch: 1, Batch: 217, Loss: 8.306729316711426\n",
      "Epoch: 1, Batch: 218, Loss: 7.806629180908203\n",
      "Epoch: 1, Batch: 219, Loss: 7.8700032234191895\n",
      "Epoch: 1, Batch: 220, Loss: 7.848376750946045\n",
      "Epoch: 1, Batch: 221, Loss: 7.923434734344482\n",
      "Epoch: 1, Batch: 222, Loss: 8.049749374389648\n",
      "Epoch: 1, Batch: 223, Loss: 7.797420501708984\n",
      "Epoch: 1, Batch: 224, Loss: 7.949218273162842\n",
      "Epoch: 1, Batch: 225, Loss: 7.810171604156494\n",
      "Epoch: 1, Batch: 226, Loss: 7.91179895401001\n",
      "Epoch: 1, Batch: 227, Loss: 7.798377990722656\n",
      "Epoch: 1, Batch: 228, Loss: 8.160141944885254\n",
      "Epoch: 1, Batch: 229, Loss: 7.707594394683838\n",
      "Epoch: 1, Batch: 230, Loss: 7.806382656097412\n",
      "Epoch: 1, Batch: 231, Loss: 7.972741603851318\n",
      "Epoch: 1, Batch: 232, Loss: 7.885138511657715\n",
      "Epoch: 1, Batch: 233, Loss: 7.810237407684326\n",
      "Epoch: 1, Batch: 234, Loss: 7.826837062835693\n",
      "Epoch: 1, Batch: 235, Loss: 7.573637962341309\n",
      "Epoch: 1, Batch: 236, Loss: 7.747640609741211\n",
      "Epoch: 1, Batch: 237, Loss: 7.90725564956665\n",
      "Epoch: 1, Batch: 238, Loss: 7.75041389465332\n",
      "Epoch: 1, Batch: 239, Loss: 7.864028453826904\n",
      "Epoch: 1, Batch: 240, Loss: 8.039039611816406\n",
      "Epoch: 1, Batch: 241, Loss: 7.795821666717529\n",
      "Epoch: 1, Batch: 242, Loss: 7.961598873138428\n",
      "Epoch: 1, Batch: 243, Loss: 7.889565467834473\n",
      "Epoch: 1, Batch: 244, Loss: 7.763309478759766\n",
      "Epoch: 1, Batch: 245, Loss: 7.705446243286133\n",
      "Epoch: 1, Batch: 246, Loss: 7.951411724090576\n",
      "Epoch: 1, Batch: 247, Loss: 8.19092845916748\n",
      "Epoch: 1, Batch: 248, Loss: 7.758286952972412\n",
      "Epoch: 1, Batch: 249, Loss: 8.090842247009277\n",
      "Epoch: 1, Batch: 250, Loss: 7.857473850250244\n",
      "Epoch: 1, Batch: 251, Loss: 7.761309623718262\n",
      "Epoch: 1, Batch: 252, Loss: 7.763358116149902\n",
      "Epoch: 1, Batch: 253, Loss: 7.830865859985352\n",
      "Epoch: 1, Batch: 254, Loss: 7.961735248565674\n",
      "Epoch: 1, Batch: 255, Loss: 7.90047025680542\n",
      "Epoch: 1, Batch: 256, Loss: 7.8667426109313965\n",
      "Epoch: 1, Batch: 257, Loss: 7.590914249420166\n",
      "Epoch: 1, Batch: 258, Loss: 7.863783359527588\n",
      "Epoch: 1, Batch: 259, Loss: 7.871435642242432\n",
      "Epoch: 1, Batch: 260, Loss: 7.715055465698242\n",
      "Epoch: 1, Batch: 261, Loss: 7.875392913818359\n",
      "Epoch: 1, Batch: 262, Loss: 7.872068405151367\n",
      "Epoch: 1, Batch: 263, Loss: 7.89128303527832\n",
      "Epoch: 1, Batch: 264, Loss: 7.533871650695801\n",
      "Epoch: 1, Batch: 265, Loss: 7.794646739959717\n",
      "Epoch: 1, Batch: 266, Loss: 7.701003074645996\n",
      "Epoch: 1, Batch: 267, Loss: 7.605769634246826\n",
      "Epoch: 1, Batch: 268, Loss: 7.649561405181885\n",
      "Epoch: 1, Batch: 269, Loss: 7.799860000610352\n",
      "Epoch: 1, Batch: 270, Loss: 7.518800735473633\n",
      "Epoch: 1, Batch: 271, Loss: 7.5434794425964355\n",
      "Epoch: 1, Batch: 272, Loss: 7.728559970855713\n",
      "Epoch: 1, Batch: 273, Loss: 7.802309036254883\n",
      "Epoch: 1, Batch: 274, Loss: 7.557812690734863\n",
      "Epoch: 1, Batch: 275, Loss: 7.436276912689209\n",
      "Epoch: 1, Batch: 276, Loss: 7.516757488250732\n",
      "Epoch: 1, Batch: 277, Loss: 7.865972518920898\n",
      "Epoch: 1, Batch: 278, Loss: 7.755088806152344\n",
      "Epoch: 1, Batch: 279, Loss: 7.77118444442749\n",
      "Epoch: 1, Batch: 280, Loss: 7.6318230628967285\n",
      "Epoch: 1, Batch: 281, Loss: 7.651996612548828\n",
      "Epoch: 1, Batch: 282, Loss: 7.376274585723877\n",
      "Epoch: 1, Batch: 283, Loss: 7.217811107635498\n",
      "Epoch: 1, Batch: 284, Loss: 7.486131191253662\n",
      "Epoch: 1, Batch: 285, Loss: 7.4493560791015625\n",
      "Epoch: 1, Batch: 286, Loss: 7.640448093414307\n",
      "Epoch: 1, Batch: 287, Loss: 7.5961198806762695\n",
      "Epoch: 1, Batch: 288, Loss: 7.7870683670043945\n",
      "Epoch: 1, Batch: 289, Loss: 7.552752494812012\n",
      "Epoch: 1, Batch: 290, Loss: 7.465310573577881\n",
      "Epoch: 1, Batch: 291, Loss: 7.847888946533203\n",
      "Epoch: 1, Batch: 292, Loss: 7.590872287750244\n",
      "Epoch: 1, Batch: 293, Loss: 7.460202217102051\n",
      "Epoch: 1, Batch: 294, Loss: 7.399648666381836\n",
      "Epoch: 1, Batch: 295, Loss: 7.597823143005371\n",
      "Epoch: 1, Batch: 296, Loss: 7.583102226257324\n",
      "Epoch: 1, Batch: 297, Loss: 7.862050533294678\n",
      "Epoch: 1, Batch: 298, Loss: 7.624374866485596\n",
      "Epoch: 1, Batch: 299, Loss: 7.800290584564209\n",
      "Epoch: 1, Batch: 300, Loss: 7.529710292816162\n",
      "Epoch: 1, Batch: 301, Loss: 7.398216724395752\n",
      "Epoch: 1, Batch: 302, Loss: 7.47381067276001\n",
      "Epoch: 1, Batch: 303, Loss: 7.375293254852295\n",
      "Epoch: 1, Batch: 304, Loss: 7.382828712463379\n",
      "Epoch: 1, Batch: 305, Loss: 7.361466407775879\n",
      "Epoch: 1, Batch: 306, Loss: 7.592252731323242\n",
      "Epoch: 1, Batch: 307, Loss: 7.451451778411865\n",
      "Epoch: 1, Batch: 308, Loss: 7.612391948699951\n",
      "Epoch: 1, Batch: 309, Loss: 7.606930732727051\n",
      "Epoch: 1, Batch: 310, Loss: 7.471048355102539\n",
      "Epoch: 1, Batch: 311, Loss: 7.715139865875244\n",
      "Epoch: 1, Batch: 312, Loss: 7.418434143066406\n",
      "Epoch: 1, Batch: 313, Loss: 7.342852592468262\n",
      "Epoch: 1, Batch: 314, Loss: 7.320756912231445\n",
      "Epoch: 1, Batch: 315, Loss: 7.327215671539307\n",
      "Epoch: 1, Batch: 316, Loss: 7.356803894042969\n",
      "Epoch: 1, Batch: 317, Loss: 7.311049938201904\n",
      "Epoch: 1, Batch: 318, Loss: 7.3020339012146\n",
      "Epoch: 1, Batch: 319, Loss: 7.51004695892334\n",
      "Epoch: 1, Batch: 320, Loss: 7.554017066955566\n",
      "Epoch: 1, Batch: 321, Loss: 7.225203037261963\n",
      "Epoch: 1, Batch: 322, Loss: 7.2275495529174805\n",
      "Epoch: 1, Batch: 323, Loss: 7.387057304382324\n",
      "Epoch: 1, Batch: 324, Loss: 7.164663314819336\n",
      "Epoch: 1, Batch: 325, Loss: 7.1771087646484375\n",
      "Epoch: 1, Batch: 326, Loss: 7.533177375793457\n",
      "Epoch: 1, Batch: 327, Loss: 7.30507755279541\n",
      "Epoch: 1, Batch: 328, Loss: 7.19533634185791\n",
      "Epoch: 1, Batch: 329, Loss: 7.21368408203125\n",
      "Epoch: 1, Batch: 330, Loss: 7.194823741912842\n",
      "Epoch: 1, Batch: 331, Loss: 7.297202110290527\n",
      "Epoch: 1, Batch: 332, Loss: 7.386804580688477\n",
      "Epoch: 1, Batch: 333, Loss: 7.173083782196045\n",
      "Epoch: 1, Batch: 334, Loss: 7.34421443939209\n",
      "Epoch: 1, Batch: 335, Loss: 7.334080696105957\n",
      "Epoch: 1, Batch: 336, Loss: 7.383699893951416\n",
      "Epoch: 1, Batch: 337, Loss: 7.175632476806641\n",
      "Epoch: 1, Batch: 338, Loss: 7.062193393707275\n",
      "Epoch: 1, Batch: 339, Loss: 7.380140781402588\n",
      "Epoch: 1, Batch: 340, Loss: 7.43704891204834\n",
      "Epoch: 1, Batch: 341, Loss: 7.330049991607666\n",
      "Epoch: 1, Batch: 342, Loss: 6.997213363647461\n",
      "Epoch: 1, Batch: 343, Loss: 7.437272548675537\n",
      "Epoch: 1, Batch: 344, Loss: 7.13580322265625\n",
      "Epoch: 1, Batch: 345, Loss: 7.212498664855957\n",
      "Epoch: 1, Batch: 346, Loss: 7.188687324523926\n",
      "Epoch: 1, Batch: 347, Loss: 7.236648082733154\n",
      "Epoch: 1, Batch: 348, Loss: 7.271545886993408\n",
      "Epoch: 1, Batch: 349, Loss: 7.28328275680542\n",
      "Epoch: 1, Batch: 350, Loss: 7.2609663009643555\n",
      "Epoch: 1, Batch: 351, Loss: 7.2030768394470215\n",
      "Epoch: 1, Batch: 352, Loss: 6.979289531707764\n",
      "Epoch: 1, Batch: 353, Loss: 6.999806880950928\n",
      "Epoch: 1, Batch: 354, Loss: 7.149552822113037\n",
      "Epoch: 1, Batch: 355, Loss: 6.816344738006592\n",
      "Epoch: 1, Batch: 356, Loss: 6.963634490966797\n",
      "Epoch: 1, Batch: 357, Loss: 7.233312129974365\n",
      "Epoch: 1, Batch: 358, Loss: 6.90144681930542\n",
      "Epoch: 1, Batch: 359, Loss: 7.216888427734375\n",
      "Epoch: 1, Batch: 360, Loss: 7.010164260864258\n",
      "Epoch: 1, Batch: 361, Loss: 6.9397196769714355\n",
      "Epoch: 1, Batch: 362, Loss: 7.154291152954102\n",
      "Epoch: 1, Batch: 363, Loss: 6.958111763000488\n",
      "Epoch: 1, Batch: 364, Loss: 7.152753829956055\n",
      "Epoch: 1, Batch: 365, Loss: 7.273123264312744\n",
      "Epoch: 1, Batch: 366, Loss: 6.797288417816162\n",
      "Epoch: 1, Batch: 367, Loss: 7.052353858947754\n",
      "Epoch: 1, Batch: 368, Loss: 6.935851573944092\n",
      "Epoch: 1, Batch: 369, Loss: 7.0086870193481445\n",
      "Epoch: 1, Batch: 370, Loss: 7.241089344024658\n",
      "Epoch: 1, Batch: 371, Loss: 7.283166885375977\n",
      "Epoch: 1, Batch: 372, Loss: 7.022287845611572\n",
      "Epoch: 1, Batch: 373, Loss: 7.111537456512451\n",
      "Epoch: 1, Batch: 374, Loss: 7.319483757019043\n",
      "Epoch: 1, Batch: 375, Loss: 6.895219802856445\n",
      "Epoch: 1, Batch: 376, Loss: 6.8342976570129395\n",
      "Epoch: 1, Batch: 377, Loss: 7.297499179840088\n",
      "Epoch: 1, Batch: 378, Loss: 7.130352973937988\n",
      "Epoch: 1, Batch: 379, Loss: 7.034609794616699\n",
      "Epoch: 1, Batch: 380, Loss: 7.0380940437316895\n",
      "Epoch: 1, Batch: 381, Loss: 7.088284492492676\n",
      "Epoch: 1, Batch: 382, Loss: 6.9458327293396\n",
      "Epoch: 1, Batch: 383, Loss: 6.784829139709473\n",
      "Epoch: 1, Batch: 384, Loss: 6.91815710067749\n",
      "Epoch: 1, Batch: 385, Loss: 7.250311851501465\n",
      "Epoch: 1, Batch: 386, Loss: 6.744237899780273\n",
      "Epoch: 1, Batch: 387, Loss: 6.714389801025391\n",
      "Epoch: 1, Batch: 388, Loss: 7.001729488372803\n",
      "Epoch: 1, Batch: 389, Loss: 6.969616889953613\n",
      "Epoch: 1, Batch: 390, Loss: 7.02700662612915\n",
      "Epoch: 1, Batch: 391, Loss: 7.040205955505371\n",
      "Epoch: 1, Batch: 392, Loss: 7.082138538360596\n",
      "Epoch: 1, Batch: 393, Loss: 6.902509689331055\n",
      "Epoch: 1, Batch: 394, Loss: 6.6177568435668945\n",
      "Epoch: 1, Batch: 395, Loss: 6.826140403747559\n",
      "Epoch: 1, Batch: 396, Loss: 6.766988277435303\n",
      "Epoch: 1, Batch: 397, Loss: 6.821979522705078\n",
      "Epoch: 1, Batch: 398, Loss: 7.014425277709961\n",
      "Epoch: 1, Batch: 399, Loss: 6.774369716644287\n",
      "Epoch: 1, Batch: 400, Loss: 6.702483177185059\n",
      "Epoch: 1, Batch: 401, Loss: 6.9244771003723145\n",
      "Epoch: 1, Batch: 402, Loss: 6.585960388183594\n",
      "Epoch: 1, Batch: 403, Loss: 6.865633010864258\n",
      "Epoch: 1, Batch: 404, Loss: 6.78558874130249\n",
      "Epoch: 1, Batch: 405, Loss: 7.027874946594238\n",
      "Epoch: 1, Batch: 406, Loss: 6.79603385925293\n",
      "Epoch: 1, Batch: 407, Loss: 6.738080024719238\n",
      "Epoch: 1, Batch: 408, Loss: 6.744616985321045\n",
      "Epoch: 1, Batch: 409, Loss: 7.267234802246094\n",
      "Epoch: 1, Batch: 410, Loss: 7.003983020782471\n",
      "Epoch: 1, Batch: 411, Loss: 6.589113712310791\n",
      "Epoch: 1, Batch: 412, Loss: 6.696900367736816\n",
      "Epoch: 1, Batch: 413, Loss: 6.8097333908081055\n",
      "Epoch: 1, Batch: 414, Loss: 6.75430965423584\n",
      "Epoch: 1, Batch: 415, Loss: 6.943050384521484\n",
      "Epoch: 1, Batch: 416, Loss: 6.761758327484131\n",
      "Epoch: 1, Batch: 417, Loss: 6.8743510246276855\n",
      "Epoch: 1, Batch: 418, Loss: 6.588259220123291\n",
      "Epoch: 1, Batch: 419, Loss: 6.805513381958008\n",
      "Epoch: 1, Batch: 420, Loss: 6.4293975830078125\n",
      "Epoch: 1, Batch: 421, Loss: 6.746708869934082\n",
      "Epoch: 1, Batch: 422, Loss: 6.697105407714844\n",
      "Epoch: 1, Batch: 423, Loss: 6.636785984039307\n",
      "Epoch: 1, Batch: 424, Loss: 6.692373752593994\n",
      "Epoch: 1, Batch: 425, Loss: 6.779247760772705\n",
      "Epoch: 1, Batch: 426, Loss: 6.878286838531494\n",
      "Epoch: 1, Batch: 427, Loss: 6.395969867706299\n",
      "Epoch: 1, Batch: 428, Loss: 6.520272254943848\n",
      "Epoch: 1, Batch: 429, Loss: 6.721457004547119\n",
      "Epoch: 1, Batch: 430, Loss: 6.7966108322143555\n",
      "Epoch: 1, Batch: 431, Loss: 6.721622467041016\n",
      "Epoch: 1, Batch: 432, Loss: 6.619344234466553\n",
      "Epoch: 1, Batch: 433, Loss: 6.621164798736572\n",
      "Epoch: 1, Batch: 434, Loss: 6.804522514343262\n",
      "Epoch: 1, Batch: 435, Loss: 6.860942840576172\n",
      "Epoch: 1, Batch: 436, Loss: 6.626209735870361\n",
      "Epoch: 1, Batch: 437, Loss: 6.757603168487549\n",
      "Epoch: 1, Batch: 438, Loss: 6.6548943519592285\n",
      "Epoch: 1, Batch: 439, Loss: 6.538554668426514\n",
      "Epoch: 1, Batch: 440, Loss: 6.509237766265869\n",
      "Epoch: 1, Batch: 441, Loss: 6.889113426208496\n",
      "Epoch: 1, Batch: 442, Loss: 6.607949733734131\n",
      "Epoch: 1, Batch: 443, Loss: 6.720938205718994\n",
      "Epoch: 1, Batch: 444, Loss: 6.643218517303467\n",
      "Epoch: 1, Batch: 445, Loss: 6.682614326477051\n",
      "Epoch: 1, Batch: 446, Loss: 6.464898109436035\n",
      "Epoch: 1, Batch: 447, Loss: 6.863619804382324\n",
      "Epoch: 1, Batch: 448, Loss: 6.631775856018066\n",
      "Epoch: 1, Batch: 449, Loss: 6.493607997894287\n",
      "Epoch: 1, Batch: 450, Loss: 6.6054816246032715\n",
      "Epoch: 1, Batch: 451, Loss: 6.637966632843018\n",
      "Epoch: 1, Batch: 452, Loss: 6.490610599517822\n",
      "Epoch: 1, Batch: 453, Loss: 6.594813346862793\n",
      "Epoch: 1, Batch: 454, Loss: 6.600769519805908\n",
      "Epoch: 1, Batch: 455, Loss: 6.559762001037598\n",
      "Epoch: 1, Batch: 456, Loss: 6.499396324157715\n",
      "Epoch: 1, Batch: 457, Loss: 6.256734848022461\n",
      "Epoch: 1, Batch: 458, Loss: 6.818514823913574\n",
      "Epoch: 1, Batch: 459, Loss: 6.93286657333374\n",
      "Epoch: 1, Batch: 460, Loss: 6.540538787841797\n",
      "Epoch: 1, Batch: 461, Loss: 6.5084733963012695\n",
      "Epoch: 1, Batch: 462, Loss: 6.574416637420654\n",
      "Epoch: 1, Batch: 463, Loss: 6.4119791984558105\n",
      "Epoch: 1, Batch: 464, Loss: 6.493727684020996\n",
      "Epoch: 1, Batch: 465, Loss: 6.304667949676514\n",
      "Epoch: 1, Batch: 466, Loss: 6.778774738311768\n",
      "Epoch: 1, Batch: 467, Loss: 6.471414566040039\n",
      "Epoch: 1, Batch: 468, Loss: 6.843855381011963\n",
      "Epoch: 1, Batch: 469, Loss: 6.695503234863281\n",
      "Epoch: 1, Batch: 470, Loss: 6.420312404632568\n",
      "Epoch: 1, Batch: 471, Loss: 6.154122352600098\n",
      "Epoch: 1, Batch: 472, Loss: 6.6093549728393555\n",
      "Epoch: 1, Batch: 473, Loss: 6.612942218780518\n",
      "Epoch: 1, Batch: 474, Loss: 6.640130996704102\n",
      "Epoch: 1, Batch: 475, Loss: 6.6285271644592285\n",
      "Epoch: 1, Batch: 476, Loss: 6.23354959487915\n",
      "Epoch: 1, Batch: 477, Loss: 6.254955768585205\n",
      "Epoch: 1, Batch: 478, Loss: 6.5036540031433105\n",
      "Epoch: 1, Batch: 479, Loss: 6.406213283538818\n",
      "Epoch: 1, Batch: 480, Loss: 6.283256530761719\n",
      "Epoch: 1, Batch: 481, Loss: 6.276887893676758\n",
      "Epoch: 1, Batch: 482, Loss: 6.34260368347168\n",
      "Epoch: 1, Batch: 483, Loss: 6.403048992156982\n",
      "Epoch: 1, Batch: 484, Loss: 6.379828453063965\n",
      "Epoch: 1, Batch: 485, Loss: 6.229400634765625\n",
      "Epoch: 1, Batch: 486, Loss: 6.271481513977051\n",
      "Epoch: 1, Batch: 487, Loss: 6.456887722015381\n",
      "Epoch: 1, Batch: 488, Loss: 6.293034076690674\n",
      "Epoch: 1, Batch: 489, Loss: 6.505643367767334\n",
      "Epoch: 1, Batch: 490, Loss: 6.016704559326172\n",
      "Epoch: 1, Batch: 491, Loss: 6.235095024108887\n",
      "Epoch: 1, Batch: 492, Loss: 6.519317626953125\n",
      "Epoch: 1, Batch: 493, Loss: 6.192852020263672\n",
      "Epoch: 1, Batch: 494, Loss: 6.279365062713623\n",
      "Epoch: 1, Batch: 495, Loss: 6.472253799438477\n",
      "Epoch: 1, Batch: 496, Loss: 6.39613151550293\n",
      "Epoch: 1, Batch: 497, Loss: 6.530333995819092\n",
      "Epoch: 1, Batch: 498, Loss: 6.649875640869141\n",
      "Epoch: 1, Batch: 499, Loss: 6.298126697540283\n",
      "Epoch: 1, Batch: 500, Loss: 6.412132740020752\n",
      "Epoch: 1, Batch: 501, Loss: 6.124042987823486\n",
      "Epoch: 1, Batch: 502, Loss: 6.314255237579346\n",
      "Epoch: 1, Batch: 503, Loss: 6.196568965911865\n",
      "Epoch: 1, Batch: 504, Loss: 6.186386585235596\n",
      "Epoch: 1, Batch: 505, Loss: 6.311487674713135\n",
      "Epoch: 1, Batch: 506, Loss: 6.251333236694336\n",
      "Epoch: 1, Batch: 507, Loss: 6.298619270324707\n",
      "Epoch: 1, Batch: 508, Loss: 6.271857738494873\n",
      "Epoch: 1, Batch: 509, Loss: 6.158222675323486\n",
      "Epoch: 1, Batch: 510, Loss: 6.203813076019287\n",
      "Epoch: 1, Batch: 511, Loss: 6.000151634216309\n",
      "Epoch: 1, Batch: 512, Loss: 6.122211933135986\n",
      "Epoch: 1, Batch: 513, Loss: 6.276025772094727\n",
      "Epoch: 1, Batch: 514, Loss: 6.429576873779297\n",
      "Epoch: 1, Batch: 515, Loss: 6.687518119812012\n",
      "Epoch: 1, Batch: 516, Loss: 6.283443450927734\n",
      "Epoch: 1, Batch: 517, Loss: 5.971598148345947\n",
      "Epoch: 1, Batch: 518, Loss: 6.195129871368408\n",
      "Epoch: 1, Batch: 519, Loss: 6.241099834442139\n",
      "Epoch: 1, Batch: 520, Loss: 6.142352104187012\n",
      "Epoch: 1, Batch: 521, Loss: 6.377596855163574\n",
      "Epoch: 1, Batch: 522, Loss: 6.500945091247559\n",
      "Epoch: 1, Batch: 523, Loss: 6.519765377044678\n",
      "Epoch: 1, Batch: 524, Loss: 6.407167911529541\n",
      "Epoch: 1, Batch: 525, Loss: 6.1360650062561035\n",
      "Epoch: 1, Batch: 526, Loss: 6.214306354522705\n",
      "Epoch: 1, Batch: 527, Loss: 6.27974271774292\n",
      "Epoch: 1, Batch: 528, Loss: 5.969348907470703\n",
      "Epoch: 1, Batch: 529, Loss: 5.821578025817871\n",
      "Epoch: 1, Batch: 530, Loss: 5.839654922485352\n",
      "Epoch: 1, Batch: 531, Loss: 6.3202738761901855\n",
      "Epoch: 1, Batch: 532, Loss: 6.325272083282471\n",
      "Epoch: 1, Batch: 533, Loss: 6.5494704246521\n",
      "Epoch: 1, Batch: 534, Loss: 6.4743876457214355\n",
      "Epoch: 1, Batch: 535, Loss: 5.859144687652588\n",
      "Epoch: 1, Batch: 536, Loss: 6.4955854415893555\n",
      "Epoch: 1, Batch: 537, Loss: 6.301763534545898\n",
      "Epoch: 1, Batch: 538, Loss: 5.904078006744385\n",
      "Epoch: 1, Batch: 539, Loss: 6.211967945098877\n",
      "Epoch: 1, Batch: 540, Loss: 6.352668762207031\n",
      "Epoch: 1, Batch: 541, Loss: 6.2479658126831055\n",
      "Epoch: 1, Batch: 542, Loss: 6.303279399871826\n",
      "Epoch: 1, Batch: 543, Loss: 6.134471416473389\n",
      "Epoch: 1, Batch: 544, Loss: 6.201488971710205\n",
      "Epoch: 1, Batch: 545, Loss: 5.888601779937744\n",
      "Epoch: 1, Batch: 546, Loss: 6.063274383544922\n",
      "Epoch: 1, Batch: 547, Loss: 5.938693523406982\n",
      "Epoch: 1, Batch: 548, Loss: 6.204131126403809\n",
      "Epoch: 1, Batch: 549, Loss: 6.485723972320557\n",
      "Epoch: 1, Batch: 550, Loss: 6.077284812927246\n",
      "Epoch: 1, Batch: 551, Loss: 6.2169413566589355\n",
      "Epoch: 1, Batch: 552, Loss: 6.218604564666748\n",
      "Epoch: 1, Batch: 553, Loss: 6.204929351806641\n",
      "Epoch: 1, Batch: 554, Loss: 6.413578033447266\n",
      "Epoch: 1, Batch: 555, Loss: 6.34733247756958\n",
      "Epoch: 1, Batch: 556, Loss: 6.077929973602295\n",
      "Epoch: 1, Batch: 557, Loss: 6.072506904602051\n",
      "Epoch: 1, Batch: 558, Loss: 6.288985729217529\n",
      "Epoch: 1, Batch: 559, Loss: 6.482946872711182\n",
      "Epoch: 1, Batch: 560, Loss: 6.353148460388184\n",
      "Epoch: 1, Batch: 561, Loss: 6.168299674987793\n",
      "Epoch: 1, Batch: 562, Loss: 6.225866317749023\n",
      "Epoch: 1, Batch: 563, Loss: 6.2258148193359375\n",
      "Epoch: 1, Batch: 564, Loss: 6.117903709411621\n",
      "Epoch: 1, Batch: 565, Loss: 6.083409309387207\n",
      "Epoch: 1, Batch: 566, Loss: 6.318966865539551\n",
      "Epoch: 1, Batch: 567, Loss: 6.093266487121582\n",
      "Epoch: 1, Batch: 568, Loss: 6.174684047698975\n",
      "Epoch: 1, Batch: 569, Loss: 6.1105732917785645\n",
      "Epoch: 1, Batch: 570, Loss: 6.168896675109863\n",
      "Epoch: 1, Batch: 571, Loss: 5.844080448150635\n",
      "Epoch: 1, Batch: 572, Loss: 6.157456398010254\n",
      "Epoch: 1, Batch: 573, Loss: 5.981250762939453\n",
      "Epoch: 1, Batch: 574, Loss: 6.0817646980285645\n",
      "Epoch: 1, Batch: 575, Loss: 5.963764190673828\n",
      "Epoch: 1, Batch: 576, Loss: 6.197290420532227\n",
      "Epoch: 1, Batch: 577, Loss: 5.717530250549316\n",
      "Epoch: 1, Batch: 578, Loss: 6.104475498199463\n",
      "Epoch: 1, Batch: 579, Loss: 6.113755226135254\n",
      "Epoch: 1, Batch: 580, Loss: 6.015080451965332\n",
      "Epoch: 1, Batch: 581, Loss: 6.1815266609191895\n",
      "Epoch: 1, Batch: 582, Loss: 5.90977144241333\n",
      "Epoch: 1, Batch: 583, Loss: 5.90350866317749\n",
      "Epoch: 1, Batch: 584, Loss: 6.217673301696777\n",
      "Epoch: 1, Batch: 585, Loss: 6.174349308013916\n",
      "Epoch: 1, Batch: 586, Loss: 6.0161662101745605\n",
      "Epoch: 1, Batch: 587, Loss: 5.969338417053223\n",
      "Epoch: 1, Batch: 588, Loss: 6.080649375915527\n",
      "Epoch: 1, Batch: 589, Loss: 6.2410783767700195\n",
      "Epoch: 1, Batch: 590, Loss: 6.008017063140869\n",
      "Epoch: 1, Batch: 591, Loss: 6.231930732727051\n",
      "Epoch: 1, Batch: 592, Loss: 6.112802982330322\n",
      "Epoch: 1, Batch: 593, Loss: 5.803186893463135\n",
      "Epoch: 1, Batch: 594, Loss: 6.193292140960693\n",
      "Epoch: 1, Batch: 595, Loss: 6.033009052276611\n",
      "Epoch: 1, Batch: 596, Loss: 6.2108283042907715\n",
      "Epoch: 1, Batch: 597, Loss: 5.7982563972473145\n",
      "Epoch: 1, Batch: 598, Loss: 6.102094650268555\n",
      "Epoch: 1, Batch: 599, Loss: 6.253783226013184\n",
      "Epoch: 1, Batch: 600, Loss: 6.077337265014648\n",
      "Epoch: 1, Batch: 601, Loss: 6.103804111480713\n",
      "Epoch: 1, Batch: 602, Loss: 5.723039627075195\n",
      "Epoch: 1, Batch: 603, Loss: 6.091463565826416\n",
      "Epoch: 1, Batch: 604, Loss: 6.2480034828186035\n",
      "Epoch: 1, Batch: 605, Loss: 6.263634204864502\n",
      "Epoch: 1, Batch: 606, Loss: 6.340195655822754\n",
      "Epoch: 1, Batch: 607, Loss: 6.0998125076293945\n",
      "Epoch: 1, Batch: 608, Loss: 5.812716484069824\n",
      "Epoch: 1, Batch: 609, Loss: 6.042862892150879\n",
      "Epoch: 1, Batch: 610, Loss: 5.818598747253418\n",
      "Epoch: 1, Batch: 611, Loss: 6.125265598297119\n",
      "Epoch: 1, Batch: 612, Loss: 6.2415080070495605\n",
      "Epoch: 1, Batch: 613, Loss: 6.051354885101318\n",
      "Epoch: 1, Batch: 614, Loss: 6.064212799072266\n",
      "Epoch: 1, Batch: 615, Loss: 6.061734199523926\n",
      "Epoch: 1, Batch: 616, Loss: 5.947999954223633\n",
      "Epoch: 1, Batch: 617, Loss: 5.75862455368042\n",
      "Epoch: 1, Batch: 618, Loss: 6.07481575012207\n",
      "Epoch: 1, Batch: 619, Loss: 6.099113464355469\n",
      "Epoch: 1, Batch: 620, Loss: 5.865725517272949\n",
      "Epoch: 1, Batch: 621, Loss: 6.0305280685424805\n",
      "Epoch: 1, Batch: 622, Loss: 6.0732340812683105\n",
      "Epoch: 1, Batch: 623, Loss: 6.113450527191162\n",
      "Epoch: 1, Batch: 624, Loss: 5.953491687774658\n",
      "Epoch: 1, Batch: 625, Loss: 5.747082710266113\n",
      "Epoch: 1, Batch: 626, Loss: 5.9773077964782715\n",
      "Epoch: 1, Batch: 627, Loss: 5.98132848739624\n",
      "Epoch: 1, Batch: 628, Loss: 6.086536884307861\n",
      "Epoch: 1, Batch: 629, Loss: 6.188055515289307\n",
      "Epoch: 1, Batch: 630, Loss: 6.02664852142334\n",
      "Epoch: 1, Batch: 631, Loss: 5.95427131652832\n",
      "Epoch: 1, Batch: 632, Loss: 6.250665664672852\n",
      "Epoch: 1, Batch: 633, Loss: 6.00211238861084\n",
      "Epoch: 1, Batch: 634, Loss: 5.977169990539551\n",
      "Epoch: 1, Batch: 635, Loss: 6.119949817657471\n",
      "Epoch: 1, Batch: 636, Loss: 5.978449821472168\n",
      "Epoch: 1, Batch: 637, Loss: 5.805906772613525\n",
      "Epoch: 1, Batch: 638, Loss: 6.239580154418945\n",
      "Epoch: 1, Batch: 639, Loss: 6.04002571105957\n",
      "Epoch: 1, Batch: 640, Loss: 6.042646408081055\n",
      "Epoch: 1, Batch: 641, Loss: 5.604321002960205\n",
      "Epoch: 1, Batch: 642, Loss: 5.956623077392578\n",
      "Epoch: 1, Batch: 643, Loss: 6.162590026855469\n",
      "Epoch: 1, Batch: 644, Loss: 5.815472602844238\n",
      "Epoch: 1, Batch: 645, Loss: 5.8472490310668945\n",
      "Epoch: 1, Batch: 646, Loss: 5.691247463226318\n",
      "Epoch: 1, Batch: 647, Loss: 6.106986045837402\n",
      "Epoch: 1, Batch: 648, Loss: 5.893978118896484\n",
      "Epoch: 1, Batch: 649, Loss: 5.899052619934082\n",
      "Epoch: 1, Batch: 650, Loss: 5.85039758682251\n",
      "Epoch: 1, Batch: 651, Loss: 5.842437267303467\n",
      "Epoch: 1, Batch: 652, Loss: 6.0398054122924805\n",
      "Epoch: 1, Batch: 653, Loss: 6.015227794647217\n",
      "Epoch: 1, Batch: 654, Loss: 5.984829902648926\n",
      "Epoch: 1, Batch: 655, Loss: 6.0108208656311035\n",
      "Epoch: 1, Batch: 656, Loss: 5.869377613067627\n",
      "Epoch: 1, Batch: 657, Loss: 5.980636119842529\n",
      "Epoch: 1, Batch: 658, Loss: 5.971916198730469\n",
      "Epoch: 1, Batch: 659, Loss: 6.189383506774902\n",
      "Epoch: 1, Batch: 660, Loss: 5.92141056060791\n",
      "Epoch: 1, Batch: 661, Loss: 5.9118547439575195\n",
      "Epoch: 1, Batch: 662, Loss: 5.923640727996826\n",
      "Epoch: 1, Batch: 663, Loss: 5.7736711502075195\n",
      "Epoch: 1, Batch: 664, Loss: 5.6019487380981445\n",
      "Epoch: 1, Batch: 665, Loss: 5.770238876342773\n",
      "Epoch: 1, Batch: 666, Loss: 6.2319254875183105\n",
      "Epoch: 1, Batch: 667, Loss: 5.940462589263916\n",
      "Epoch: 1, Batch: 668, Loss: 5.594671249389648\n",
      "Epoch: 1, Batch: 669, Loss: 6.01120138168335\n",
      "Epoch: 1, Batch: 670, Loss: 6.019383430480957\n",
      "Epoch: 1, Batch: 671, Loss: 5.912879467010498\n",
      "Epoch: 1, Batch: 672, Loss: 5.721860408782959\n",
      "Epoch: 1, Batch: 673, Loss: 5.903115749359131\n",
      "Epoch: 1, Batch: 674, Loss: 5.706578731536865\n",
      "Epoch: 1, Batch: 675, Loss: 6.269508361816406\n",
      "Epoch: 1, Batch: 676, Loss: 6.079356670379639\n",
      "Epoch: 1, Batch: 677, Loss: 5.83189582824707\n",
      "Epoch: 1, Batch: 678, Loss: 5.887261867523193\n",
      "Epoch: 1, Batch: 679, Loss: 5.914430141448975\n",
      "Epoch: 1, Batch: 680, Loss: 5.7507758140563965\n",
      "Epoch: 1, Batch: 681, Loss: 5.8805742263793945\n",
      "Epoch: 1, Batch: 682, Loss: 6.031356334686279\n",
      "Epoch: 1, Batch: 683, Loss: 5.724801063537598\n",
      "Epoch: 1, Batch: 684, Loss: 5.815144062042236\n",
      "Epoch: 1, Batch: 685, Loss: 6.112288475036621\n",
      "Epoch: 1, Batch: 686, Loss: 6.065550327301025\n",
      "Epoch: 1, Batch: 687, Loss: 5.854849815368652\n",
      "Epoch: 1, Batch: 688, Loss: 5.799957275390625\n",
      "Epoch: 1, Batch: 689, Loss: 5.883731365203857\n",
      "Epoch: 1, Batch: 690, Loss: 5.863232135772705\n",
      "Epoch: 1, Batch: 691, Loss: 5.853372097015381\n",
      "Epoch: 1, Batch: 692, Loss: 5.804560661315918\n",
      "Epoch: 1, Batch: 693, Loss: 5.863010883331299\n",
      "Epoch: 1, Batch: 694, Loss: 5.734032154083252\n",
      "Epoch: 1, Batch: 695, Loss: 5.9321441650390625\n",
      "Epoch: 1, Batch: 696, Loss: 5.909817695617676\n",
      "Epoch: 1, Batch: 697, Loss: 5.909221649169922\n",
      "Epoch: 1, Batch: 698, Loss: 6.154227256774902\n",
      "Epoch: 1, Batch: 699, Loss: 5.905914783477783\n",
      "Epoch: 1, Batch: 700, Loss: 5.997291088104248\n",
      "Epoch: 1, Batch: 701, Loss: 5.812160491943359\n",
      "Epoch: 1, Batch: 702, Loss: 5.8046135902404785\n",
      "Epoch: 1, Batch: 703, Loss: 6.142798900604248\n",
      "Epoch: 1, Batch: 704, Loss: 6.001984119415283\n",
      "Epoch: 1, Batch: 705, Loss: 5.813048839569092\n",
      "Epoch: 1, Batch: 706, Loss: 5.877383232116699\n",
      "Epoch: 1, Batch: 707, Loss: 5.830606460571289\n",
      "Epoch: 1, Batch: 708, Loss: 5.794346332550049\n",
      "Epoch: 1, Batch: 709, Loss: 5.900261878967285\n",
      "Epoch: 1, Batch: 710, Loss: 5.674779891967773\n",
      "Epoch: 1, Batch: 711, Loss: 5.709112167358398\n",
      "Epoch: 1, Batch: 712, Loss: 6.096213340759277\n",
      "Epoch: 1, Batch: 713, Loss: 5.820578098297119\n",
      "Epoch: 1, Batch: 714, Loss: 5.854669094085693\n",
      "Epoch: 1, Batch: 715, Loss: 6.045379161834717\n",
      "Epoch: 1, Batch: 716, Loss: 6.064255714416504\n",
      "Epoch: 1, Batch: 717, Loss: 5.870439529418945\n",
      "Epoch: 1, Batch: 718, Loss: 6.012197494506836\n",
      "Epoch: 1, Batch: 719, Loss: 5.739239692687988\n",
      "Epoch: 1, Batch: 720, Loss: 5.842593193054199\n",
      "Epoch: 1, Batch: 721, Loss: 5.701033115386963\n",
      "Epoch: 1, Batch: 722, Loss: 5.8741774559021\n",
      "Epoch: 1, Batch: 723, Loss: 5.752379417419434\n",
      "Epoch: 1, Batch: 724, Loss: 5.535059928894043\n",
      "Epoch: 1, Batch: 725, Loss: 5.841060161590576\n",
      "Epoch: 1, Batch: 726, Loss: 5.6228508949279785\n",
      "Epoch: 1, Batch: 727, Loss: 5.590308666229248\n",
      "Epoch: 1, Batch: 728, Loss: 5.69089412689209\n",
      "Epoch: 1, Batch: 729, Loss: 5.616249084472656\n",
      "Epoch: 1, Batch: 730, Loss: 5.826042652130127\n",
      "Epoch: 1, Batch: 731, Loss: 5.813209056854248\n",
      "Epoch: 1, Batch: 732, Loss: 5.720874309539795\n",
      "Epoch: 1, Batch: 733, Loss: 5.988264083862305\n",
      "Epoch: 1, Batch: 734, Loss: 5.986456394195557\n",
      "Epoch: 1, Batch: 735, Loss: 5.897575378417969\n",
      "Epoch: 1, Batch: 736, Loss: 5.809789657592773\n",
      "Epoch: 1, Batch: 737, Loss: 5.970574855804443\n",
      "Epoch: 1, Batch: 738, Loss: 5.820323467254639\n",
      "Epoch: 1, Batch: 739, Loss: 5.73463249206543\n",
      "Epoch: 1, Batch: 740, Loss: 5.417592525482178\n",
      "Epoch: 1, Batch: 741, Loss: 5.987375259399414\n",
      "Epoch: 1, Batch: 742, Loss: 5.826188087463379\n",
      "Epoch: 1, Batch: 743, Loss: 5.705456256866455\n",
      "Epoch: 1, Batch: 744, Loss: 5.954549312591553\n",
      "Epoch: 1, Batch: 745, Loss: 5.934967517852783\n",
      "Epoch: 1, Batch: 746, Loss: 5.9801459312438965\n",
      "Epoch: 1, Batch: 747, Loss: 5.817201614379883\n",
      "Epoch: 1, Batch: 748, Loss: 5.6641950607299805\n",
      "Epoch: 1, Batch: 749, Loss: 5.758824825286865\n",
      "Epoch: 1, Batch: 750, Loss: 5.8265604972839355\n",
      "Epoch: 1, Batch: 751, Loss: 6.01259183883667\n",
      "Epoch: 1, Batch: 752, Loss: 6.115423202514648\n",
      "Epoch: 1, Batch: 753, Loss: 5.902937412261963\n",
      "Epoch: 1, Batch: 754, Loss: 5.4914445877075195\n",
      "Epoch: 1, Batch: 755, Loss: 5.700328350067139\n",
      "Epoch: 1, Batch: 756, Loss: 5.550931930541992\n",
      "Epoch: 1, Batch: 757, Loss: 5.822986602783203\n",
      "Epoch: 1, Batch: 758, Loss: 5.483945846557617\n",
      "Epoch: 1, Batch: 759, Loss: 5.517202377319336\n",
      "Epoch: 1, Batch: 760, Loss: 5.766233444213867\n",
      "Epoch: 1, Batch: 761, Loss: 5.815709590911865\n",
      "Epoch: 1, Batch: 762, Loss: 5.880260944366455\n",
      "Epoch: 1, Batch: 763, Loss: 5.855231761932373\n",
      "Epoch: 1, Batch: 764, Loss: 5.631793975830078\n",
      "Epoch: 1, Batch: 765, Loss: 5.856157302856445\n",
      "Epoch: 1, Batch: 766, Loss: 5.506166458129883\n",
      "Epoch: 1, Batch: 767, Loss: 5.740270614624023\n",
      "Epoch: 1, Batch: 768, Loss: 5.7790422439575195\n",
      "Epoch: 1, Batch: 769, Loss: 5.7396721839904785\n",
      "Epoch: 1, Batch: 770, Loss: 5.687246322631836\n",
      "Epoch: 1, Batch: 771, Loss: 5.845035076141357\n",
      "Epoch: 1, Batch: 772, Loss: 5.586806774139404\n",
      "Epoch: 1, Batch: 773, Loss: 5.862225532531738\n",
      "Epoch: 1, Batch: 774, Loss: 5.776883125305176\n",
      "Epoch: 1, Batch: 775, Loss: 5.804734706878662\n",
      "Epoch: 1, Batch: 776, Loss: 5.740713119506836\n",
      "Epoch: 1, Batch: 777, Loss: 5.975142955780029\n",
      "Epoch: 1, Batch: 778, Loss: 5.449609756469727\n",
      "Epoch: 1, Batch: 779, Loss: 5.829774856567383\n",
      "Epoch: 1, Batch: 780, Loss: 5.587487697601318\n",
      "Epoch: 1, Batch: 781, Loss: 5.9614667892456055\n",
      "Epoch: 1, Batch: 782, Loss: 5.664799690246582\n",
      "Epoch: 1, Batch: 783, Loss: 5.585573196411133\n",
      "Epoch: 1, Batch: 784, Loss: 5.6356611251831055\n",
      "Epoch: 1, Batch: 785, Loss: 5.509361743927002\n",
      "Epoch: 1, Batch: 786, Loss: 5.751922130584717\n",
      "Epoch: 1, Batch: 787, Loss: 5.765382766723633\n",
      "Epoch: 1, Batch: 788, Loss: 5.780508041381836\n",
      "Epoch: 1, Batch: 789, Loss: 5.677839756011963\n",
      "Epoch: 1, Batch: 790, Loss: 5.6668572425842285\n",
      "Epoch: 1, Batch: 791, Loss: 5.68896484375\n",
      "Epoch: 1, Batch: 792, Loss: 5.662574768066406\n",
      "Epoch: 1, Batch: 793, Loss: 5.550045490264893\n",
      "Epoch: 1, Batch: 794, Loss: 5.38362455368042\n",
      "Epoch: 1, Batch: 795, Loss: 5.91739559173584\n",
      "Epoch: 1, Batch: 796, Loss: 5.564730167388916\n",
      "Epoch: 1, Batch: 797, Loss: 5.900346279144287\n",
      "Epoch: 1, Batch: 798, Loss: 5.536552429199219\n",
      "Epoch: 1, Batch: 799, Loss: 5.671750068664551\n",
      "Epoch: 1, Batch: 800, Loss: 5.540072917938232\n",
      "Epoch: 1, Batch: 801, Loss: 5.58505392074585\n",
      "Epoch: 1, Batch: 802, Loss: 5.676685333251953\n",
      "Epoch: 1, Batch: 803, Loss: 6.07643985748291\n",
      "Epoch: 1, Batch: 804, Loss: 5.779087066650391\n",
      "Epoch: 1, Batch: 805, Loss: 5.78977632522583\n",
      "Epoch: 1, Batch: 806, Loss: 5.625495910644531\n",
      "Epoch: 1, Batch: 807, Loss: 5.741664886474609\n",
      "Epoch: 1, Batch: 808, Loss: 5.763054847717285\n",
      "Epoch: 1, Batch: 809, Loss: 5.63655424118042\n",
      "Epoch: 1, Batch: 810, Loss: 5.4598565101623535\n",
      "Epoch: 1, Batch: 811, Loss: 5.6160993576049805\n",
      "Epoch: 1, Batch: 812, Loss: 5.747410774230957\n",
      "Epoch: 1, Batch: 813, Loss: 5.539766311645508\n",
      "Epoch: 1, Batch: 814, Loss: 5.8390278816223145\n",
      "Epoch: 1, Batch: 815, Loss: 5.827705383300781\n",
      "Epoch: 1, Batch: 816, Loss: 5.67206335067749\n",
      "Epoch: 1, Batch: 817, Loss: 5.706004619598389\n",
      "Epoch: 1, Batch: 818, Loss: 5.4670891761779785\n",
      "Epoch: 1, Batch: 819, Loss: 5.6460137367248535\n",
      "Epoch: 1, Batch: 820, Loss: 5.625080108642578\n",
      "Epoch: 1, Batch: 821, Loss: 5.649138927459717\n",
      "Epoch: 1, Batch: 822, Loss: 5.696959495544434\n",
      "Epoch: 1, Batch: 823, Loss: 5.83113431930542\n",
      "Epoch: 1, Batch: 824, Loss: 5.717774868011475\n",
      "Epoch: 1, Batch: 825, Loss: 5.8386335372924805\n",
      "Epoch: 1, Batch: 826, Loss: 5.616685390472412\n",
      "Epoch: 1, Batch: 827, Loss: 5.486293792724609\n",
      "Epoch: 1, Batch: 828, Loss: 5.617698669433594\n",
      "Epoch: 1, Batch: 829, Loss: 5.631679058074951\n",
      "Epoch: 1, Batch: 830, Loss: 5.656068801879883\n",
      "Epoch: 1, Batch: 831, Loss: 5.730487823486328\n",
      "Epoch: 1, Batch: 832, Loss: 5.735499858856201\n",
      "Epoch: 1, Batch: 833, Loss: 5.544875144958496\n",
      "Epoch: 1, Batch: 834, Loss: 5.852502346038818\n",
      "Epoch: 1, Batch: 835, Loss: 5.771227836608887\n",
      "Epoch: 1, Batch: 836, Loss: 5.965361595153809\n",
      "Epoch: 1, Batch: 837, Loss: 5.541747570037842\n",
      "Epoch: 1, Batch: 838, Loss: 5.914269924163818\n",
      "Epoch: 1, Batch: 839, Loss: 5.606526851654053\n",
      "Epoch: 1, Batch: 840, Loss: 5.677772521972656\n",
      "Epoch: 1, Batch: 841, Loss: 5.921767711639404\n",
      "Epoch: 1, Batch: 842, Loss: 5.240422248840332\n",
      "Epoch: 1, Batch: 843, Loss: 5.41392707824707\n",
      "Epoch: 1, Batch: 844, Loss: 5.573504447937012\n",
      "Epoch: 1, Batch: 845, Loss: 5.629420757293701\n",
      "Epoch: 1, Batch: 846, Loss: 5.320443153381348\n",
      "Epoch: 1, Batch: 847, Loss: 5.546871185302734\n",
      "Epoch: 1, Batch: 848, Loss: 5.772571086883545\n",
      "Epoch: 1, Batch: 849, Loss: 5.493490695953369\n",
      "Epoch: 1, Batch: 850, Loss: 5.762157917022705\n",
      "Epoch: 1, Batch: 851, Loss: 5.717976093292236\n",
      "Epoch: 1, Batch: 852, Loss: 5.765591144561768\n",
      "Epoch: 1, Batch: 853, Loss: 5.6406965255737305\n",
      "Epoch: 1, Batch: 854, Loss: 5.61624813079834\n",
      "Epoch: 1, Batch: 855, Loss: 5.963593006134033\n",
      "Epoch: 1, Batch: 856, Loss: 5.665432453155518\n",
      "Epoch: 1, Batch: 857, Loss: 5.840726375579834\n",
      "Epoch: 1, Batch: 858, Loss: 5.612181186676025\n",
      "Epoch: 1, Batch: 859, Loss: 5.684978008270264\n",
      "Epoch: 1, Batch: 860, Loss: 5.491792678833008\n",
      "Epoch: 1, Batch: 861, Loss: 5.754665374755859\n",
      "Epoch: 1, Batch: 862, Loss: 5.6337175369262695\n",
      "Epoch: 1, Batch: 863, Loss: 5.828558444976807\n",
      "Epoch: 1, Batch: 864, Loss: 6.077597141265869\n",
      "Epoch: 1, Batch: 865, Loss: 5.435393333435059\n",
      "Epoch: 1, Batch: 866, Loss: 5.354310989379883\n",
      "Epoch: 1, Batch: 867, Loss: 5.461974620819092\n",
      "Epoch: 1, Batch: 868, Loss: 5.411766052246094\n",
      "Epoch: 1, Batch: 869, Loss: 5.749013900756836\n",
      "Epoch: 1, Batch: 870, Loss: 5.492156028747559\n",
      "Epoch: 1, Batch: 871, Loss: 5.942626476287842\n",
      "Epoch: 1, Batch: 872, Loss: 5.6910505294799805\n",
      "Epoch: 1, Batch: 873, Loss: 5.838551998138428\n",
      "Epoch: 1, Batch: 874, Loss: 5.599708557128906\n",
      "Epoch: 1, Batch: 875, Loss: 5.776587009429932\n",
      "Epoch: 1, Batch: 876, Loss: 5.672903060913086\n",
      "Epoch: 1, Batch: 877, Loss: 5.422789573669434\n",
      "Epoch: 1, Batch: 878, Loss: 5.78108024597168\n",
      "Epoch: 1, Batch: 879, Loss: 5.652080059051514\n",
      "Epoch: 1, Batch: 880, Loss: 5.312415599822998\n",
      "Epoch: 1, Batch: 881, Loss: 5.502663612365723\n",
      "Epoch: 1, Batch: 882, Loss: 5.670386791229248\n",
      "Epoch: 1, Batch: 883, Loss: 5.607709884643555\n",
      "Epoch: 1, Batch: 884, Loss: 5.584196090698242\n",
      "Epoch: 1, Batch: 885, Loss: 5.144379615783691\n",
      "Epoch: 1, Batch: 886, Loss: 5.552801132202148\n",
      "Epoch: 1, Batch: 887, Loss: 5.895438194274902\n",
      "Epoch: 1, Batch: 888, Loss: 5.560372352600098\n",
      "Epoch: 1, Batch: 889, Loss: 5.603653907775879\n",
      "Epoch: 1, Batch: 890, Loss: 5.726670265197754\n",
      "Epoch: 1, Batch: 891, Loss: 5.316092491149902\n",
      "Epoch: 1, Batch: 892, Loss: 5.5362324714660645\n",
      "Epoch: 1, Batch: 893, Loss: 5.585759162902832\n",
      "Epoch: 1, Batch: 894, Loss: 5.731373310089111\n",
      "Epoch: 1, Batch: 895, Loss: 5.594451904296875\n",
      "Epoch: 1, Batch: 896, Loss: 5.613253593444824\n",
      "Epoch: 1, Batch: 897, Loss: 5.527341842651367\n",
      "Epoch: 1, Batch: 898, Loss: 5.6953840255737305\n",
      "Epoch: 1, Batch: 899, Loss: 5.42023229598999\n",
      "Epoch: 1, Batch: 900, Loss: 5.845728397369385\n",
      "Epoch: 1, Batch: 901, Loss: 5.696387767791748\n",
      "Epoch: 1, Batch: 902, Loss: 5.391819953918457\n",
      "Epoch: 1, Batch: 903, Loss: 5.451618671417236\n",
      "Epoch: 1, Batch: 904, Loss: 5.574972152709961\n",
      "Epoch: 1, Batch: 905, Loss: 5.676085948944092\n",
      "Epoch: 1, Batch: 906, Loss: 5.5298309326171875\n",
      "Epoch: 1, Batch: 907, Loss: 5.779922008514404\n",
      "Epoch: 1, Batch: 908, Loss: 5.584848403930664\n",
      "Epoch: 1, Batch: 909, Loss: 5.383743762969971\n",
      "Epoch: 1, Batch: 910, Loss: 5.521464824676514\n",
      "Epoch: 1, Batch: 911, Loss: 5.527955055236816\n",
      "Epoch: 1, Batch: 912, Loss: 5.550998210906982\n",
      "Epoch: 1, Batch: 913, Loss: 5.362008571624756\n",
      "Epoch: 1, Batch: 914, Loss: 5.635558605194092\n",
      "Epoch: 1, Batch: 915, Loss: 5.543673038482666\n",
      "Epoch: 1, Batch: 916, Loss: 5.492419242858887\n",
      "Epoch: 1, Batch: 917, Loss: 5.591738224029541\n",
      "Epoch: 1, Batch: 918, Loss: 5.475326061248779\n",
      "Epoch: 1, Batch: 919, Loss: 5.709960460662842\n",
      "Epoch: 1, Batch: 920, Loss: 5.5016984939575195\n",
      "Epoch: 1, Batch: 921, Loss: 5.4174418449401855\n",
      "Epoch: 1, Batch: 922, Loss: 5.557243347167969\n",
      "Epoch: 1, Batch: 923, Loss: 5.517007350921631\n",
      "Epoch: 1, Batch: 924, Loss: 5.535189628601074\n",
      "Epoch: 1, Batch: 925, Loss: 5.7728705406188965\n",
      "Epoch: 1, Batch: 926, Loss: 5.845039367675781\n",
      "Epoch: 1, Batch: 927, Loss: 5.728696823120117\n",
      "Epoch: 1, Batch: 928, Loss: 5.492870807647705\n",
      "Epoch: 1, Batch: 929, Loss: 5.5068135261535645\n",
      "Epoch: 1, Batch: 930, Loss: 5.486008644104004\n",
      "Epoch: 1, Batch: 931, Loss: 5.370477199554443\n",
      "Epoch: 1, Batch: 932, Loss: 5.271831512451172\n",
      "Epoch: 1, Batch: 933, Loss: 5.596772193908691\n",
      "Epoch: 1, Batch: 934, Loss: 5.5962982177734375\n",
      "Epoch: 1, Batch: 935, Loss: 5.245982646942139\n",
      "Epoch: 1, Batch: 936, Loss: 5.505298137664795\n",
      "Epoch: 1, Batch: 937, Loss: 5.7301530838012695\n",
      "Epoch: 1, Batch: 938, Loss: 5.2675700187683105\n",
      "Epoch: 1, Batch: 939, Loss: 5.491659641265869\n",
      "Epoch: 1, Batch: 940, Loss: 5.366362571716309\n",
      "Epoch: 1, Batch: 941, Loss: 5.522019386291504\n",
      "Epoch: 1, Batch: 942, Loss: 5.786748886108398\n",
      "Epoch: 1, Batch: 943, Loss: 5.671912670135498\n",
      "Epoch: 1, Batch: 944, Loss: 5.468728065490723\n",
      "Epoch: 1, Batch: 945, Loss: 5.625682830810547\n",
      "Epoch: 1, Batch: 946, Loss: 5.948311805725098\n",
      "Epoch: 1, Batch: 947, Loss: 5.573153972625732\n",
      "Epoch: 1, Batch: 948, Loss: 5.487732410430908\n",
      "Epoch: 1, Batch: 949, Loss: 5.349872589111328\n",
      "Epoch: 1, Batch: 950, Loss: 5.741265296936035\n",
      "Epoch: 1, Batch: 951, Loss: 5.452566146850586\n",
      "Epoch: 1, Batch: 952, Loss: 5.720930576324463\n",
      "Epoch: 1, Batch: 953, Loss: 5.461958885192871\n",
      "Epoch: 1, Batch: 954, Loss: 5.692187786102295\n",
      "Epoch: 1, Batch: 955, Loss: 5.587915420532227\n",
      "Epoch: 1, Batch: 956, Loss: 5.847367763519287\n",
      "Epoch: 1, Batch: 957, Loss: 5.617623329162598\n",
      "Epoch: 1, Batch: 958, Loss: 5.708062648773193\n",
      "Epoch: 1, Batch: 959, Loss: 5.546462059020996\n",
      "Epoch: 1, Batch: 960, Loss: 5.488238334655762\n",
      "Epoch: 1, Batch: 961, Loss: 5.3191633224487305\n",
      "Epoch: 1, Batch: 962, Loss: 5.544681072235107\n",
      "Epoch: 1, Batch: 963, Loss: 5.688681602478027\n",
      "Epoch: 1, Batch: 964, Loss: 5.104954719543457\n",
      "Epoch: 1, Batch: 965, Loss: 5.404690265655518\n",
      "Epoch: 1, Batch: 966, Loss: 5.588754177093506\n",
      "Epoch: 1, Batch: 967, Loss: 5.556805610656738\n",
      "Epoch: 1, Batch: 968, Loss: 5.735556602478027\n",
      "Epoch: 1, Batch: 969, Loss: 5.746927261352539\n",
      "Epoch: 1, Batch: 970, Loss: 5.452499866485596\n",
      "Epoch: 1, Batch: 971, Loss: 5.88548469543457\n",
      "Epoch: 1, Batch: 972, Loss: 5.346617221832275\n",
      "Epoch: 1, Batch: 973, Loss: 5.658170223236084\n",
      "Epoch: 1, Batch: 974, Loss: 5.439453601837158\n",
      "Epoch: 1, Batch: 975, Loss: 5.4910173416137695\n",
      "Epoch: 1, Batch: 976, Loss: 5.599816799163818\n",
      "Epoch: 1, Batch: 977, Loss: 5.635429382324219\n",
      "Epoch: 1, Batch: 978, Loss: 5.516016960144043\n",
      "Epoch: 1, Batch: 979, Loss: 5.54970645904541\n",
      "Epoch: 1, Batch: 980, Loss: 5.393751621246338\n",
      "Epoch: 1, Batch: 981, Loss: 5.43856143951416\n",
      "Epoch: 1, Batch: 982, Loss: 5.22951602935791\n",
      "Epoch: 1, Batch: 983, Loss: 5.266804218292236\n",
      "Epoch: 1, Batch: 984, Loss: 5.476832866668701\n",
      "Epoch: 1, Batch: 985, Loss: 5.446138381958008\n",
      "Epoch: 1, Batch: 986, Loss: 5.332765102386475\n",
      "Epoch: 1, Batch: 987, Loss: 5.750420570373535\n",
      "Epoch: 1, Batch: 988, Loss: 5.388547420501709\n",
      "Epoch: 1, Batch: 989, Loss: 5.649639129638672\n",
      "Epoch: 1, Batch: 990, Loss: 5.288470268249512\n",
      "Epoch: 1, Batch: 991, Loss: 5.501073360443115\n",
      "Epoch: 1, Batch: 992, Loss: 5.334368705749512\n",
      "Epoch: 1, Batch: 993, Loss: 5.684985160827637\n",
      "Epoch: 1, Batch: 994, Loss: 5.549843788146973\n",
      "Epoch: 1, Batch: 995, Loss: 5.524740219116211\n",
      "Epoch: 1, Batch: 996, Loss: 5.47227144241333\n",
      "Epoch: 1, Batch: 997, Loss: 5.5020575523376465\n",
      "Epoch: 1, Batch: 998, Loss: 5.595575332641602\n",
      "Epoch: 1, Batch: 999, Loss: 5.432603359222412\n",
      "Epoch: 1, Batch: 1000, Loss: 5.7254815101623535\n",
      "Epoch: 1, Batch: 1001, Loss: 5.5674824714660645\n",
      "Epoch: 1, Batch: 1002, Loss: 5.729461193084717\n",
      "Epoch: 1, Batch: 1003, Loss: 5.462409019470215\n",
      "Epoch: 1, Batch: 1004, Loss: 5.947248935699463\n",
      "Epoch: 1, Batch: 1005, Loss: 5.5388712882995605\n",
      "Epoch: 1, Batch: 1006, Loss: 5.531764507293701\n",
      "Epoch: 1, Batch: 1007, Loss: 5.551257610321045\n",
      "Epoch: 1, Batch: 1008, Loss: 5.477875709533691\n",
      "Epoch: 1, Batch: 1009, Loss: 5.460637092590332\n",
      "Epoch: 1, Batch: 1010, Loss: 5.540036678314209\n",
      "Epoch: 1, Batch: 1011, Loss: 5.4700446128845215\n",
      "Epoch: 1, Batch: 1012, Loss: 5.543172836303711\n",
      "Epoch: 1, Batch: 1013, Loss: 5.520451545715332\n",
      "Epoch: 1, Batch: 1014, Loss: 5.436251640319824\n",
      "Epoch: 1, Batch: 1015, Loss: 5.407448768615723\n",
      "Epoch: 1, Batch: 1016, Loss: 5.550784111022949\n",
      "Epoch: 1, Batch: 1017, Loss: 5.324103355407715\n",
      "Epoch: 1, Batch: 1018, Loss: 5.656730651855469\n",
      "Epoch: 1, Batch: 1019, Loss: 5.5156097412109375\n",
      "Epoch: 1, Batch: 1020, Loss: 5.3195929527282715\n",
      "Epoch: 1, Batch: 1021, Loss: 5.4451799392700195\n",
      "Epoch: 1, Batch: 1022, Loss: 5.360629558563232\n",
      "Epoch: 1, Batch: 1023, Loss: 5.445667743682861\n",
      "Epoch: 1, Batch: 1024, Loss: 5.629268169403076\n",
      "Epoch: 1, Batch: 1025, Loss: 5.409204483032227\n",
      "Epoch: 1, Batch: 1026, Loss: 5.365139007568359\n",
      "Epoch: 1, Batch: 1027, Loss: 5.195892810821533\n",
      "Epoch: 1, Batch: 1028, Loss: 5.634313106536865\n",
      "Epoch: 1, Batch: 1029, Loss: 5.430294036865234\n",
      "Epoch: 1, Batch: 1030, Loss: 5.481411933898926\n",
      "Epoch: 1, Batch: 1031, Loss: 5.26631498336792\n",
      "Epoch: 1, Batch: 1032, Loss: 5.399435520172119\n",
      "Epoch: 1, Batch: 1033, Loss: 5.5169267654418945\n",
      "Epoch: 1, Batch: 1034, Loss: 5.3585124015808105\n",
      "Epoch: 1, Batch: 1035, Loss: 5.585409164428711\n",
      "Epoch: 1, Batch: 1036, Loss: 5.722174167633057\n",
      "Epoch: 1, Batch: 1037, Loss: 5.298076629638672\n",
      "Epoch: 1, Batch: 1038, Loss: 5.376222133636475\n",
      "Epoch: 1, Batch: 1039, Loss: 5.592215061187744\n",
      "Epoch: 1, Batch: 1040, Loss: 5.2800445556640625\n",
      "Epoch: 1, Batch: 1041, Loss: 5.339130401611328\n",
      "Epoch: 1, Batch: 1042, Loss: 5.384583473205566\n",
      "Epoch: 1, Batch: 1043, Loss: 5.465548515319824\n",
      "Epoch: 1, Batch: 1044, Loss: 5.48305082321167\n",
      "Epoch: 1, Batch: 1045, Loss: 5.277379035949707\n",
      "Epoch: 1, Batch: 1046, Loss: 5.748241901397705\n",
      "Epoch: 1, Batch: 1047, Loss: 5.025291442871094\n",
      "Epoch: 1, Batch: 1048, Loss: 5.25149393081665\n",
      "Epoch: 1, Batch: 1049, Loss: 5.453783988952637\n",
      "Epoch: 1, Batch: 1050, Loss: 5.865604877471924\n",
      "Epoch: 1, Batch: 1051, Loss: 5.589226722717285\n",
      "Epoch: 1, Batch: 1052, Loss: 5.4176836013793945\n",
      "Epoch: 1, Batch: 1053, Loss: 5.299294948577881\n",
      "Epoch: 1, Batch: 1054, Loss: 5.194452285766602\n",
      "Epoch: 1, Batch: 1055, Loss: 5.422287464141846\n",
      "Epoch: 1, Batch: 1056, Loss: 5.4720354080200195\n",
      "Epoch: 1, Batch: 1057, Loss: 5.433230876922607\n",
      "Epoch: 1, Batch: 1058, Loss: 5.591029644012451\n",
      "Epoch: 1, Batch: 1059, Loss: 5.272451400756836\n",
      "Epoch: 1, Batch: 1060, Loss: 5.373266696929932\n",
      "Epoch: 1, Batch: 1061, Loss: 5.523565769195557\n",
      "Epoch: 1, Batch: 1062, Loss: 5.3344950675964355\n",
      "Epoch: 1, Batch: 1063, Loss: 5.272427082061768\n",
      "Epoch: 1, Batch: 1064, Loss: 5.617110729217529\n",
      "Epoch: 1, Batch: 1065, Loss: 5.4106831550598145\n",
      "Epoch: 1, Batch: 1066, Loss: 5.448183059692383\n",
      "Epoch: 1, Batch: 1067, Loss: 5.365377426147461\n",
      "Epoch: 1, Batch: 1068, Loss: 5.33937931060791\n",
      "Epoch: 1, Batch: 1069, Loss: 5.385517120361328\n",
      "Epoch: 1, Batch: 1070, Loss: 5.479086399078369\n",
      "Epoch: 1, Batch: 1071, Loss: 5.616586685180664\n",
      "Epoch: 1, Batch: 1072, Loss: 5.54769229888916\n",
      "Epoch: 1, Batch: 1073, Loss: 5.283239841461182\n",
      "Epoch: 1, Batch: 1074, Loss: 5.143456935882568\n",
      "Epoch: 1, Batch: 1075, Loss: 5.471400737762451\n",
      "Epoch: 1, Batch: 1076, Loss: 5.2637739181518555\n",
      "Epoch: 1, Batch: 1077, Loss: 5.4402031898498535\n",
      "Epoch: 1, Batch: 1078, Loss: 5.495596885681152\n",
      "Epoch: 1, Batch: 1079, Loss: 5.482045650482178\n",
      "Epoch: 1, Batch: 1080, Loss: 5.483353137969971\n",
      "Epoch: 1, Batch: 1081, Loss: 5.382944583892822\n",
      "Epoch: 1, Batch: 1082, Loss: 5.31071662902832\n",
      "Epoch: 1, Batch: 1083, Loss: 5.35561466217041\n",
      "Epoch: 1, Batch: 1084, Loss: 5.6077680587768555\n",
      "Epoch: 1, Batch: 1085, Loss: 5.3089070320129395\n",
      "Epoch: 1, Batch: 1086, Loss: 5.422268390655518\n",
      "Epoch: 1, Batch: 1087, Loss: 5.383049011230469\n",
      "Epoch: 1, Batch: 1088, Loss: 5.892665863037109\n",
      "Epoch: 1, Batch: 1089, Loss: 5.548544406890869\n",
      "Epoch: 1, Batch: 1090, Loss: 5.2693867683410645\n",
      "Epoch: 1, Batch: 1091, Loss: 5.451696872711182\n",
      "Epoch: 1, Batch: 1092, Loss: 5.583846569061279\n",
      "Epoch: 1, Batch: 1093, Loss: 5.291069507598877\n",
      "Epoch: 1, Batch: 1094, Loss: 5.487358093261719\n",
      "Epoch: 1, Batch: 1095, Loss: 5.188486099243164\n",
      "Epoch: 1, Batch: 1096, Loss: 5.436339378356934\n",
      "Epoch: 1, Batch: 1097, Loss: 5.2976508140563965\n",
      "Epoch: 1, Batch: 1098, Loss: 5.555130481719971\n",
      "Epoch: 1, Batch: 1099, Loss: 5.363244533538818\n",
      "Epoch: 1, Batch: 1100, Loss: 5.313173770904541\n",
      "Epoch: 1, Batch: 1101, Loss: 5.347607612609863\n",
      "Epoch: 1, Batch: 1102, Loss: 5.468212604522705\n",
      "Epoch: 1, Batch: 1103, Loss: 5.393735885620117\n",
      "Epoch: 1, Batch: 1104, Loss: 5.819820880889893\n",
      "Epoch: 1, Batch: 1105, Loss: 5.418544769287109\n",
      "Epoch: 1, Batch: 1106, Loss: 5.104188442230225\n",
      "Epoch: 1, Batch: 1107, Loss: 4.952006816864014\n",
      "Epoch: 1, Batch: 1108, Loss: 5.4844489097595215\n",
      "Epoch: 1, Batch: 1109, Loss: 5.519377708435059\n",
      "Epoch: 1, Batch: 1110, Loss: 5.489873886108398\n",
      "Epoch: 1, Batch: 1111, Loss: 5.673695087432861\n",
      "Epoch: 1, Batch: 1112, Loss: 5.3257317543029785\n",
      "Epoch: 1, Batch: 1113, Loss: 5.1519083976745605\n",
      "Epoch: 1, Batch: 1114, Loss: 5.767797946929932\n",
      "Epoch: 1, Batch: 1115, Loss: 5.217253684997559\n",
      "Epoch: 1, Batch: 1116, Loss: 5.3359904289245605\n",
      "Epoch: 1, Batch: 1117, Loss: 5.409692287445068\n",
      "Epoch: 1, Batch: 1118, Loss: 5.291213512420654\n",
      "Epoch: 1, Batch: 1119, Loss: 5.272408962249756\n",
      "Epoch: 1, Batch: 1120, Loss: 5.362792015075684\n",
      "Epoch: 1, Batch: 1121, Loss: 5.56003475189209\n",
      "Epoch: 1, Batch: 1122, Loss: 5.6441802978515625\n",
      "Epoch: 1, Batch: 1123, Loss: 5.076807022094727\n",
      "Epoch: 1, Batch: 1124, Loss: 5.440273284912109\n",
      "Epoch: 1, Batch: 1125, Loss: 5.690732955932617\n",
      "Epoch: 1, Batch: 1126, Loss: 5.55165958404541\n",
      "Epoch: 1, Batch: 1127, Loss: 5.453425884246826\n",
      "Epoch: 1, Batch: 1128, Loss: 5.213971138000488\n",
      "Epoch: 1, Batch: 1129, Loss: 5.370225429534912\n",
      "Epoch: 1, Batch: 1130, Loss: 5.225134372711182\n",
      "Epoch: 1, Batch: 1131, Loss: 5.3072943687438965\n",
      "Epoch: 1, Batch: 1132, Loss: 5.5207672119140625\n",
      "Epoch: 1, Batch: 1133, Loss: 5.248302936553955\n",
      "Epoch: 1, Batch: 1134, Loss: 5.562229156494141\n",
      "Epoch: 1, Batch: 1135, Loss: 5.488620758056641\n",
      "Epoch: 1, Batch: 1136, Loss: 5.202333450317383\n",
      "Epoch: 1, Batch: 1137, Loss: 5.681241035461426\n",
      "Epoch: 1, Batch: 1138, Loss: 5.140176296234131\n",
      "Epoch: 1, Batch: 1139, Loss: 5.437128067016602\n",
      "Epoch: 1, Batch: 1140, Loss: 5.188563823699951\n",
      "Epoch: 1, Batch: 1141, Loss: 5.415421009063721\n",
      "Epoch: 1, Batch: 1142, Loss: 5.302597999572754\n",
      "Epoch: 1, Batch: 1143, Loss: 5.204717636108398\n",
      "Epoch: 1, Batch: 1144, Loss: 5.114368915557861\n",
      "Epoch: 1, Batch: 1145, Loss: 5.438037395477295\n",
      "Epoch: 1, Batch: 1146, Loss: 5.504866123199463\n",
      "Epoch: 1, Batch: 1147, Loss: 5.398422718048096\n",
      "Epoch: 1, Batch: 1148, Loss: 5.302674770355225\n",
      "Epoch: 1, Batch: 1149, Loss: 5.425542831420898\n",
      "Epoch: 1, Batch: 1150, Loss: 5.507089614868164\n",
      "Epoch: 1, Batch: 1151, Loss: 5.51358699798584\n",
      "Epoch: 1, Batch: 1152, Loss: 5.3470778465271\n",
      "Epoch: 1, Batch: 1153, Loss: 5.256442070007324\n",
      "Epoch: 1, Batch: 1154, Loss: 5.540788173675537\n",
      "Epoch: 1, Batch: 1155, Loss: 5.273950576782227\n",
      "Epoch: 1, Batch: 1156, Loss: 5.334805488586426\n",
      "Epoch: 1, Batch: 1157, Loss: 5.186132907867432\n",
      "Epoch: 1, Batch: 1158, Loss: 5.389521598815918\n",
      "Epoch: 1, Batch: 1159, Loss: 5.131770610809326\n",
      "Epoch: 1, Batch: 1160, Loss: 5.268582344055176\n",
      "Epoch: 1, Batch: 1161, Loss: 5.50733757019043\n",
      "Epoch: 1, Batch: 1162, Loss: 5.233621597290039\n",
      "Epoch: 1, Batch: 1163, Loss: 5.215361595153809\n",
      "Epoch: 1, Batch: 1164, Loss: 5.474329471588135\n",
      "Epoch: 1, Batch: 1165, Loss: 5.406612396240234\n",
      "Epoch: 1, Batch: 1166, Loss: 5.581545829772949\n",
      "Epoch: 1, Batch: 1167, Loss: 5.316423416137695\n",
      "Epoch: 1, Batch: 1168, Loss: 5.255609512329102\n",
      "Epoch: 1, Batch: 1169, Loss: 5.313448429107666\n",
      "Epoch: 1, Batch: 1170, Loss: 5.333489418029785\n",
      "Epoch: 1, Batch: 1171, Loss: 5.512862205505371\n",
      "Epoch: 1, Batch: 1172, Loss: 5.692194938659668\n",
      "Epoch: 1, Batch: 1173, Loss: 5.304467678070068\n",
      "Epoch: 1, Batch: 1174, Loss: 5.321599006652832\n",
      "Epoch: 1, Batch: 1175, Loss: 5.567794322967529\n",
      "Epoch: 1, Batch: 1176, Loss: 5.263684272766113\n",
      "Epoch: 1, Batch: 1177, Loss: 5.3543477058410645\n",
      "Epoch: 1, Batch: 1178, Loss: 5.44503927230835\n",
      "Epoch: 1, Batch: 1179, Loss: 5.389170169830322\n",
      "Epoch: 1, Batch: 1180, Loss: 5.19386100769043\n",
      "Epoch: 1, Batch: 1181, Loss: 5.315969467163086\n",
      "Epoch: 1, Batch: 1182, Loss: 5.343814849853516\n",
      "Epoch: 1, Batch: 1183, Loss: 5.725620269775391\n",
      "Epoch: 1, Batch: 1184, Loss: 5.332042694091797\n",
      "Epoch: 1, Batch: 1185, Loss: 5.213865280151367\n",
      "Epoch: 1, Batch: 1186, Loss: 5.588345050811768\n",
      "Epoch: 1, Batch: 1187, Loss: 5.503737449645996\n",
      "Epoch: 1, Batch: 1188, Loss: 5.3234052658081055\n",
      "Epoch: 1, Batch: 1189, Loss: 5.314046382904053\n",
      "Epoch: 1, Batch: 1190, Loss: 5.587245464324951\n",
      "Epoch: 1, Batch: 1191, Loss: 5.249475002288818\n",
      "Epoch: 1, Batch: 1192, Loss: 5.49473762512207\n",
      "Epoch: 1, Batch: 1193, Loss: 5.454921722412109\n",
      "Epoch: 1, Batch: 1194, Loss: 5.103235721588135\n",
      "Epoch: 1, Batch: 1195, Loss: 5.101025581359863\n",
      "Epoch: 1, Batch: 1196, Loss: 5.319723129272461\n",
      "Epoch: 1, Batch: 1197, Loss: 5.164061546325684\n",
      "Epoch: 1, Batch: 1198, Loss: 5.103781223297119\n",
      "Epoch: 1, Batch: 1199, Loss: 5.282468795776367\n",
      "Epoch: 1, Batch: 1200, Loss: 5.166220664978027\n",
      "Epoch: 1, Batch: 1201, Loss: 5.2590718269348145\n",
      "Epoch: 1, Batch: 1202, Loss: 5.2925238609313965\n",
      "Epoch: 1, Batch: 1203, Loss: 5.388380527496338\n",
      "Epoch: 1, Batch: 1204, Loss: 5.097390174865723\n",
      "Epoch: 1, Batch: 1205, Loss: 5.507033824920654\n",
      "Epoch: 1, Batch: 1206, Loss: 5.441339492797852\n",
      "Epoch: 1, Batch: 1207, Loss: 5.128457546234131\n",
      "Epoch: 1, Batch: 1208, Loss: 5.336616039276123\n",
      "Epoch: 1, Batch: 1209, Loss: 5.390747547149658\n",
      "Epoch: 1, Batch: 1210, Loss: 5.057135581970215\n",
      "Epoch: 1, Batch: 1211, Loss: 5.472945690155029\n",
      "Epoch: 1, Batch: 1212, Loss: 5.277415752410889\n",
      "Epoch: 1, Batch: 1213, Loss: 5.505256652832031\n",
      "Epoch: 1, Batch: 1214, Loss: 5.161144256591797\n",
      "Epoch: 1, Batch: 1215, Loss: 5.331027507781982\n",
      "Epoch: 1, Batch: 1216, Loss: 5.546220302581787\n",
      "Epoch: 1, Batch: 1217, Loss: 4.9888739585876465\n",
      "Epoch: 1, Batch: 1218, Loss: 5.457287788391113\n",
      "Epoch: 1, Batch: 1219, Loss: 5.229475975036621\n",
      "Epoch: 1, Batch: 1220, Loss: 5.1354193687438965\n",
      "Epoch: 1, Batch: 1221, Loss: 5.097284317016602\n",
      "Epoch: 1, Batch: 1222, Loss: 5.363900661468506\n",
      "Epoch: 1, Batch: 1223, Loss: 5.295212745666504\n",
      "Epoch: 1, Batch: 1224, Loss: 5.448525905609131\n",
      "Epoch: 1, Batch: 1225, Loss: 5.370589256286621\n",
      "Epoch: 1, Batch: 1226, Loss: 5.3796892166137695\n",
      "Epoch: 1, Batch: 1227, Loss: 5.419196605682373\n",
      "Epoch: 1, Batch: 1228, Loss: 5.13857364654541\n",
      "Epoch: 1, Batch: 1229, Loss: 5.512007713317871\n",
      "Epoch: 1, Batch: 1230, Loss: 5.101587295532227\n",
      "Epoch: 1, Batch: 1231, Loss: 5.330138683319092\n",
      "Epoch: 1, Batch: 1232, Loss: 5.438085556030273\n",
      "Epoch: 1, Batch: 1233, Loss: 5.382035255432129\n",
      "Epoch: 1, Batch: 1234, Loss: 5.422776222229004\n",
      "Epoch: 1, Batch: 1235, Loss: 5.349941730499268\n",
      "Epoch: 1, Batch: 1236, Loss: 5.291630268096924\n",
      "Epoch: 1, Batch: 1237, Loss: 5.177905082702637\n",
      "Epoch: 1, Batch: 1238, Loss: 5.441727638244629\n",
      "Epoch: 1, Batch: 1239, Loss: 5.257802486419678\n",
      "Epoch: 1, Batch: 1240, Loss: 5.424652099609375\n",
      "Epoch: 1, Batch: 1241, Loss: 5.31618070602417\n",
      "Epoch: 1, Batch: 1242, Loss: 5.328243732452393\n",
      "Epoch: 1, Batch: 1243, Loss: 5.254942893981934\n",
      "Epoch: 1, Batch: 1244, Loss: 5.089544296264648\n",
      "Epoch: 1, Batch: 1245, Loss: 5.295199871063232\n",
      "Epoch: 1, Batch: 1246, Loss: 5.1048808097839355\n",
      "Epoch: 1, Batch: 1247, Loss: 5.021798133850098\n",
      "Epoch: 1, Batch: 1248, Loss: 5.446742534637451\n",
      "Epoch: 1, Batch: 1249, Loss: 5.19728422164917\n",
      "Epoch: 1, Batch: 1250, Loss: 5.350787162780762\n",
      "Epoch: 1, Batch: 1251, Loss: 5.471136093139648\n",
      "Epoch: 1, Batch: 1252, Loss: 5.001676082611084\n",
      "Epoch: 1, Batch: 1253, Loss: 5.205859661102295\n",
      "Epoch: 1, Batch: 1254, Loss: 5.20263147354126\n",
      "Epoch: 1, Batch: 1255, Loss: 5.309258460998535\n",
      "Epoch: 1, Batch: 1256, Loss: 5.630594253540039\n",
      "Epoch: 1, Batch: 1257, Loss: 5.502894401550293\n",
      "Epoch: 1, Batch: 1258, Loss: 5.295678615570068\n",
      "Epoch: 1, Batch: 1259, Loss: 5.216547012329102\n",
      "Epoch: 1, Batch: 1260, Loss: 5.409244537353516\n",
      "Epoch: 1, Batch: 1261, Loss: 5.15023946762085\n",
      "Epoch: 1, Batch: 1262, Loss: 5.107972621917725\n",
      "Epoch: 1, Batch: 1263, Loss: 5.3120012283325195\n",
      "Epoch: 1, Batch: 1264, Loss: 5.228882312774658\n",
      "Epoch: 1, Batch: 1265, Loss: 5.230106830596924\n",
      "Epoch: 1, Batch: 1266, Loss: 5.400513648986816\n",
      "Epoch: 1, Batch: 1267, Loss: 5.250721454620361\n",
      "Epoch: 1, Batch: 1268, Loss: 5.228102684020996\n",
      "Epoch: 1, Batch: 1269, Loss: 5.2795209884643555\n",
      "Epoch: 1, Batch: 1270, Loss: 5.122835159301758\n",
      "Epoch: 1, Batch: 1271, Loss: 5.410640716552734\n",
      "Epoch: 1, Batch: 1272, Loss: 5.558605670928955\n",
      "Epoch: 1, Batch: 1273, Loss: 5.319063186645508\n",
      "Epoch: 1, Batch: 1274, Loss: 5.146911144256592\n",
      "Epoch: 1, Batch: 1275, Loss: 5.080833911895752\n",
      "Epoch: 1, Batch: 1276, Loss: 5.429779529571533\n",
      "Epoch: 1, Batch: 1277, Loss: 5.457381248474121\n",
      "Epoch: 1, Batch: 1278, Loss: 5.284854412078857\n",
      "Epoch: 1, Batch: 1279, Loss: 5.505794048309326\n",
      "Epoch: 1, Batch: 1280, Loss: 5.439427375793457\n",
      "Epoch: 1, Batch: 1281, Loss: 5.423532009124756\n",
      "Epoch: 1, Batch: 1282, Loss: 5.387568473815918\n",
      "Epoch: 1, Batch: 1283, Loss: 5.283212184906006\n",
      "Epoch: 1, Batch: 1284, Loss: 5.098805904388428\n",
      "Epoch: 1, Batch: 1285, Loss: 5.497180461883545\n",
      "Epoch: 1, Batch: 1286, Loss: 5.2534613609313965\n",
      "Epoch: 1, Batch: 1287, Loss: 5.067988872528076\n",
      "Epoch: 1, Batch: 1288, Loss: 5.270029544830322\n",
      "Epoch: 1, Batch: 1289, Loss: 5.2148823738098145\n",
      "Epoch: 1, Batch: 1290, Loss: 5.190333843231201\n",
      "Epoch: 1, Batch: 1291, Loss: 5.486750602722168\n",
      "Epoch: 1, Batch: 1292, Loss: 5.347206115722656\n",
      "Epoch: 1, Batch: 1293, Loss: 5.302481651306152\n",
      "Epoch: 1, Batch: 1294, Loss: 5.340060234069824\n",
      "Epoch: 1, Batch: 1295, Loss: 5.176390171051025\n",
      "Epoch: 1, Batch: 1296, Loss: 5.162306785583496\n",
      "Epoch: 1, Batch: 1297, Loss: 5.307284832000732\n",
      "Epoch: 1, Batch: 1298, Loss: 5.32821798324585\n",
      "Epoch: 1, Batch: 1299, Loss: 5.277487754821777\n",
      "Epoch: 1, Batch: 1300, Loss: 5.061915397644043\n",
      "Epoch: 1, Batch: 1301, Loss: 5.102175235748291\n",
      "Epoch: 1, Batch: 1302, Loss: 5.410388946533203\n",
      "Epoch: 1, Batch: 1303, Loss: 5.567124843597412\n",
      "Epoch: 1, Batch: 1304, Loss: 5.0971360206604\n",
      "Epoch: 1, Batch: 1305, Loss: 5.474897384643555\n",
      "Epoch: 1, Batch: 1306, Loss: 5.520290374755859\n",
      "Epoch: 1, Batch: 1307, Loss: 5.241405010223389\n",
      "Epoch: 1, Batch: 1308, Loss: 5.388184547424316\n",
      "Epoch: 1, Batch: 1309, Loss: 5.301548480987549\n",
      "Epoch: 1, Batch: 1310, Loss: 5.329235076904297\n",
      "Epoch: 1, Batch: 1311, Loss: 5.580955982208252\n",
      "Epoch: 1, Batch: 1312, Loss: 5.114925861358643\n",
      "Epoch: 1, Batch: 1313, Loss: 5.703566551208496\n",
      "Epoch: 1, Batch: 1314, Loss: 5.423003673553467\n",
      "Epoch: 1, Batch: 1315, Loss: 5.166008949279785\n",
      "Epoch: 1, Batch: 1316, Loss: 5.2726287841796875\n",
      "Epoch: 1, Batch: 1317, Loss: 5.186894416809082\n",
      "Epoch: 1, Batch: 1318, Loss: 5.091727256774902\n",
      "Epoch: 1, Batch: 1319, Loss: 5.094122409820557\n",
      "Epoch: 1, Batch: 1320, Loss: 5.553436279296875\n",
      "Epoch: 1, Batch: 1321, Loss: 5.235684871673584\n",
      "Epoch: 1, Batch: 1322, Loss: 5.239156723022461\n",
      "Epoch: 1, Batch: 1323, Loss: 5.1313652992248535\n",
      "Epoch: 1, Batch: 1324, Loss: 5.369136810302734\n",
      "Epoch: 1, Batch: 1325, Loss: 5.268899440765381\n",
      "Epoch: 1, Batch: 1326, Loss: 5.251358985900879\n",
      "Epoch: 1, Batch: 1327, Loss: 5.347308158874512\n",
      "Epoch: 1, Batch: 1328, Loss: 5.201387882232666\n",
      "Epoch: 1, Batch: 1329, Loss: 5.168872833251953\n",
      "Epoch: 1, Batch: 1330, Loss: 5.23051118850708\n",
      "Epoch: 1, Batch: 1331, Loss: 5.266383647918701\n",
      "Epoch: 1, Batch: 1332, Loss: 5.3815531730651855\n",
      "Epoch: 1, Batch: 1333, Loss: 5.135760307312012\n",
      "Epoch: 1, Batch: 1334, Loss: 5.389583587646484\n",
      "Epoch: 1, Batch: 1335, Loss: 5.58581018447876\n",
      "Epoch: 1, Batch: 1336, Loss: 5.29685115814209\n",
      "Epoch: 1, Batch: 1337, Loss: 4.9816107749938965\n",
      "Epoch: 1, Batch: 1338, Loss: 5.319192409515381\n",
      "Epoch: 1, Batch: 1339, Loss: 5.285235404968262\n",
      "Epoch: 1, Batch: 1340, Loss: 5.066510200500488\n",
      "Epoch: 1, Batch: 1341, Loss: 5.273013591766357\n",
      "Epoch: 1, Batch: 1342, Loss: 5.189880847930908\n",
      "Epoch: 1, Batch: 1343, Loss: 5.052988052368164\n",
      "Epoch: 1, Batch: 1344, Loss: 5.16427755355835\n",
      "Epoch: 1, Batch: 1345, Loss: 5.206172943115234\n",
      "Epoch: 1, Batch: 1346, Loss: 5.369347095489502\n",
      "Epoch: 1, Batch: 1347, Loss: 5.424670696258545\n",
      "Epoch: 1, Batch: 1348, Loss: 5.287064075469971\n",
      "Epoch: 1, Batch: 1349, Loss: 5.193769454956055\n",
      "Epoch: 1, Batch: 1350, Loss: 5.150173187255859\n",
      "Epoch: 1, Batch: 1351, Loss: 5.118043899536133\n",
      "Epoch: 1, Batch: 1352, Loss: 5.153371810913086\n",
      "Epoch: 1, Batch: 1353, Loss: 5.287229061126709\n",
      "Epoch: 1, Batch: 1354, Loss: 5.310944080352783\n",
      "Epoch: 1, Batch: 1355, Loss: 5.465991497039795\n",
      "Epoch: 1, Batch: 1356, Loss: 5.338334560394287\n",
      "Epoch: 1, Batch: 1357, Loss: 5.217065811157227\n",
      "Epoch: 1, Batch: 1358, Loss: 5.305007457733154\n",
      "Epoch: 1, Batch: 1359, Loss: 5.127596855163574\n",
      "Epoch: 1, Batch: 1360, Loss: 5.471551895141602\n",
      "Epoch: 1, Batch: 1361, Loss: 5.303779602050781\n",
      "Epoch: 1, Batch: 1362, Loss: 5.18023157119751\n",
      "Epoch: 1, Batch: 1363, Loss: 5.460971832275391\n",
      "Epoch: 1, Batch: 1364, Loss: 5.080236434936523\n",
      "Epoch: 1, Batch: 1365, Loss: 5.251231670379639\n",
      "Epoch: 1, Batch: 1366, Loss: 4.987045764923096\n",
      "Epoch: 1, Batch: 1367, Loss: 5.239433765411377\n",
      "Epoch: 1, Batch: 1368, Loss: 5.4282732009887695\n",
      "Epoch: 1, Batch: 1369, Loss: 5.109914302825928\n",
      "Epoch: 1, Batch: 1370, Loss: 5.4035325050354\n",
      "Epoch: 1, Batch: 1371, Loss: 5.130156993865967\n",
      "Epoch: 1, Batch: 1372, Loss: 5.095376491546631\n",
      "Epoch: 1, Batch: 1373, Loss: 5.4394965171813965\n",
      "Epoch: 1, Batch: 1374, Loss: 4.98451566696167\n",
      "Epoch: 1, Batch: 1375, Loss: 5.217432498931885\n",
      "Epoch: 1, Batch: 1376, Loss: 5.011866569519043\n",
      "Epoch: 1, Batch: 1377, Loss: 5.195043563842773\n",
      "Epoch: 1, Batch: 1378, Loss: 5.146158695220947\n",
      "Epoch: 1, Batch: 1379, Loss: 4.975428581237793\n",
      "Epoch: 1, Batch: 1380, Loss: 5.2683234214782715\n",
      "Epoch: 1, Batch: 1381, Loss: 5.462085723876953\n",
      "Epoch: 1, Batch: 1382, Loss: 5.165493011474609\n",
      "Epoch: 1, Batch: 1383, Loss: 4.992007255554199\n",
      "Epoch: 1, Batch: 1384, Loss: 5.308047771453857\n",
      "Epoch: 1, Batch: 1385, Loss: 4.814876556396484\n",
      "Epoch: 1, Batch: 1386, Loss: 5.168787002563477\n",
      "Epoch: 1, Batch: 1387, Loss: 5.170975208282471\n",
      "Epoch: 1, Batch: 1388, Loss: 5.349571704864502\n",
      "Epoch: 1, Batch: 1389, Loss: 5.220794677734375\n",
      "Epoch: 1, Batch: 1390, Loss: 5.098876953125\n",
      "Epoch: 1, Batch: 1391, Loss: 5.02188777923584\n",
      "Epoch: 1, Batch: 1392, Loss: 5.410157680511475\n",
      "Epoch: 1, Batch: 1393, Loss: 5.341211318969727\n",
      "Epoch: 1, Batch: 1394, Loss: 5.172216892242432\n",
      "Epoch: 1, Batch: 1395, Loss: 5.106251239776611\n",
      "Epoch: 1, Batch: 1396, Loss: 5.201912879943848\n",
      "Epoch: 1, Batch: 1397, Loss: 5.3615498542785645\n",
      "Epoch: 1, Batch: 1398, Loss: 5.121611595153809\n",
      "Epoch: 1, Batch: 1399, Loss: 5.0686187744140625\n",
      "Epoch: 1, Batch: 1400, Loss: 5.236695766448975\n",
      "Epoch: 1, Batch: 1401, Loss: 5.150857448577881\n",
      "Epoch: 1, Batch: 1402, Loss: 5.216088771820068\n",
      "Epoch: 1, Batch: 1403, Loss: 5.352817535400391\n",
      "Epoch: 1, Batch: 1404, Loss: 5.157955169677734\n",
      "Epoch: 1, Batch: 1405, Loss: 5.487030506134033\n",
      "Epoch: 1, Batch: 1406, Loss: 5.351968288421631\n",
      "Epoch: 1, Batch: 1407, Loss: 5.208954811096191\n",
      "Epoch: 1, Batch: 1408, Loss: 5.269217014312744\n",
      "Epoch: 1, Batch: 1409, Loss: 5.375983238220215\n",
      "Epoch: 1, Batch: 1410, Loss: 5.51759147644043\n",
      "Epoch: 1, Batch: 1411, Loss: 5.059325218200684\n",
      "Epoch: 1, Batch: 1412, Loss: 5.433088302612305\n",
      "Epoch: 1, Batch: 1413, Loss: 5.235586166381836\n",
      "Epoch: 1, Batch: 1414, Loss: 5.403782844543457\n",
      "Epoch: 1, Batch: 1415, Loss: 5.206634998321533\n",
      "Epoch: 1, Batch: 1416, Loss: 5.419650554656982\n",
      "Epoch: 1, Batch: 1417, Loss: 5.377684593200684\n",
      "Epoch: 1, Batch: 1418, Loss: 5.260491847991943\n",
      "Epoch: 1, Batch: 1419, Loss: 5.030937671661377\n",
      "Epoch: 1, Batch: 1420, Loss: 4.982865333557129\n",
      "Epoch: 1, Batch: 1421, Loss: 5.0629191398620605\n",
      "Epoch: 1, Batch: 1422, Loss: 5.367854595184326\n",
      "Epoch: 1, Batch: 1423, Loss: 5.054706573486328\n",
      "Epoch: 1, Batch: 1424, Loss: 5.246329307556152\n",
      "Epoch: 1, Batch: 1425, Loss: 5.338768005371094\n",
      "Epoch: 1, Batch: 1426, Loss: 5.293317794799805\n",
      "Epoch: 1, Batch: 1427, Loss: 5.5136189460754395\n",
      "Epoch: 1, Batch: 1428, Loss: 5.547962665557861\n",
      "Epoch: 1, Batch: 1429, Loss: 5.017641067504883\n",
      "Epoch: 1, Batch: 1430, Loss: 5.281257152557373\n",
      "Epoch: 1, Batch: 1431, Loss: 5.161623477935791\n",
      "Epoch: 1, Batch: 1432, Loss: 5.198910713195801\n",
      "Epoch: 1, Batch: 1433, Loss: 5.233587265014648\n",
      "Epoch: 1, Batch: 1434, Loss: 5.066802501678467\n",
      "Epoch: 1, Batch: 1435, Loss: 5.021731853485107\n",
      "Epoch: 1, Batch: 1436, Loss: 5.084209442138672\n",
      "Epoch: 1, Batch: 1437, Loss: 5.17222785949707\n",
      "Epoch: 1, Batch: 1438, Loss: 4.93143367767334\n",
      "Epoch: 1, Batch: 1439, Loss: 4.952691555023193\n",
      "Epoch: 1, Batch: 1440, Loss: 5.16174840927124\n",
      "Epoch: 1, Batch: 1441, Loss: 5.187083721160889\n",
      "Epoch: 1, Batch: 1442, Loss: 5.348055839538574\n",
      "Epoch: 1, Batch: 1443, Loss: 5.193456649780273\n",
      "Epoch: 1, Batch: 1444, Loss: 5.248481273651123\n",
      "Epoch: 1, Batch: 1445, Loss: 4.95403528213501\n",
      "Epoch: 1, Batch: 1446, Loss: 5.020595073699951\n",
      "Epoch: 1, Batch: 1447, Loss: 5.408836841583252\n",
      "Epoch: 1, Batch: 1448, Loss: 5.311074733734131\n",
      "Epoch: 1, Batch: 1449, Loss: 5.383965969085693\n",
      "Epoch: 1, Batch: 1450, Loss: 4.967970848083496\n",
      "Epoch: 1, Batch: 1451, Loss: 5.30282735824585\n",
      "Epoch: 1, Batch: 1452, Loss: 5.232039928436279\n",
      "Epoch: 1, Batch: 1453, Loss: 5.102493762969971\n",
      "Epoch: 1, Batch: 1454, Loss: 5.129056930541992\n",
      "Epoch: 1, Batch: 1455, Loss: 5.088066101074219\n",
      "Epoch: 1, Batch: 1456, Loss: 5.1602935791015625\n",
      "Epoch: 1, Batch: 1457, Loss: 4.71017599105835\n",
      "Epoch: 1, Batch: 1458, Loss: 4.914580345153809\n",
      "Epoch: 1, Batch: 1459, Loss: 5.179083347320557\n",
      "Epoch: 1, Batch: 1460, Loss: 5.004628658294678\n",
      "Epoch: 1, Batch: 1461, Loss: 4.94960880279541\n",
      "Epoch: 1, Batch: 1462, Loss: 5.263512134552002\n",
      "Epoch: 1, Batch: 1463, Loss: 5.131991386413574\n",
      "Epoch: 1, Batch: 1464, Loss: 5.221823215484619\n",
      "Epoch: 1, Batch: 1465, Loss: 4.995989799499512\n",
      "Epoch: 1, Batch: 1466, Loss: 5.535665035247803\n",
      "Epoch: 1, Batch: 1467, Loss: 5.138336658477783\n",
      "Epoch: 1, Batch: 1468, Loss: 5.051245212554932\n",
      "Epoch: 1, Batch: 1469, Loss: 5.136176586151123\n",
      "Epoch: 1, Batch: 1470, Loss: 5.085689067840576\n",
      "Epoch: 1, Batch: 1471, Loss: 5.118473052978516\n",
      "Epoch: 1, Batch: 1472, Loss: 5.384882926940918\n",
      "Epoch: 1, Batch: 1473, Loss: 5.3088059425354\n",
      "Epoch: 1, Batch: 1474, Loss: 5.261877536773682\n",
      "Epoch: 1, Batch: 1475, Loss: 5.358238220214844\n",
      "Epoch: 1, Batch: 1476, Loss: 5.156295299530029\n",
      "Epoch: 1, Batch: 1477, Loss: 5.188586711883545\n",
      "Epoch: 1, Batch: 1478, Loss: 4.994063854217529\n",
      "Epoch: 1, Batch: 1479, Loss: 5.213191986083984\n",
      "Epoch: 1, Batch: 1480, Loss: 4.808323383331299\n",
      "Epoch: 1, Batch: 1481, Loss: 5.180946350097656\n",
      "Epoch: 1, Batch: 1482, Loss: 5.023388385772705\n",
      "Epoch: 1, Batch: 1483, Loss: 5.407322406768799\n",
      "Epoch: 1, Batch: 1484, Loss: 5.103610515594482\n",
      "Epoch: 1, Batch: 1485, Loss: 4.994073390960693\n",
      "Epoch: 1, Batch: 1486, Loss: 4.999606132507324\n",
      "Epoch: 1, Batch: 1487, Loss: 5.306610584259033\n",
      "Epoch: 1, Batch: 1488, Loss: 5.135785102844238\n",
      "Epoch: 1, Batch: 1489, Loss: 5.143911361694336\n",
      "Epoch: 1, Batch: 1490, Loss: 5.196935653686523\n",
      "Epoch: 1, Batch: 1491, Loss: 5.240115165710449\n",
      "Epoch: 1, Batch: 1492, Loss: 5.524898529052734\n",
      "Epoch: 1, Batch: 1493, Loss: 5.353277683258057\n",
      "Epoch: 1, Batch: 1494, Loss: 4.968832492828369\n",
      "Epoch: 1, Batch: 1495, Loss: 4.920022964477539\n",
      "Epoch: 1, Batch: 1496, Loss: 5.076475143432617\n",
      "Epoch: 1, Batch: 1497, Loss: 5.211662769317627\n",
      "Epoch: 1, Batch: 1498, Loss: 5.031398296356201\n",
      "Epoch: 1, Batch: 1499, Loss: 5.230536460876465\n",
      "Epoch: 1, Batch: 1500, Loss: 5.4720964431762695\n",
      "Epoch: 1, Batch: 1501, Loss: 5.201897144317627\n",
      "Epoch: 1, Batch: 1502, Loss: 5.201315402984619\n",
      "Epoch: 1, Batch: 1503, Loss: 4.881361484527588\n",
      "Epoch: 1, Batch: 1504, Loss: 5.308328628540039\n",
      "Epoch: 1, Batch: 1505, Loss: 5.2995758056640625\n",
      "Epoch: 1, Batch: 1506, Loss: 5.273106098175049\n",
      "Epoch: 1, Batch: 1507, Loss: 5.218867301940918\n",
      "Epoch: 1, Batch: 1508, Loss: 4.990410327911377\n",
      "Epoch: 1, Batch: 1509, Loss: 4.923526763916016\n",
      "Epoch: 1, Batch: 1510, Loss: 5.216604232788086\n",
      "Epoch: 1, Batch: 1511, Loss: 5.198554992675781\n",
      "Epoch: 1, Batch: 1512, Loss: 5.645648956298828\n",
      "Epoch: 1, Batch: 1513, Loss: 5.213142395019531\n",
      "Epoch: 1, Batch: 1514, Loss: 5.030135154724121\n",
      "Epoch: 1, Batch: 1515, Loss: 5.124783992767334\n",
      "Epoch: 1, Batch: 1516, Loss: 5.065953254699707\n",
      "Epoch: 1, Batch: 1517, Loss: 5.0594401359558105\n",
      "Epoch: 1, Batch: 1518, Loss: 5.4030256271362305\n",
      "Epoch: 1, Batch: 1519, Loss: 5.160979270935059\n",
      "Epoch: 1, Batch: 1520, Loss: 5.036046028137207\n",
      "Epoch: 1, Batch: 1521, Loss: 5.340941429138184\n",
      "Epoch: 1, Batch: 1522, Loss: 5.387243747711182\n",
      "Epoch: 1, Batch: 1523, Loss: 5.355492115020752\n",
      "Epoch: 1, Batch: 1524, Loss: 5.152002334594727\n",
      "Epoch: 1, Batch: 1525, Loss: 4.7517595291137695\n",
      "Epoch: 1, Batch: 1526, Loss: 5.018320083618164\n",
      "Epoch: 1, Batch: 1527, Loss: 5.290635108947754\n",
      "Epoch: 1, Batch: 1528, Loss: 5.00924825668335\n",
      "Epoch: 1, Batch: 1529, Loss: 5.206329345703125\n",
      "Epoch: 1, Batch: 1530, Loss: 5.25210428237915\n",
      "Epoch: 1, Batch: 1531, Loss: 5.033735275268555\n",
      "Epoch: 1, Batch: 1532, Loss: 5.24964714050293\n",
      "Epoch: 1, Batch: 1533, Loss: 4.9490742683410645\n",
      "Epoch: 1, Batch: 1534, Loss: 5.1380109786987305\n",
      "Epoch: 1, Batch: 1535, Loss: 5.225170612335205\n",
      "Epoch: 1, Batch: 1536, Loss: 5.4043684005737305\n",
      "Epoch: 1, Batch: 1537, Loss: 5.379286766052246\n",
      "Epoch: 1, Batch: 1538, Loss: 5.215083599090576\n",
      "Epoch: 1, Batch: 1539, Loss: 5.088109493255615\n",
      "Epoch: 1, Batch: 1540, Loss: 5.152230262756348\n",
      "Epoch: 1, Batch: 1541, Loss: 5.4320855140686035\n",
      "Epoch: 1, Batch: 1542, Loss: 4.937615871429443\n",
      "Epoch: 1, Batch: 1543, Loss: 5.000634670257568\n",
      "Epoch: 1, Batch: 1544, Loss: 5.192121982574463\n",
      "Epoch: 1, Batch: 1545, Loss: 5.384307861328125\n",
      "Epoch: 1, Batch: 1546, Loss: 5.293874263763428\n",
      "Epoch: 1, Batch: 1547, Loss: 5.099837303161621\n",
      "Epoch: 1, Batch: 1548, Loss: 5.139959335327148\n",
      "Epoch: 1, Batch: 1549, Loss: 5.129774570465088\n",
      "Epoch: 1, Batch: 1550, Loss: 4.930619716644287\n",
      "Epoch: 1, Batch: 1551, Loss: 5.147228240966797\n",
      "Epoch: 1, Batch: 1552, Loss: 5.270061016082764\n",
      "Epoch: 1, Batch: 1553, Loss: 4.889402866363525\n",
      "Epoch: 1, Batch: 1554, Loss: 5.061794281005859\n",
      "Epoch: 1, Batch: 1555, Loss: 5.24945068359375\n",
      "Epoch: 1, Batch: 1556, Loss: 5.364741325378418\n",
      "Epoch: 1, Batch: 1557, Loss: 5.242290019989014\n",
      "Epoch: 1, Batch: 1558, Loss: 5.230378150939941\n",
      "Epoch: 1, Batch: 1559, Loss: 5.062842845916748\n",
      "Epoch: 1, Batch: 1560, Loss: 4.975444793701172\n",
      "Epoch: 1, Batch: 1561, Loss: 5.2208781242370605\n",
      "Epoch: 1, Batch: 1562, Loss: 5.181299686431885\n",
      "Epoch: 1, Batch: 1563, Loss: 5.219342231750488\n",
      "Epoch: 1, Batch: 1564, Loss: 5.237683296203613\n",
      "Epoch: 1, Batch: 1565, Loss: 5.46380090713501\n",
      "Epoch: 1, Batch: 1566, Loss: 5.421681880950928\n",
      "Epoch: 1, Batch: 1567, Loss: 5.082986354827881\n",
      "Epoch: 1, Batch: 1568, Loss: 5.092268943786621\n",
      "Epoch: 1, Batch: 1569, Loss: 5.179484844207764\n",
      "Epoch: 1, Batch: 1570, Loss: 5.009493350982666\n",
      "Epoch: 1, Batch: 1571, Loss: 4.989496231079102\n",
      "Epoch: 1, Batch: 1572, Loss: 4.831768989562988\n",
      "Epoch: 1, Batch: 1573, Loss: 5.19800329208374\n",
      "Epoch: 1, Batch: 1574, Loss: 5.088744640350342\n",
      "Epoch: 1, Batch: 1575, Loss: 5.151417255401611\n",
      "Epoch: 1, Batch: 1576, Loss: 4.954787731170654\n",
      "Epoch: 1, Batch: 1577, Loss: 5.1071672439575195\n",
      "Epoch: 1, Batch: 1578, Loss: 5.1743388175964355\n",
      "Epoch: 1, Batch: 1579, Loss: 5.51157808303833\n",
      "Epoch: 1, Batch: 1580, Loss: 5.127554893493652\n",
      "Epoch: 1, Batch: 1581, Loss: 5.05192232131958\n",
      "Epoch: 1, Batch: 1582, Loss: 5.210580825805664\n",
      "Epoch: 1, Batch: 1583, Loss: 5.13569450378418\n",
      "Epoch: 1, Batch: 1584, Loss: 5.069497108459473\n",
      "Epoch: 1, Batch: 1585, Loss: 5.365868091583252\n",
      "Epoch: 1, Batch: 1586, Loss: 5.059638500213623\n",
      "Epoch: 1, Batch: 1587, Loss: 4.760318756103516\n",
      "Epoch: 1, Batch: 1588, Loss: 5.120851516723633\n",
      "Epoch: 1, Batch: 1589, Loss: 4.962068557739258\n",
      "Epoch: 1, Batch: 1590, Loss: 5.303579807281494\n",
      "Epoch: 1, Batch: 1591, Loss: 5.204837322235107\n",
      "Epoch: 1, Batch: 1592, Loss: 5.311124324798584\n",
      "Epoch: 1, Batch: 1593, Loss: 5.024353981018066\n",
      "Epoch: 1, Batch: 1594, Loss: 5.328352451324463\n",
      "Epoch: 1, Batch: 1595, Loss: 5.129706382751465\n",
      "Epoch: 1, Batch: 1596, Loss: 4.9966721534729\n",
      "Epoch: 1, Batch: 1597, Loss: 4.742564678192139\n",
      "Epoch: 1, Batch: 1598, Loss: 5.3041791915893555\n",
      "Epoch: 1, Batch: 1599, Loss: 5.139786243438721\n",
      "Epoch: 1, Batch: 1600, Loss: 5.545608043670654\n",
      "Epoch: 1, Batch: 1601, Loss: 5.425164699554443\n",
      "Epoch: 1, Batch: 1602, Loss: 5.060346603393555\n",
      "Epoch: 1, Batch: 1603, Loss: 5.173432350158691\n",
      "Epoch: 1, Batch: 1604, Loss: 5.181676864624023\n",
      "Epoch: 1, Batch: 1605, Loss: 5.385356426239014\n",
      "Epoch: 1, Batch: 1606, Loss: 5.101818084716797\n",
      "Epoch: 1, Batch: 1607, Loss: 5.06836462020874\n",
      "Epoch: 1, Batch: 1608, Loss: 5.009664535522461\n",
      "Epoch: 1, Batch: 1609, Loss: 4.90866756439209\n",
      "Epoch: 1, Batch: 1610, Loss: 5.1679840087890625\n",
      "Epoch: 1, Batch: 1611, Loss: 4.920313835144043\n",
      "Epoch: 1, Batch: 1612, Loss: 5.286381721496582\n",
      "Epoch: 1, Batch: 1613, Loss: 5.195894241333008\n",
      "Epoch: 1, Batch: 1614, Loss: 5.447646617889404\n",
      "Epoch: 1, Batch: 1615, Loss: 5.105716228485107\n",
      "Epoch: 1, Batch: 1616, Loss: 5.157871246337891\n",
      "Epoch: 1, Batch: 1617, Loss: 4.939948081970215\n",
      "Epoch: 1, Batch: 1618, Loss: 4.990894317626953\n",
      "Epoch: 1, Batch: 1619, Loss: 5.035531520843506\n",
      "Epoch: 1, Batch: 1620, Loss: 5.229449272155762\n",
      "Epoch: 1, Batch: 1621, Loss: 4.958980083465576\n",
      "Epoch: 1, Batch: 1622, Loss: 5.083059310913086\n",
      "Epoch: 1, Batch: 1623, Loss: 4.910091876983643\n",
      "Epoch: 1, Batch: 1624, Loss: 5.142766952514648\n",
      "Epoch: 1, Batch: 1625, Loss: 5.142926216125488\n",
      "Epoch: 1, Batch: 1626, Loss: 5.074368953704834\n",
      "Epoch: 1, Batch: 1627, Loss: 5.264913082122803\n",
      "Epoch: 1, Batch: 1628, Loss: 5.107608318328857\n",
      "Epoch: 1, Batch: 1629, Loss: 5.204309940338135\n",
      "Epoch: 1, Batch: 1630, Loss: 5.035101413726807\n",
      "Epoch: 1, Batch: 1631, Loss: 5.108233451843262\n",
      "Epoch: 1, Batch: 1632, Loss: 4.913546085357666\n",
      "Epoch: 1, Batch: 1633, Loss: 4.9712958335876465\n",
      "Epoch: 1, Batch: 1634, Loss: 5.174328804016113\n",
      "Epoch: 1, Batch: 1635, Loss: 4.883816242218018\n",
      "Epoch: 1, Batch: 1636, Loss: 5.088990211486816\n",
      "Epoch: 1, Batch: 1637, Loss: 5.084817409515381\n",
      "Epoch: 1, Batch: 1638, Loss: 4.967379093170166\n",
      "Epoch: 1, Batch: 1639, Loss: 5.344447612762451\n",
      "Epoch: 1, Batch: 1640, Loss: 5.173591136932373\n",
      "Epoch: 1, Batch: 1641, Loss: 5.123987197875977\n",
      "Epoch: 1, Batch: 1642, Loss: 5.092428207397461\n",
      "Epoch: 1, Batch: 1643, Loss: 4.970848083496094\n",
      "Epoch: 1, Batch: 1644, Loss: 5.10983943939209\n",
      "Epoch: 1, Batch: 1645, Loss: 4.87972354888916\n",
      "Epoch: 1, Batch: 1646, Loss: 5.218075275421143\n",
      "Epoch: 1, Batch: 1647, Loss: 4.9565815925598145\n",
      "Epoch: 1, Batch: 1648, Loss: 5.069832801818848\n",
      "Epoch: 1, Batch: 1649, Loss: 5.239043235778809\n",
      "Epoch: 1, Batch: 1650, Loss: 5.153692722320557\n",
      "Epoch: 1, Batch: 1651, Loss: 5.185070514678955\n",
      "Epoch: 1, Batch: 1652, Loss: 5.3320393562316895\n",
      "Epoch: 1, Batch: 1653, Loss: 4.889729022979736\n",
      "Epoch: 1, Batch: 1654, Loss: 5.096431255340576\n",
      "Epoch: 1, Batch: 1655, Loss: 5.235358238220215\n",
      "Epoch: 1, Batch: 1656, Loss: 5.125219345092773\n",
      "Epoch: 1, Batch: 1657, Loss: 5.0908613204956055\n",
      "Epoch: 1, Batch: 1658, Loss: 5.417659282684326\n",
      "Epoch: 1, Batch: 1659, Loss: 5.165823936462402\n",
      "Epoch: 1, Batch: 1660, Loss: 4.982940196990967\n",
      "Epoch: 1, Batch: 1661, Loss: 5.0723395347595215\n",
      "Epoch: 1, Batch: 1662, Loss: 5.006059169769287\n",
      "Epoch: 1, Batch: 1663, Loss: 5.212867736816406\n",
      "Epoch: 1, Batch: 1664, Loss: 5.2605509757995605\n",
      "Epoch: 1, Batch: 1665, Loss: 4.927378177642822\n",
      "Epoch: 1, Batch: 1666, Loss: 5.014700889587402\n",
      "Epoch: 1, Batch: 1667, Loss: 4.845189571380615\n",
      "Epoch: 1, Batch: 1668, Loss: 5.219479084014893\n",
      "Epoch: 1, Batch: 1669, Loss: 5.124809265136719\n",
      "Epoch: 1, Batch: 1670, Loss: 5.156123638153076\n",
      "Epoch: 1, Batch: 1671, Loss: 5.100062847137451\n",
      "Epoch: 1, Batch: 1672, Loss: 4.9470086097717285\n",
      "Epoch: 1, Batch: 1673, Loss: 5.013881206512451\n",
      "Epoch: 1, Batch: 1674, Loss: 5.020637035369873\n",
      "Epoch: 1, Batch: 1675, Loss: 4.981749057769775\n",
      "Epoch: 1, Batch: 1676, Loss: 4.901670455932617\n",
      "Epoch: 1, Batch: 1677, Loss: 5.036742687225342\n",
      "Epoch: 1, Batch: 1678, Loss: 5.10124397277832\n",
      "Epoch: 1, Batch: 1679, Loss: 4.9739556312561035\n",
      "Epoch: 1, Batch: 1680, Loss: 5.126885414123535\n",
      "Epoch: 1, Batch: 1681, Loss: 5.014158248901367\n",
      "Epoch: 1, Batch: 1682, Loss: 5.088397979736328\n",
      "Epoch: 1, Batch: 1683, Loss: 5.267073631286621\n",
      "Epoch: 1, Batch: 1684, Loss: 5.104902744293213\n",
      "Epoch: 1, Batch: 1685, Loss: 5.052786350250244\n",
      "Epoch: 1, Batch: 1686, Loss: 5.037683010101318\n",
      "Epoch: 1, Batch: 1687, Loss: 4.867543697357178\n",
      "Epoch: 1, Batch: 1688, Loss: 5.038303375244141\n",
      "Epoch: 1, Batch: 1689, Loss: 5.106314659118652\n",
      "Epoch: 1, Batch: 1690, Loss: 5.344644069671631\n",
      "Epoch: 1, Batch: 1691, Loss: 5.323291301727295\n",
      "Epoch: 1, Batch: 1692, Loss: 5.012879848480225\n",
      "Epoch: 1, Batch: 1693, Loss: 4.938451766967773\n",
      "Epoch: 1, Batch: 1694, Loss: 5.0760698318481445\n",
      "Epoch: 1, Batch: 1695, Loss: 4.941949844360352\n",
      "Epoch: 1, Batch: 1696, Loss: 4.981988906860352\n",
      "Epoch: 1, Batch: 1697, Loss: 5.063904762268066\n",
      "Epoch: 1, Batch: 1698, Loss: 5.079537391662598\n",
      "Epoch: 1, Batch: 1699, Loss: 5.203579425811768\n",
      "Epoch: 1, Batch: 1700, Loss: 5.125339984893799\n",
      "Epoch: 1, Batch: 1701, Loss: 5.161421775817871\n",
      "Epoch: 1, Batch: 1702, Loss: 4.82201623916626\n",
      "Epoch: 1, Batch: 1703, Loss: 5.112727165222168\n",
      "Epoch: 1, Batch: 1704, Loss: 5.232392311096191\n",
      "Epoch: 1, Batch: 1705, Loss: 4.999826908111572\n",
      "Epoch: 1, Batch: 1706, Loss: 4.9841485023498535\n",
      "Epoch: 1, Batch: 1707, Loss: 4.915457725524902\n",
      "Epoch: 1, Batch: 1708, Loss: 5.0748982429504395\n",
      "Epoch: 1, Batch: 1709, Loss: 4.9625163078308105\n",
      "Epoch: 1, Batch: 1710, Loss: 5.042934894561768\n",
      "Epoch: 1, Batch: 1711, Loss: 4.9348907470703125\n",
      "Epoch: 1, Batch: 1712, Loss: 5.065834999084473\n",
      "Epoch: 1, Batch: 1713, Loss: 5.201050758361816\n",
      "Epoch: 1, Batch: 1714, Loss: 4.932331085205078\n",
      "Epoch: 1, Batch: 1715, Loss: 5.321811676025391\n",
      "Epoch: 1, Batch: 1716, Loss: 4.977405548095703\n",
      "Epoch: 1, Batch: 1717, Loss: 5.05112886428833\n",
      "Epoch: 1, Batch: 1718, Loss: 5.006102561950684\n",
      "Epoch: 1, Batch: 1719, Loss: 4.802885055541992\n",
      "Epoch: 1, Batch: 1720, Loss: 5.0579328536987305\n",
      "Epoch: 1, Batch: 1721, Loss: 5.253309726715088\n",
      "Epoch: 1, Batch: 1722, Loss: 5.1187286376953125\n",
      "Epoch: 1, Batch: 1723, Loss: 5.260231018066406\n",
      "Epoch: 1, Batch: 1724, Loss: 4.915489673614502\n",
      "Epoch: 1, Batch: 1725, Loss: 4.893399238586426\n",
      "Epoch: 1, Batch: 1726, Loss: 5.058530330657959\n",
      "Epoch: 1, Batch: 1727, Loss: 4.9865641593933105\n",
      "Epoch: 1, Batch: 1728, Loss: 5.26346492767334\n",
      "Epoch: 1, Batch: 1729, Loss: 4.966691017150879\n",
      "Epoch: 1, Batch: 1730, Loss: 5.219935894012451\n",
      "Epoch: 1, Batch: 1731, Loss: 4.7434797286987305\n",
      "Epoch: 1, Batch: 1732, Loss: 5.047623634338379\n",
      "Epoch: 1, Batch: 1733, Loss: 5.096207618713379\n",
      "Epoch: 1, Batch: 1734, Loss: 4.914402008056641\n",
      "Epoch: 1, Batch: 1735, Loss: 5.067892074584961\n",
      "Epoch: 1, Batch: 1736, Loss: 5.032104015350342\n",
      "Epoch: 1, Batch: 1737, Loss: 4.95580530166626\n",
      "Epoch: 1, Batch: 1738, Loss: 4.860229969024658\n",
      "Epoch: 1, Batch: 1739, Loss: 4.951318740844727\n",
      "Epoch: 1, Batch: 1740, Loss: 4.97661828994751\n",
      "Epoch: 1, Batch: 1741, Loss: 5.1726861000061035\n",
      "Epoch: 1, Batch: 1742, Loss: 4.849515914916992\n",
      "Epoch: 1, Batch: 1743, Loss: 5.103192329406738\n",
      "Epoch: 1, Batch: 1744, Loss: 5.1508588790893555\n",
      "Epoch: 1, Batch: 1745, Loss: 5.1179938316345215\n",
      "Epoch: 1, Batch: 1746, Loss: 4.911505699157715\n",
      "Epoch: 1, Batch: 1747, Loss: 5.185720443725586\n",
      "Epoch: 1, Batch: 1748, Loss: 4.896100044250488\n",
      "Epoch: 1, Batch: 1749, Loss: 4.9459452629089355\n",
      "Epoch: 1, Batch: 1750, Loss: 4.786487579345703\n",
      "Epoch: 1, Batch: 1751, Loss: 5.012247085571289\n",
      "Epoch: 1, Batch: 1752, Loss: 4.9539475440979\n",
      "Epoch: 1, Batch: 1753, Loss: 4.935931205749512\n",
      "Epoch: 1, Batch: 1754, Loss: 5.209620952606201\n",
      "Epoch: 1, Batch: 1755, Loss: 4.940548419952393\n",
      "Epoch: 1, Batch: 1756, Loss: 5.048817157745361\n",
      "Epoch: 1, Batch: 1757, Loss: 4.966761112213135\n",
      "Epoch: 1, Batch: 1758, Loss: 4.965076446533203\n",
      "Epoch: 1, Batch: 1759, Loss: 4.973424911499023\n",
      "Epoch: 1, Batch: 1760, Loss: 4.996408462524414\n",
      "Epoch: 1, Batch: 1761, Loss: 5.047610759735107\n",
      "Epoch: 1, Batch: 1762, Loss: 5.151088714599609\n",
      "Epoch: 1, Batch: 1763, Loss: 4.809941291809082\n",
      "Epoch: 1, Batch: 1764, Loss: 4.8810715675354\n",
      "Epoch: 1, Batch: 1765, Loss: 5.3056864738464355\n",
      "Epoch: 1, Batch: 1766, Loss: 4.993520736694336\n",
      "Epoch: 1, Batch: 1767, Loss: 4.870546340942383\n",
      "Epoch: 1, Batch: 1768, Loss: 4.998767375946045\n",
      "Epoch: 1, Batch: 1769, Loss: 5.192960262298584\n",
      "Epoch: 1, Batch: 1770, Loss: 4.985721111297607\n",
      "Epoch: 1, Batch: 1771, Loss: 4.993016242980957\n",
      "Epoch: 1, Batch: 1772, Loss: 5.090095043182373\n",
      "Epoch: 1, Batch: 1773, Loss: 5.217472553253174\n",
      "Epoch: 1, Batch: 1774, Loss: 4.880848407745361\n",
      "Epoch: 1, Batch: 1775, Loss: 5.055541515350342\n",
      "Epoch: 1, Batch: 1776, Loss: 4.951719760894775\n",
      "Epoch: 1, Batch: 1777, Loss: 5.162957668304443\n",
      "Epoch: 1, Batch: 1778, Loss: 5.199703216552734\n",
      "Epoch: 1, Batch: 1779, Loss: 4.756591320037842\n",
      "Epoch: 1, Batch: 1780, Loss: 4.862112998962402\n",
      "Epoch: 1, Batch: 1781, Loss: 5.162199020385742\n",
      "Epoch: 1, Batch: 1782, Loss: 4.917773723602295\n",
      "Epoch: 1, Batch: 1783, Loss: 5.074965000152588\n",
      "Epoch: 1, Batch: 1784, Loss: 4.8057541847229\n",
      "Epoch: 1, Batch: 1785, Loss: 4.957493782043457\n",
      "Epoch: 1, Batch: 1786, Loss: 5.113566875457764\n",
      "Epoch: 1, Batch: 1787, Loss: 4.861593246459961\n",
      "Epoch: 1, Batch: 1788, Loss: 4.932404041290283\n",
      "Epoch: 1, Batch: 1789, Loss: 5.2121734619140625\n",
      "Epoch: 1, Batch: 1790, Loss: 5.116477012634277\n",
      "Epoch: 1, Batch: 1791, Loss: 4.897220611572266\n",
      "Epoch: 1, Batch: 1792, Loss: 5.159002304077148\n",
      "Epoch: 1, Batch: 1793, Loss: 5.026829242706299\n",
      "Epoch: 1, Batch: 1794, Loss: 4.919867038726807\n",
      "Epoch: 1, Batch: 1795, Loss: 5.012702941894531\n",
      "Epoch: 1, Batch: 1796, Loss: 4.953663349151611\n",
      "Epoch: 1, Batch: 1797, Loss: 4.957518577575684\n",
      "Epoch: 1, Batch: 1798, Loss: 4.960434913635254\n",
      "Epoch: 1, Batch: 1799, Loss: 4.991507530212402\n",
      "Epoch: 1, Batch: 1800, Loss: 4.80232572555542\n",
      "Epoch: 1, Batch: 1801, Loss: 4.976144790649414\n",
      "Epoch: 1, Batch: 1802, Loss: 4.6774725914001465\n",
      "Epoch: 1, Batch: 1803, Loss: 5.094964027404785\n",
      "Epoch: 1, Batch: 1804, Loss: 5.095825672149658\n",
      "Epoch: 1, Batch: 1805, Loss: 4.864107608795166\n",
      "Epoch: 1, Batch: 1806, Loss: 4.85109281539917\n",
      "Epoch: 1, Batch: 1807, Loss: 4.8686699867248535\n",
      "Epoch: 1, Batch: 1808, Loss: 5.149695873260498\n",
      "Epoch: 1, Batch: 1809, Loss: 4.937730312347412\n",
      "Epoch: 1, Batch: 1810, Loss: 5.0042195320129395\n",
      "Epoch: 1, Batch: 1811, Loss: 5.0383734703063965\n",
      "Epoch: 1, Batch: 1812, Loss: 5.08571195602417\n",
      "Epoch: 1, Batch: 1813, Loss: 5.1696271896362305\n",
      "Epoch: 1, Batch: 1814, Loss: 5.349090099334717\n",
      "Epoch: 1, Batch: 1815, Loss: 5.201305866241455\n",
      "Epoch: 1, Batch: 1816, Loss: 5.0308451652526855\n",
      "Epoch: 1, Batch: 1817, Loss: 4.921757698059082\n",
      "Epoch: 1, Batch: 1818, Loss: 4.969079971313477\n",
      "Epoch: 1, Batch: 1819, Loss: 5.351182460784912\n",
      "Epoch: 1, Batch: 1820, Loss: 5.160778045654297\n",
      "Epoch: 1, Batch: 1821, Loss: 5.013205528259277\n",
      "Epoch: 1, Batch: 1822, Loss: 5.032985687255859\n",
      "Epoch: 1, Batch: 1823, Loss: 5.1932854652404785\n",
      "Epoch: 1, Batch: 1824, Loss: 5.217056751251221\n",
      "Epoch: 1, Batch: 1825, Loss: 4.920528888702393\n",
      "Epoch: 1, Batch: 1826, Loss: 5.092727184295654\n",
      "Epoch: 1, Batch: 1827, Loss: 5.023248195648193\n",
      "Epoch: 1, Batch: 1828, Loss: 5.067685127258301\n",
      "Epoch: 1, Batch: 1829, Loss: 4.9992828369140625\n",
      "Epoch: 1, Batch: 1830, Loss: 4.908638000488281\n",
      "Epoch: 1, Batch: 1831, Loss: 4.93086051940918\n",
      "Epoch: 1, Batch: 1832, Loss: 4.777688503265381\n",
      "Epoch: 1, Batch: 1833, Loss: 4.98447847366333\n",
      "Epoch: 1, Batch: 1834, Loss: 5.151120185852051\n",
      "Epoch: 1, Batch: 1835, Loss: 5.268226623535156\n",
      "Epoch: 1, Batch: 1836, Loss: 5.0435943603515625\n",
      "Epoch: 1, Batch: 1837, Loss: 4.861491680145264\n",
      "Epoch: 1, Batch: 1838, Loss: 5.0126118659973145\n",
      "Epoch: 1, Batch: 1839, Loss: 5.2344536781311035\n",
      "Epoch: 1, Batch: 1840, Loss: 5.09242057800293\n",
      "Epoch: 1, Batch: 1841, Loss: 4.933047294616699\n",
      "Epoch: 1, Batch: 1842, Loss: 5.158590793609619\n",
      "Epoch: 1, Batch: 1843, Loss: 5.272521495819092\n",
      "Epoch: 1, Batch: 1844, Loss: 4.7950239181518555\n",
      "Epoch: 1, Batch: 1845, Loss: 5.199179649353027\n",
      "Epoch: 1, Batch: 1846, Loss: 5.052540302276611\n",
      "Epoch: 1, Batch: 1847, Loss: 5.004545211791992\n",
      "Epoch: 1, Batch: 1848, Loss: 4.919050693511963\n",
      "Epoch: 1, Batch: 1849, Loss: 4.975091457366943\n",
      "Epoch: 1, Batch: 1850, Loss: 5.1088480949401855\n",
      "Epoch: 1, Batch: 1851, Loss: 5.025044918060303\n",
      "Epoch: 1, Batch: 1852, Loss: 4.945861339569092\n",
      "Epoch: 1, Batch: 1853, Loss: 5.156463623046875\n",
      "Epoch: 1, Batch: 1854, Loss: 5.262139797210693\n",
      "Epoch: 1, Batch: 1855, Loss: 4.968162536621094\n",
      "Epoch: 1, Batch: 1856, Loss: 4.950649738311768\n",
      "Epoch: 1, Batch: 1857, Loss: 5.122704029083252\n",
      "Epoch: 1, Batch: 1858, Loss: 4.899894714355469\n",
      "Epoch: 1, Batch: 1859, Loss: 5.125107765197754\n",
      "Epoch: 1, Batch: 1860, Loss: 4.8872480392456055\n",
      "Epoch: 1, Batch: 1861, Loss: 4.8528642654418945\n",
      "Epoch: 1, Batch: 1862, Loss: 5.006034851074219\n",
      "Epoch: 1, Batch: 1863, Loss: 5.092617034912109\n",
      "Epoch: 1, Batch: 1864, Loss: 5.064386367797852\n",
      "Epoch: 1, Batch: 1865, Loss: 4.904668807983398\n",
      "Epoch: 1, Batch: 1866, Loss: 4.954029560089111\n",
      "Epoch: 1, Batch: 1867, Loss: 4.985946178436279\n",
      "Epoch: 1, Batch: 1868, Loss: 5.147318363189697\n",
      "Epoch: 1, Batch: 1869, Loss: 4.920014381408691\n",
      "Epoch: 1, Batch: 1870, Loss: 5.041712760925293\n",
      "Epoch: 1, Batch: 1871, Loss: 4.892531871795654\n",
      "Epoch: 1, Batch: 1872, Loss: 5.293652057647705\n",
      "Epoch: 1, Batch: 1873, Loss: 5.052969932556152\n",
      "Epoch: 1, Batch: 1874, Loss: 4.912784099578857\n",
      "Epoch: 1, Batch: 1875, Loss: 4.787886619567871\n",
      "Epoch: 1, Batch: 1876, Loss: 4.8194403648376465\n",
      "Epoch: 1, Batch: 1877, Loss: 5.137166500091553\n",
      "Epoch: 1, Batch: 1878, Loss: 5.238924503326416\n",
      "Epoch: 1, Batch: 1879, Loss: 4.876123905181885\n",
      "Epoch: 1, Batch: 1880, Loss: 5.141754627227783\n",
      "Epoch: 1, Batch: 1881, Loss: 4.9449052810668945\n",
      "Epoch: 1, Batch: 1882, Loss: 5.182881832122803\n",
      "Epoch: 1, Batch: 1883, Loss: 4.8997907638549805\n",
      "Epoch: 1, Batch: 1884, Loss: 4.981022834777832\n",
      "Epoch: 1, Batch: 1885, Loss: 5.305655479431152\n",
      "Epoch: 1, Batch: 1886, Loss: 5.005699634552002\n",
      "Epoch: 1, Batch: 1887, Loss: 4.816961765289307\n",
      "Epoch: 1, Batch: 1888, Loss: 4.994116306304932\n",
      "Epoch: 1, Batch: 1889, Loss: 5.055787563323975\n",
      "Epoch: 1, Batch: 1890, Loss: 5.137127876281738\n",
      "Epoch: 1, Batch: 1891, Loss: 4.99962854385376\n",
      "Epoch: 1, Batch: 1892, Loss: 4.859073162078857\n",
      "Epoch: 1, Batch: 1893, Loss: 4.796847343444824\n",
      "Epoch: 1, Batch: 1894, Loss: 5.093240261077881\n",
      "Epoch: 1, Batch: 1895, Loss: 4.872171401977539\n",
      "Epoch: 1, Batch: 1896, Loss: 4.820288181304932\n",
      "Epoch: 1, Batch: 1897, Loss: 4.948587417602539\n",
      "Epoch: 1, Batch: 1898, Loss: 4.8065266609191895\n",
      "Epoch: 1, Batch: 1899, Loss: 4.96286678314209\n",
      "Epoch: 1, Batch: 1900, Loss: 4.703549861907959\n",
      "Epoch: 1, Batch: 1901, Loss: 4.724574565887451\n",
      "Epoch: 1, Batch: 1902, Loss: 4.872766494750977\n",
      "Epoch: 1, Batch: 1903, Loss: 5.02235746383667\n",
      "Epoch: 1, Batch: 1904, Loss: 4.944825172424316\n",
      "Epoch: 1, Batch: 1905, Loss: 4.8743696212768555\n",
      "Epoch: 1, Batch: 1906, Loss: 4.923406600952148\n",
      "Epoch: 1, Batch: 1907, Loss: 5.101112365722656\n",
      "Epoch: 1, Batch: 1908, Loss: 4.8350911140441895\n",
      "Epoch: 1, Batch: 1909, Loss: 5.200580596923828\n",
      "Epoch: 1, Batch: 1910, Loss: 4.867184638977051\n",
      "Epoch: 1, Batch: 1911, Loss: 5.137275695800781\n",
      "Epoch: 1, Batch: 1912, Loss: 4.973491191864014\n",
      "Epoch: 1, Batch: 1913, Loss: 4.857408046722412\n",
      "Epoch: 1, Batch: 1914, Loss: 5.250669956207275\n",
      "Epoch: 1, Batch: 1915, Loss: 5.093805313110352\n",
      "Epoch: 1, Batch: 1916, Loss: 5.233569622039795\n",
      "Epoch: 1, Batch: 1917, Loss: 4.976778030395508\n",
      "Epoch: 1, Batch: 1918, Loss: 4.957372665405273\n",
      "Epoch: 1, Batch: 1919, Loss: 4.87394905090332\n",
      "Epoch: 1, Batch: 1920, Loss: 5.124940395355225\n",
      "Epoch: 1, Batch: 1921, Loss: 4.849902629852295\n",
      "Epoch: 1, Batch: 1922, Loss: 4.960459232330322\n",
      "Epoch: 1, Batch: 1923, Loss: 4.819321632385254\n",
      "Epoch: 1, Batch: 1924, Loss: 4.995209217071533\n",
      "Epoch: 1, Batch: 1925, Loss: 5.381056308746338\n",
      "Epoch: 1, Batch: 1926, Loss: 5.205634593963623\n",
      "Epoch: 1, Batch: 1927, Loss: 4.891996383666992\n",
      "Epoch: 1, Batch: 1928, Loss: 4.925900936126709\n",
      "Epoch: 1, Batch: 1929, Loss: 5.036628723144531\n",
      "Epoch: 1, Batch: 1930, Loss: 4.996159076690674\n",
      "Epoch: 1, Batch: 1931, Loss: 4.910560607910156\n",
      "Epoch: 1, Batch: 1932, Loss: 4.762879848480225\n",
      "Epoch: 1, Batch: 1933, Loss: 5.146111488342285\n",
      "Epoch: 1, Batch: 1934, Loss: 5.156625270843506\n",
      "Epoch: 1, Batch: 1935, Loss: 4.941205024719238\n",
      "Epoch: 1, Batch: 1936, Loss: 5.105124473571777\n",
      "Epoch: 1, Batch: 1937, Loss: 5.078920841217041\n",
      "Epoch: 1, Batch: 1938, Loss: 5.061392307281494\n",
      "Epoch: 1, Batch: 1939, Loss: 4.909825325012207\n",
      "Epoch: 1, Batch: 1940, Loss: 4.746909141540527\n",
      "Epoch: 1, Batch: 1941, Loss: 4.94326114654541\n",
      "Epoch: 1, Batch: 1942, Loss: 4.866310119628906\n",
      "Epoch: 1, Batch: 1943, Loss: 4.993878364562988\n",
      "Epoch: 1, Batch: 1944, Loss: 4.870639324188232\n",
      "Epoch: 1, Batch: 1945, Loss: 4.87513542175293\n",
      "Epoch: 1, Batch: 1946, Loss: 5.081722259521484\n",
      "Epoch: 1, Batch: 1947, Loss: 4.818497657775879\n",
      "Epoch: 1, Batch: 1948, Loss: 5.12339973449707\n",
      "Epoch: 1, Batch: 1949, Loss: 5.106141090393066\n",
      "Epoch: 1, Batch: 1950, Loss: 5.048619270324707\n",
      "Epoch: 1, Batch: 1951, Loss: 4.847524166107178\n",
      "Epoch: 1, Batch: 1952, Loss: 5.18605375289917\n",
      "Epoch: 1, Batch: 1953, Loss: 4.959436416625977\n",
      "Epoch: 1, Batch: 1954, Loss: 5.262166976928711\n",
      "Epoch: 1, Batch: 1955, Loss: 5.033357620239258\n",
      "Epoch: 1, Batch: 1956, Loss: 4.8552165031433105\n",
      "Epoch: 1, Batch: 1957, Loss: 5.126089096069336\n",
      "Epoch: 1, Batch: 1958, Loss: 5.188989162445068\n",
      "Epoch: 1, Batch: 1959, Loss: 4.813118934631348\n",
      "Epoch: 1, Batch: 1960, Loss: 5.305140018463135\n",
      "Epoch: 1, Batch: 1961, Loss: 4.819076061248779\n",
      "Epoch: 1, Batch: 1962, Loss: 4.9662299156188965\n",
      "Epoch: 1, Batch: 1963, Loss: 5.321480751037598\n",
      "Epoch: 1, Batch: 1964, Loss: 4.7854156494140625\n",
      "Epoch: 1, Batch: 1965, Loss: 5.0994672775268555\n",
      "Epoch: 1, Batch: 1966, Loss: 5.059243679046631\n",
      "Epoch: 1, Batch: 1967, Loss: 4.973649024963379\n",
      "Epoch: 1, Batch: 1968, Loss: 5.15196418762207\n",
      "Epoch: 1, Batch: 1969, Loss: 5.180817604064941\n",
      "Epoch: 1, Batch: 1970, Loss: 4.61212682723999\n",
      "Epoch: 1, Batch: 1971, Loss: 4.824683666229248\n",
      "Epoch: 1, Batch: 1972, Loss: 4.862875938415527\n",
      "Epoch: 1, Batch: 1973, Loss: 4.951358318328857\n",
      "Epoch: 1, Batch: 1974, Loss: 5.081475257873535\n",
      "Epoch: 1, Batch: 1975, Loss: 5.1099629402160645\n",
      "Epoch: 1, Batch: 1976, Loss: 4.6225056648254395\n",
      "Epoch: 1, Batch: 1977, Loss: 5.222707271575928\n",
      "Epoch: 1, Batch: 1978, Loss: 4.937374591827393\n",
      "Epoch: 1, Batch: 1979, Loss: 4.848524570465088\n",
      "Epoch: 1, Batch: 1980, Loss: 5.015343189239502\n",
      "Epoch: 1, Batch: 1981, Loss: 4.875533103942871\n",
      "Epoch: 1, Batch: 1982, Loss: 5.017184734344482\n",
      "Epoch: 1, Batch: 1983, Loss: 4.815333366394043\n",
      "Epoch: 1, Batch: 1984, Loss: 4.775904655456543\n",
      "Epoch: 1, Batch: 1985, Loss: 4.919528007507324\n",
      "Epoch: 1, Batch: 1986, Loss: 5.123201847076416\n",
      "Epoch: 1, Batch: 1987, Loss: 4.95188045501709\n",
      "Epoch: 1, Batch: 1988, Loss: 4.924513339996338\n",
      "Epoch: 1, Batch: 1989, Loss: 5.031398296356201\n",
      "Epoch: 1, Batch: 1990, Loss: 5.040708541870117\n",
      "Epoch: 1, Batch: 1991, Loss: 4.6869940757751465\n",
      "Epoch: 1, Batch: 1992, Loss: 4.9452223777771\n",
      "Epoch: 1, Batch: 1993, Loss: 4.893361568450928\n",
      "Epoch: 1, Batch: 1994, Loss: 4.931962490081787\n",
      "Epoch: 1, Batch: 1995, Loss: 4.999683380126953\n",
      "Epoch: 1, Batch: 1996, Loss: 4.793606758117676\n",
      "Epoch: 1, Batch: 1997, Loss: 4.877804279327393\n",
      "Epoch: 1, Batch: 1998, Loss: 4.829738140106201\n",
      "Epoch: 1, Batch: 1999, Loss: 4.890369892120361\n",
      "Epoch: 1, Batch: 2000, Loss: 4.970123767852783\n",
      "Epoch: 1, Batch: 2001, Loss: 5.067726135253906\n",
      "Epoch: 1, Batch: 2002, Loss: 4.797117233276367\n",
      "Epoch: 1, Batch: 2003, Loss: 4.981568813323975\n",
      "Epoch: 1, Batch: 2004, Loss: 4.790729522705078\n",
      "Epoch: 1, Batch: 2005, Loss: 4.841635704040527\n",
      "Epoch: 1, Batch: 2006, Loss: 4.702306747436523\n",
      "Epoch: 1, Batch: 2007, Loss: 4.9087138175964355\n",
      "Epoch: 1, Batch: 2008, Loss: 4.996298313140869\n",
      "Epoch: 1, Batch: 2009, Loss: 4.980083465576172\n",
      "Epoch: 1, Batch: 2010, Loss: 5.209523677825928\n",
      "Epoch: 1, Batch: 2011, Loss: 4.91742467880249\n",
      "Epoch: 1, Batch: 2012, Loss: 4.779599666595459\n",
      "Epoch: 1, Batch: 2013, Loss: 4.759799480438232\n",
      "Epoch: 1, Batch: 2014, Loss: 4.965263843536377\n",
      "Epoch: 1, Batch: 2015, Loss: 5.2109375\n",
      "Epoch: 1, Batch: 2016, Loss: 4.975323677062988\n",
      "Epoch: 1, Batch: 2017, Loss: 5.022213935852051\n",
      "Epoch: 1, Batch: 2018, Loss: 5.324073314666748\n",
      "Epoch: 1, Batch: 2019, Loss: 5.142000675201416\n",
      "Epoch: 1, Batch: 2020, Loss: 5.146442890167236\n",
      "Epoch: 1, Batch: 2021, Loss: 5.003615379333496\n",
      "Epoch: 1, Batch: 2022, Loss: 5.006155490875244\n",
      "Epoch: 1, Batch: 2023, Loss: 4.9288249015808105\n",
      "Epoch: 1, Batch: 2024, Loss: 4.9929351806640625\n",
      "Epoch: 1, Batch: 2025, Loss: 4.849225044250488\n",
      "Epoch: 1, Batch: 2026, Loss: 4.8757476806640625\n",
      "Epoch: 1, Batch: 2027, Loss: 4.8825883865356445\n",
      "Epoch: 1, Batch: 2028, Loss: 5.2069549560546875\n",
      "Epoch: 1, Batch: 2029, Loss: 5.16513204574585\n",
      "Epoch: 1, Batch: 2030, Loss: 4.888632297515869\n",
      "Epoch: 1, Batch: 2031, Loss: 4.815028667449951\n",
      "Epoch: 1, Batch: 2032, Loss: 4.935378551483154\n",
      "Epoch: 1, Batch: 2033, Loss: 5.06406307220459\n",
      "Epoch: 1, Batch: 2034, Loss: 5.343783855438232\n",
      "Epoch: 1, Batch: 2035, Loss: 5.0409979820251465\n",
      "Epoch: 1, Batch: 2036, Loss: 4.897127628326416\n",
      "Epoch: 1, Batch: 2037, Loss: 4.865103244781494\n",
      "Epoch: 1, Batch: 2038, Loss: 4.8878278732299805\n",
      "Epoch: 1, Batch: 2039, Loss: 5.075525760650635\n",
      "Epoch: 1, Batch: 2040, Loss: 5.203248977661133\n",
      "Epoch: 1, Batch: 2041, Loss: 5.008518218994141\n",
      "Epoch: 1, Batch: 2042, Loss: 4.99649715423584\n",
      "Epoch: 1, Batch: 2043, Loss: 5.215304851531982\n",
      "Epoch: 1, Batch: 2044, Loss: 5.106309413909912\n",
      "Epoch: 1, Batch: 2045, Loss: 5.056499004364014\n",
      "Epoch: 1, Batch: 2046, Loss: 5.017604351043701\n",
      "Epoch: 1, Batch: 2047, Loss: 4.736942768096924\n",
      "Epoch: 1, Batch: 2048, Loss: 4.708554744720459\n",
      "Epoch: 1, Batch: 2049, Loss: 4.868987083435059\n",
      "Epoch: 1, Batch: 2050, Loss: 4.820114612579346\n",
      "Epoch: 1, Batch: 2051, Loss: 5.0173444747924805\n",
      "Epoch: 1, Batch: 2052, Loss: 5.230801105499268\n",
      "Epoch: 1, Batch: 2053, Loss: 5.081857681274414\n",
      "Epoch: 1, Batch: 2054, Loss: 4.821615219116211\n",
      "Epoch: 1, Batch: 2055, Loss: 5.08089017868042\n",
      "Epoch: 1, Batch: 2056, Loss: 4.866230487823486\n",
      "Epoch: 1, Batch: 2057, Loss: 5.128097057342529\n",
      "Epoch: 1, Batch: 2058, Loss: 4.981557369232178\n",
      "Epoch: 1, Batch: 2059, Loss: 4.848257064819336\n",
      "Epoch: 1, Batch: 2060, Loss: 4.800407409667969\n",
      "Epoch: 1, Batch: 2061, Loss: 4.956563949584961\n",
      "Epoch: 1, Batch: 2062, Loss: 4.961658000946045\n",
      "Epoch: 1, Batch: 2063, Loss: 4.872268199920654\n",
      "Epoch: 1, Batch: 2064, Loss: 5.09834623336792\n",
      "Epoch: 1, Batch: 2065, Loss: 4.999067783355713\n",
      "Epoch: 1, Batch: 2066, Loss: 5.0545148849487305\n",
      "Epoch: 1, Batch: 2067, Loss: 4.958367824554443\n",
      "Epoch: 1, Batch: 2068, Loss: 4.965709209442139\n",
      "Epoch: 1, Batch: 2069, Loss: 4.763425827026367\n",
      "Epoch: 1, Batch: 2070, Loss: 5.171636581420898\n",
      "Epoch: 1, Batch: 2071, Loss: 4.774383544921875\n",
      "Epoch: 1, Batch: 2072, Loss: 4.6826934814453125\n",
      "Epoch: 1, Batch: 2073, Loss: 5.142615795135498\n",
      "Epoch: 1, Batch: 2074, Loss: 4.8780670166015625\n",
      "Epoch: 1, Batch: 2075, Loss: 5.093582630157471\n",
      "Epoch: 1, Batch: 2076, Loss: 4.904803276062012\n",
      "Epoch: 1, Batch: 2077, Loss: 5.012533664703369\n",
      "Epoch: 1, Batch: 2078, Loss: 4.993655204772949\n",
      "Epoch: 1, Batch: 2079, Loss: 5.113185882568359\n",
      "Epoch: 1, Batch: 2080, Loss: 4.788305759429932\n",
      "Epoch: 1, Batch: 2081, Loss: 5.140340805053711\n",
      "Epoch: 1, Batch: 2082, Loss: 4.894425392150879\n",
      "Epoch: 1, Batch: 2083, Loss: 4.968489170074463\n",
      "Epoch: 1, Batch: 2084, Loss: 4.882882595062256\n",
      "Epoch: 1, Batch: 2085, Loss: 5.095611572265625\n",
      "Epoch: 1, Batch: 2086, Loss: 4.805328369140625\n",
      "Epoch: 1, Batch: 2087, Loss: 4.989057540893555\n",
      "Epoch: 1, Batch: 2088, Loss: 4.983683109283447\n",
      "Epoch: 1, Batch: 2089, Loss: 5.0024895668029785\n",
      "Epoch: 1, Batch: 2090, Loss: 4.944039344787598\n",
      "Epoch: 1, Batch: 2091, Loss: 5.161252975463867\n",
      "Epoch: 1, Batch: 2092, Loss: 4.968328475952148\n",
      "Epoch: 1, Batch: 2093, Loss: 5.07404088973999\n",
      "Epoch: 1, Batch: 2094, Loss: 5.123773574829102\n",
      "Epoch: 1, Batch: 2095, Loss: 4.7460408210754395\n",
      "Epoch: 1, Batch: 2096, Loss: 4.776065349578857\n",
      "Epoch: 1, Batch: 2097, Loss: 5.117127418518066\n",
      "Epoch: 1, Batch: 2098, Loss: 5.067694664001465\n",
      "Epoch: 1, Batch: 2099, Loss: 5.029156684875488\n",
      "Epoch: 1, Batch: 2100, Loss: 4.90158224105835\n",
      "Epoch: 1, Batch: 2101, Loss: 5.085789680480957\n",
      "Epoch: 1, Batch: 2102, Loss: 4.883591175079346\n",
      "Epoch: 1, Batch: 2103, Loss: 5.082672119140625\n",
      "Epoch: 1, Batch: 2104, Loss: 5.065309047698975\n",
      "Epoch: 1, Batch: 2105, Loss: 4.910514831542969\n",
      "Epoch: 1, Batch: 2106, Loss: 5.03481388092041\n",
      "Epoch: 1, Batch: 2107, Loss: 5.074490070343018\n",
      "Epoch: 1, Batch: 2108, Loss: 4.7581400871276855\n",
      "Epoch: 1, Batch: 2109, Loss: 4.959734916687012\n",
      "Epoch: 1, Batch: 2110, Loss: 4.787548065185547\n",
      "Epoch: 1, Batch: 2111, Loss: 5.035675525665283\n",
      "Epoch: 1, Batch: 2112, Loss: 4.989302635192871\n",
      "Epoch: 1, Batch: 2113, Loss: 5.122002124786377\n",
      "Epoch: 1, Batch: 2114, Loss: 4.873097896575928\n",
      "Epoch: 1, Batch: 2115, Loss: 5.146306991577148\n",
      "Epoch: 1, Batch: 2116, Loss: 4.817925930023193\n",
      "Epoch: 1, Batch: 2117, Loss: 4.98307466506958\n",
      "Epoch: 1, Batch: 2118, Loss: 4.845374584197998\n",
      "Epoch: 1, Batch: 2119, Loss: 4.896318435668945\n",
      "Epoch: 1, Batch: 2120, Loss: 5.016628742218018\n",
      "Epoch: 1, Batch: 2121, Loss: 4.740792751312256\n",
      "Epoch: 1, Batch: 2122, Loss: 5.009298801422119\n",
      "Epoch: 1, Batch: 2123, Loss: 5.097561359405518\n",
      "Epoch: 1, Batch: 2124, Loss: 4.972661972045898\n",
      "Epoch: 1, Batch: 2125, Loss: 4.916665554046631\n",
      "Epoch: 1, Batch: 2126, Loss: 4.789715766906738\n",
      "Epoch: 1, Batch: 2127, Loss: 5.021132946014404\n",
      "Epoch: 1, Batch: 2128, Loss: 5.0562872886657715\n",
      "Epoch: 1, Batch: 2129, Loss: 4.778479099273682\n",
      "Epoch: 1, Batch: 2130, Loss: 5.213932514190674\n",
      "Epoch: 1, Batch: 2131, Loss: 5.095363140106201\n",
      "Epoch: 1, Batch: 2132, Loss: 4.789437294006348\n",
      "Epoch: 1, Batch: 2133, Loss: 4.74041748046875\n",
      "Epoch: 1, Batch: 2134, Loss: 4.893147945404053\n",
      "Epoch: 1, Batch: 2135, Loss: 5.033904075622559\n",
      "Epoch: 1, Batch: 2136, Loss: 5.026186466217041\n",
      "Epoch: 1, Batch: 2137, Loss: 4.983859539031982\n",
      "Epoch: 1, Batch: 2138, Loss: 4.8478240966796875\n",
      "Epoch: 1, Batch: 2139, Loss: 4.777347564697266\n",
      "Epoch: 1, Batch: 2140, Loss: 4.879431247711182\n",
      "Epoch: 1, Batch: 2141, Loss: 4.927867412567139\n",
      "Epoch: 1, Batch: 2142, Loss: 4.931295394897461\n",
      "Epoch: 1, Batch: 2143, Loss: 5.065492153167725\n",
      "Epoch: 1, Batch: 2144, Loss: 4.6647491455078125\n",
      "Epoch: 1, Batch: 2145, Loss: 4.867384433746338\n",
      "Epoch: 1, Batch: 2146, Loss: 4.85631799697876\n",
      "Epoch: 1, Batch: 2147, Loss: 4.918065547943115\n",
      "Epoch: 1, Batch: 2148, Loss: 5.008790016174316\n",
      "Epoch: 1, Batch: 2149, Loss: 5.032803058624268\n",
      "Epoch: 1, Batch: 2150, Loss: 4.630488395690918\n",
      "Epoch: 1, Batch: 2151, Loss: 5.048007011413574\n",
      "Epoch: 1, Batch: 2152, Loss: 4.854297637939453\n",
      "Epoch: 1, Batch: 2153, Loss: 5.135366916656494\n",
      "Epoch: 1, Batch: 2154, Loss: 4.955772399902344\n",
      "Epoch: 1, Batch: 2155, Loss: 4.787466049194336\n",
      "Epoch: 1, Batch: 2156, Loss: 4.972309589385986\n",
      "Epoch: 1, Batch: 2157, Loss: 4.832814693450928\n",
      "Epoch: 1, Batch: 2158, Loss: 4.9924726486206055\n",
      "Epoch: 1, Batch: 2159, Loss: 4.852274417877197\n",
      "Epoch: 1, Batch: 2160, Loss: 4.9212727546691895\n",
      "Epoch: 1, Batch: 2161, Loss: 4.882700443267822\n",
      "Epoch: 1, Batch: 2162, Loss: 4.758094310760498\n",
      "Epoch: 1, Batch: 2163, Loss: 4.958350658416748\n",
      "Epoch: 1, Batch: 2164, Loss: 5.213293552398682\n",
      "Epoch: 1, Batch: 2165, Loss: 5.028392314910889\n",
      "Epoch: 1, Batch: 2166, Loss: 5.103326797485352\n",
      "Epoch: 1, Batch: 2167, Loss: 5.046144008636475\n",
      "Epoch: 1, Batch: 2168, Loss: 4.8966064453125\n",
      "Epoch: 1, Batch: 2169, Loss: 5.19038724899292\n",
      "Epoch: 1, Batch: 2170, Loss: 5.038328170776367\n",
      "Epoch: 1, Batch: 2171, Loss: 4.886800765991211\n",
      "Epoch: 1, Batch: 2172, Loss: 4.90169095993042\n",
      "Epoch: 1, Batch: 2173, Loss: 5.013047695159912\n",
      "Epoch: 1, Batch: 2174, Loss: 4.969315052032471\n",
      "Epoch: 1, Batch: 2175, Loss: 4.9121270179748535\n",
      "Epoch: 1, Batch: 2176, Loss: 4.891382694244385\n",
      "Epoch: 1, Batch: 2177, Loss: 4.8008503913879395\n",
      "Epoch: 1, Batch: 2178, Loss: 4.879132270812988\n",
      "Epoch: 1, Batch: 2179, Loss: 4.932359218597412\n",
      "Epoch: 1, Batch: 2180, Loss: 4.872032642364502\n",
      "Epoch: 1, Batch: 2181, Loss: 5.145543575286865\n",
      "Epoch: 1, Batch: 2182, Loss: 4.950763702392578\n",
      "Epoch: 1, Batch: 2183, Loss: 4.851075172424316\n",
      "Epoch: 1, Batch: 2184, Loss: 4.8968186378479\n",
      "Epoch: 1, Batch: 2185, Loss: 4.929605484008789\n",
      "Epoch: 1, Batch: 2186, Loss: 4.810382843017578\n",
      "Epoch: 1, Batch: 2187, Loss: 5.008768558502197\n",
      "Epoch: 1, Batch: 2188, Loss: 4.861384391784668\n",
      "Epoch: 1, Batch: 2189, Loss: 4.711568832397461\n",
      "Epoch: 1, Batch: 2190, Loss: 4.54958963394165\n",
      "Epoch: 1, Batch: 2191, Loss: 4.947848320007324\n",
      "Epoch: 1, Batch: 2192, Loss: 4.965664863586426\n",
      "Epoch: 1, Batch: 2193, Loss: 5.297414302825928\n",
      "Epoch: 1, Batch: 2194, Loss: 5.078065872192383\n",
      "Epoch: 1, Batch: 2195, Loss: 5.07439661026001\n",
      "Epoch: 1, Batch: 2196, Loss: 4.736807823181152\n",
      "Epoch: 1, Batch: 2197, Loss: 4.801473617553711\n",
      "Epoch: 1, Batch: 2198, Loss: 4.8962249755859375\n",
      "Epoch: 1, Batch: 2199, Loss: 4.933565616607666\n",
      "Epoch: 1, Batch: 2200, Loss: 5.135993957519531\n",
      "Epoch: 1, Batch: 2201, Loss: 5.064422130584717\n",
      "Epoch: 1, Batch: 2202, Loss: 5.004015922546387\n",
      "Epoch: 1, Batch: 2203, Loss: 4.938411712646484\n",
      "Epoch: 1, Batch: 2204, Loss: 4.9858527183532715\n",
      "Epoch: 1, Batch: 2205, Loss: 4.936398506164551\n",
      "Epoch: 1, Batch: 2206, Loss: 4.911542892456055\n",
      "Epoch: 1, Batch: 2207, Loss: 4.86453104019165\n",
      "Epoch: 1, Batch: 2208, Loss: 4.96841287612915\n",
      "Epoch: 1, Batch: 2209, Loss: 4.884422779083252\n",
      "Epoch: 1, Batch: 2210, Loss: 4.9681220054626465\n",
      "Epoch: 1, Batch: 2211, Loss: 4.952335834503174\n",
      "Epoch: 1, Batch: 2212, Loss: 4.873188495635986\n",
      "Epoch: 1, Batch: 2213, Loss: 4.98012113571167\n",
      "Epoch: 1, Batch: 2214, Loss: 5.002889156341553\n",
      "Epoch: 1, Batch: 2215, Loss: 5.215649127960205\n",
      "Epoch: 1, Batch: 2216, Loss: 5.199963092803955\n",
      "Epoch: 1, Batch: 2217, Loss: 5.001255512237549\n",
      "Epoch: 1, Batch: 2218, Loss: 4.710811138153076\n",
      "Epoch: 1, Batch: 2219, Loss: 4.639827251434326\n",
      "Epoch: 1, Batch: 2220, Loss: 5.000045299530029\n",
      "Epoch: 1, Batch: 2221, Loss: 4.9171552658081055\n",
      "Epoch: 1, Batch: 2222, Loss: 4.821542739868164\n",
      "Epoch: 1, Batch: 2223, Loss: 5.027166843414307\n",
      "Epoch: 1, Batch: 2224, Loss: 4.64060640335083\n",
      "Epoch: 1, Batch: 2225, Loss: 4.749250411987305\n",
      "Epoch: 1, Batch: 2226, Loss: 4.67386531829834\n",
      "Epoch: 1, Batch: 2227, Loss: 4.754775524139404\n",
      "Epoch: 1, Batch: 2228, Loss: 4.9070725440979\n",
      "Epoch: 1, Batch: 2229, Loss: 4.9751996994018555\n",
      "Epoch: 1, Batch: 2230, Loss: 4.949939727783203\n",
      "Epoch: 1, Batch: 2231, Loss: 4.799571514129639\n",
      "Epoch: 1, Batch: 2232, Loss: 4.818055629730225\n",
      "Epoch: 1, Batch: 2233, Loss: 4.70683479309082\n",
      "Epoch: 1, Batch: 2234, Loss: 5.00786018371582\n",
      "Epoch: 1, Batch: 2235, Loss: 4.843146800994873\n",
      "Epoch: 1, Batch: 2236, Loss: 4.9008331298828125\n",
      "Epoch: 1, Batch: 2237, Loss: 4.901233673095703\n",
      "Epoch: 1, Batch: 2238, Loss: 4.8307952880859375\n",
      "Epoch: 1, Batch: 2239, Loss: 4.97202730178833\n",
      "Epoch: 1, Batch: 2240, Loss: 5.024848461151123\n",
      "Epoch: 1, Batch: 2241, Loss: 4.880918979644775\n",
      "Epoch: 1, Batch: 2242, Loss: 4.966650485992432\n",
      "Epoch: 1, Batch: 2243, Loss: 4.687722682952881\n",
      "Epoch: 1, Batch: 2244, Loss: 4.675083160400391\n",
      "Epoch: 1, Batch: 2245, Loss: 4.980511665344238\n",
      "Epoch: 1, Batch: 2246, Loss: 5.279688835144043\n",
      "Epoch: 1, Batch: 2247, Loss: 5.0163893699646\n",
      "Epoch: 1, Batch: 2248, Loss: 4.838622093200684\n",
      "Epoch: 1, Batch: 2249, Loss: 5.02644157409668\n",
      "Epoch: 1, Batch: 2250, Loss: 4.458809852600098\n",
      "Epoch: 1, Batch: 2251, Loss: 5.032990455627441\n",
      "Epoch: 1, Batch: 2252, Loss: 4.786004543304443\n",
      "Epoch: 1, Batch: 2253, Loss: 4.951863765716553\n",
      "Epoch: 1, Batch: 2254, Loss: 4.97234582901001\n",
      "Epoch: 1, Batch: 2255, Loss: 4.986330986022949\n",
      "Epoch: 1, Batch: 2256, Loss: 4.891756534576416\n",
      "Epoch: 1, Batch: 2257, Loss: 4.9697089195251465\n",
      "Epoch: 1, Batch: 2258, Loss: 4.975412845611572\n",
      "Epoch: 1, Batch: 2259, Loss: 4.827567100524902\n",
      "Epoch: 1, Batch: 2260, Loss: 4.875339031219482\n",
      "Epoch: 1, Batch: 2261, Loss: 4.849451065063477\n",
      "Epoch: 1, Batch: 2262, Loss: 5.194253444671631\n",
      "Epoch: 1, Batch: 2263, Loss: 4.843468189239502\n",
      "Epoch: 1, Batch: 2264, Loss: 4.968977928161621\n",
      "Epoch: 1, Batch: 2265, Loss: 4.785258769989014\n",
      "Epoch: 1, Batch: 2266, Loss: 4.9244704246521\n",
      "Epoch: 1, Batch: 2267, Loss: 4.909771919250488\n",
      "Epoch: 1, Batch: 2268, Loss: 5.0420989990234375\n",
      "Epoch: 1, Batch: 2269, Loss: 5.09511137008667\n",
      "Epoch: 1, Batch: 2270, Loss: 4.764617919921875\n",
      "Epoch: 1, Batch: 2271, Loss: 4.886244773864746\n",
      "Epoch: 1, Batch: 2272, Loss: 4.70107889175415\n",
      "Epoch: 1, Batch: 2273, Loss: 4.709761142730713\n",
      "Epoch: 1, Batch: 2274, Loss: 4.7832136154174805\n",
      "Epoch: 1, Batch: 2275, Loss: 4.719973087310791\n",
      "Epoch: 1, Batch: 2276, Loss: 4.794756889343262\n",
      "Epoch: 1, Batch: 2277, Loss: 5.018119812011719\n",
      "Epoch: 1, Batch: 2278, Loss: 4.914299011230469\n",
      "Epoch: 1, Batch: 2279, Loss: 4.948126316070557\n",
      "Epoch: 1, Batch: 2280, Loss: 4.816995620727539\n",
      "Epoch: 1, Batch: 2281, Loss: 4.875884056091309\n",
      "Epoch: 1, Batch: 2282, Loss: 4.83049201965332\n",
      "Epoch: 1, Batch: 2283, Loss: 4.923393726348877\n",
      "Epoch: 1, Batch: 2284, Loss: 4.931920528411865\n",
      "Epoch: 1, Batch: 2285, Loss: 4.835722923278809\n",
      "Epoch: 1, Batch: 2286, Loss: 4.7831926345825195\n",
      "Epoch: 1, Batch: 2287, Loss: 4.791184902191162\n",
      "Epoch: 1, Batch: 2288, Loss: 5.008047103881836\n",
      "Epoch: 1, Batch: 2289, Loss: 4.757115364074707\n",
      "Epoch: 1, Batch: 2290, Loss: 4.857508182525635\n",
      "Epoch: 1, Batch: 2291, Loss: 4.969862461090088\n",
      "Epoch: 1, Batch: 2292, Loss: 4.913763046264648\n",
      "Epoch: 1, Batch: 2293, Loss: 4.956399917602539\n",
      "Epoch: 1, Batch: 2294, Loss: 4.967119216918945\n",
      "Epoch: 1, Batch: 2295, Loss: 4.8551506996154785\n",
      "Epoch: 1, Batch: 2296, Loss: 4.531867980957031\n",
      "Epoch: 1, Batch: 2297, Loss: 4.464751720428467\n",
      "Epoch: 1, Batch: 2298, Loss: 4.832942008972168\n",
      "Epoch: 1, Batch: 2299, Loss: 4.852075099945068\n",
      "Epoch: 1, Batch: 2300, Loss: 4.896171569824219\n",
      "Epoch: 1, Batch: 2301, Loss: 4.762729167938232\n",
      "Epoch: 1, Batch: 2302, Loss: 4.806722640991211\n",
      "Epoch: 1, Batch: 2303, Loss: 4.938045501708984\n",
      "Epoch: 1, Batch: 2304, Loss: 4.879263877868652\n",
      "Epoch: 1, Batch: 2305, Loss: 5.03382682800293\n",
      "Epoch: 1, Batch: 2306, Loss: 5.158194541931152\n",
      "Epoch: 1, Batch: 2307, Loss: 4.750990867614746\n",
      "Epoch: 1, Batch: 2308, Loss: 4.939024925231934\n",
      "Epoch: 1, Batch: 2309, Loss: 4.974155426025391\n",
      "Epoch: 1, Batch: 2310, Loss: 4.83569860458374\n",
      "Epoch: 1, Batch: 2311, Loss: 4.886236190795898\n",
      "Epoch: 1, Batch: 2312, Loss: 4.893734931945801\n",
      "Epoch: 1, Batch: 2313, Loss: 4.719831466674805\n",
      "Epoch: 1, Batch: 2314, Loss: 4.827515602111816\n",
      "Epoch: 1, Batch: 2315, Loss: 5.154877185821533\n",
      "Epoch: 1, Batch: 2316, Loss: 4.8122992515563965\n",
      "Epoch: 1, Batch: 2317, Loss: 4.903898239135742\n",
      "Epoch: 1, Batch: 2318, Loss: 4.997062683105469\n",
      "Epoch: 1, Batch: 2319, Loss: 4.724010467529297\n",
      "Epoch: 1, Batch: 2320, Loss: 4.685234069824219\n",
      "Epoch: 1, Batch: 2321, Loss: 4.748176574707031\n",
      "Epoch: 1, Batch: 2322, Loss: 4.736461639404297\n",
      "Epoch: 1, Batch: 2323, Loss: 4.875524520874023\n",
      "Epoch: 1, Batch: 2324, Loss: 5.011379241943359\n",
      "Epoch: 1, Batch: 2325, Loss: 5.009860038757324\n",
      "Epoch: 1, Batch: 2326, Loss: 4.791220664978027\n",
      "Epoch: 1, Batch: 2327, Loss: 4.842629432678223\n",
      "Epoch: 1, Batch: 2328, Loss: 4.671004772186279\n",
      "Epoch: 1, Batch: 2329, Loss: 5.1659932136535645\n",
      "Epoch: 1, Batch: 2330, Loss: 5.061433792114258\n",
      "Epoch: 1, Batch: 2331, Loss: 4.9161224365234375\n",
      "Epoch: 1, Batch: 2332, Loss: 4.8751749992370605\n",
      "Epoch: 1, Batch: 2333, Loss: 4.989903450012207\n",
      "Epoch: 1, Batch: 2334, Loss: 5.029120922088623\n",
      "Epoch: 1, Batch: 2335, Loss: 5.0741376876831055\n",
      "Epoch: 1, Batch: 2336, Loss: 4.907509803771973\n",
      "Epoch: 1, Batch: 2337, Loss: 4.949334621429443\n",
      "Epoch: 1, Batch: 2338, Loss: 4.751745223999023\n",
      "Epoch: 1, Batch: 2339, Loss: 4.7857537269592285\n",
      "Epoch: 1, Batch: 2340, Loss: 4.868038177490234\n",
      "Epoch: 1, Batch: 2341, Loss: 4.856925010681152\n",
      "Epoch: 1, Batch: 2342, Loss: 4.78466796875\n",
      "Epoch: 1, Batch: 2343, Loss: 4.934606552124023\n",
      "Epoch: 1, Batch: 2344, Loss: 4.854228496551514\n",
      "Epoch: 1, Batch: 2345, Loss: 4.885951995849609\n",
      "Epoch: 1, Batch: 2346, Loss: 4.808124542236328\n",
      "Epoch: 1, Batch: 2347, Loss: 4.9878458976745605\n",
      "Epoch: 1, Batch: 2348, Loss: 4.5824761390686035\n",
      "Epoch: 1, Batch: 2349, Loss: 4.845170497894287\n",
      "Epoch: 1, Batch: 2350, Loss: 4.809026718139648\n",
      "Epoch: 1, Batch: 2351, Loss: 5.015926837921143\n",
      "Epoch: 1, Batch: 2352, Loss: 5.052947998046875\n",
      "Epoch: 1, Batch: 2353, Loss: 4.849893093109131\n",
      "Epoch: 1, Batch: 2354, Loss: 4.7150750160217285\n",
      "Epoch: 1, Batch: 2355, Loss: 4.864569187164307\n",
      "Epoch: 1, Batch: 2356, Loss: 4.838582992553711\n",
      "Epoch: 1, Batch: 2357, Loss: 4.71404504776001\n",
      "Epoch: 1, Batch: 2358, Loss: 4.923331260681152\n",
      "Epoch: 1, Batch: 2359, Loss: 4.996635913848877\n",
      "Epoch: 1, Batch: 2360, Loss: 4.9232964515686035\n",
      "Epoch: 1, Batch: 2361, Loss: 4.903824806213379\n",
      "Epoch: 1, Batch: 2362, Loss: 4.810368537902832\n",
      "Epoch: 1, Batch: 2363, Loss: 4.929080963134766\n",
      "Epoch: 1, Batch: 2364, Loss: 4.83841609954834\n",
      "Epoch: 1, Batch: 2365, Loss: 4.798796653747559\n",
      "Epoch: 1, Batch: 2366, Loss: 4.910148620605469\n",
      "Epoch: 1, Batch: 2367, Loss: 4.935051918029785\n",
      "Epoch: 1, Batch: 2368, Loss: 4.918755054473877\n",
      "Epoch: 1, Batch: 2369, Loss: 4.721352577209473\n",
      "Epoch: 1, Batch: 2370, Loss: 4.9045634269714355\n",
      "Epoch: 1, Batch: 2371, Loss: 4.8903303146362305\n",
      "Epoch: 1, Batch: 2372, Loss: 4.770748615264893\n",
      "Epoch: 1, Batch: 2373, Loss: 4.8578081130981445\n",
      "Epoch: 1, Batch: 2374, Loss: 4.6760334968566895\n",
      "Epoch: 1, Batch: 2375, Loss: 4.8577094078063965\n",
      "Epoch: 1, Batch: 2376, Loss: 4.93577766418457\n",
      "Epoch: 1, Batch: 2377, Loss: 4.769019603729248\n",
      "Epoch: 1, Batch: 2378, Loss: 4.983272075653076\n",
      "Epoch: 1, Batch: 2379, Loss: 4.789164066314697\n",
      "Epoch: 1, Batch: 2380, Loss: 4.88848876953125\n",
      "Epoch: 1, Batch: 2381, Loss: 4.717940807342529\n",
      "Epoch: 1, Batch: 2382, Loss: 4.79479455947876\n",
      "Epoch: 1, Batch: 2383, Loss: 4.873015403747559\n",
      "Epoch: 1, Batch: 2384, Loss: 4.753848075866699\n",
      "Epoch: 1, Batch: 2385, Loss: 4.666786193847656\n",
      "Epoch: 1, Batch: 2386, Loss: 4.912637233734131\n",
      "Epoch: 1, Batch: 2387, Loss: 4.874466419219971\n",
      "Epoch: 1, Batch: 2388, Loss: 4.823974132537842\n",
      "Epoch: 1, Batch: 2389, Loss: 4.749638080596924\n",
      "Epoch: 1, Batch: 2390, Loss: 4.924534320831299\n",
      "Epoch: 1, Batch: 2391, Loss: 4.769362449645996\n",
      "Epoch: 1, Batch: 2392, Loss: 4.7743330001831055\n",
      "Epoch: 1, Batch: 2393, Loss: 4.585079193115234\n",
      "Epoch: 1, Batch: 2394, Loss: 5.0205230712890625\n",
      "Epoch: 1, Batch: 2395, Loss: 5.096783638000488\n",
      "Epoch: 1, Batch: 2396, Loss: 5.007641315460205\n",
      "Epoch: 1, Batch: 2397, Loss: 4.8858723640441895\n",
      "Epoch: 1, Batch: 2398, Loss: 4.960375785827637\n",
      "Epoch: 1, Batch: 2399, Loss: 5.092113971710205\n",
      "Epoch: 1, Batch: 2400, Loss: 4.923428058624268\n",
      "Epoch: 1, Batch: 2401, Loss: 4.829379081726074\n",
      "Epoch: 1, Batch: 2402, Loss: 4.683828353881836\n",
      "Epoch: 1, Batch: 2403, Loss: 4.921145439147949\n",
      "Epoch: 1, Batch: 2404, Loss: 4.864628791809082\n",
      "Epoch: 1, Batch: 2405, Loss: 5.098397731781006\n",
      "Epoch: 1, Batch: 2406, Loss: 4.863550662994385\n",
      "Epoch: 1, Batch: 2407, Loss: 4.847119331359863\n",
      "Epoch: 1, Batch: 2408, Loss: 4.887484550476074\n",
      "Epoch: 1, Batch: 2409, Loss: 4.94316291809082\n",
      "Epoch: 1, Batch: 2410, Loss: 4.897579669952393\n",
      "Epoch: 1, Batch: 2411, Loss: 4.7678728103637695\n",
      "Epoch: 1, Batch: 2412, Loss: 4.851974010467529\n",
      "Epoch: 1, Batch: 2413, Loss: 4.6870269775390625\n",
      "Epoch: 1, Batch: 2414, Loss: 5.054925918579102\n",
      "Epoch: 1, Batch: 2415, Loss: 5.100764751434326\n",
      "Epoch: 1, Batch: 2416, Loss: 4.861503601074219\n",
      "Epoch: 1, Batch: 2417, Loss: 4.711706161499023\n",
      "Epoch: 1, Batch: 2418, Loss: 4.820589065551758\n",
      "Epoch: 1, Batch: 2419, Loss: 4.986788749694824\n",
      "Epoch: 1, Batch: 2420, Loss: 5.052917003631592\n",
      "Epoch: 1, Batch: 2421, Loss: 4.789211750030518\n",
      "Epoch: 1, Batch: 2422, Loss: 5.150141716003418\n",
      "Epoch: 1, Batch: 2423, Loss: 4.776412010192871\n",
      "Epoch: 1, Batch: 2424, Loss: 4.753785610198975\n",
      "Epoch: 1, Batch: 2425, Loss: 4.815138339996338\n",
      "Epoch: 1, Batch: 2426, Loss: 4.986764907836914\n",
      "Epoch: 1, Batch: 2427, Loss: 5.144684314727783\n",
      "Epoch: 1, Batch: 2428, Loss: 4.81669282913208\n",
      "Epoch: 1, Batch: 2429, Loss: 4.840372562408447\n",
      "Epoch: 1, Batch: 2430, Loss: 4.723915100097656\n",
      "Epoch: 1, Batch: 2431, Loss: 4.76214075088501\n",
      "Epoch: 1, Batch: 2432, Loss: 4.858894348144531\n",
      "Epoch: 1, Batch: 2433, Loss: 4.726433753967285\n",
      "Epoch: 1, Batch: 2434, Loss: 5.044751167297363\n",
      "Epoch: 1, Batch: 2435, Loss: 4.965229511260986\n",
      "Epoch: 1, Batch: 2436, Loss: 5.017816543579102\n",
      "Epoch: 1, Batch: 2437, Loss: 4.947452068328857\n",
      "Epoch: 1, Batch: 2438, Loss: 4.792966365814209\n",
      "Epoch: 1, Batch: 2439, Loss: 4.826241493225098\n",
      "Epoch: 1, Batch: 2440, Loss: 4.743456840515137\n",
      "Epoch: 1, Batch: 2441, Loss: 4.74402379989624\n",
      "Epoch: 1, Batch: 2442, Loss: 4.7154130935668945\n",
      "Epoch: 1, Batch: 2443, Loss: 4.870931625366211\n",
      "Epoch: 1, Batch: 2444, Loss: 4.972774982452393\n",
      "Epoch: 1, Batch: 2445, Loss: 4.840811729431152\n",
      "Epoch: 1, Batch: 2446, Loss: 4.781187534332275\n",
      "Epoch: 1, Batch: 2447, Loss: 4.81776237487793\n",
      "Epoch: 1, Batch: 2448, Loss: 4.812952518463135\n",
      "Epoch: 1, Batch: 2449, Loss: 4.773743152618408\n",
      "Epoch: 1, Batch: 2450, Loss: 4.703270435333252\n",
      "Epoch: 1, Batch: 2451, Loss: 4.8353095054626465\n",
      "Epoch: 1, Batch: 2452, Loss: 4.799607276916504\n",
      "Epoch: 1, Batch: 2453, Loss: 4.561509132385254\n",
      "Epoch: 1, Batch: 2454, Loss: 5.059297561645508\n",
      "Epoch: 1, Batch: 2455, Loss: 4.892733573913574\n",
      "Epoch: 1, Batch: 2456, Loss: 4.858246326446533\n",
      "Epoch: 1, Batch: 2457, Loss: 4.533331871032715\n",
      "Epoch: 1, Batch: 2458, Loss: 4.798009872436523\n",
      "Epoch: 1, Batch: 2459, Loss: 5.040536880493164\n",
      "Epoch: 1, Batch: 2460, Loss: 5.052246570587158\n",
      "Epoch: 1, Batch: 2461, Loss: 5.134382247924805\n",
      "Epoch: 1, Batch: 2462, Loss: 4.910867691040039\n",
      "Epoch: 1, Batch: 2463, Loss: 4.6929850578308105\n",
      "Epoch: 1, Batch: 2464, Loss: 4.7815752029418945\n",
      "Epoch: 1, Batch: 2465, Loss: 5.07370662689209\n",
      "Epoch: 1, Batch: 2466, Loss: 4.673361778259277\n",
      "Epoch: 1, Batch: 2467, Loss: 4.935525417327881\n",
      "Epoch: 1, Batch: 2468, Loss: 4.880769729614258\n",
      "Epoch: 1, Batch: 2469, Loss: 4.757734298706055\n",
      "Epoch: 1, Batch: 2470, Loss: 4.9551897048950195\n",
      "Epoch: 1, Batch: 2471, Loss: 4.742065906524658\n",
      "Epoch: 1, Batch: 2472, Loss: 4.958654880523682\n",
      "Epoch: 1, Batch: 2473, Loss: 4.828639507293701\n",
      "Epoch: 1, Batch: 2474, Loss: 4.85627555847168\n",
      "Epoch: 1, Batch: 2475, Loss: 4.863824844360352\n",
      "Epoch: 1, Batch: 2476, Loss: 4.942491054534912\n",
      "Epoch: 1, Batch: 2477, Loss: 4.899765491485596\n",
      "Epoch: 1, Batch: 2478, Loss: 4.753849506378174\n",
      "Epoch: 1, Batch: 2479, Loss: 4.751276016235352\n",
      "Epoch: 1, Batch: 2480, Loss: 4.667078495025635\n",
      "Epoch: 1, Batch: 2481, Loss: 4.788838863372803\n",
      "Epoch: 1, Batch: 2482, Loss: 4.750023365020752\n",
      "Epoch: 1, Batch: 2483, Loss: 4.749631881713867\n",
      "Epoch: 1, Batch: 2484, Loss: 4.951597690582275\n",
      "Epoch: 1, Batch: 2485, Loss: 4.944891929626465\n",
      "Epoch: 1, Batch: 2486, Loss: 4.803009510040283\n",
      "Epoch: 1, Batch: 2487, Loss: 4.94420051574707\n",
      "Epoch: 1, Batch: 2488, Loss: 4.817231178283691\n",
      "Epoch: 1, Batch: 2489, Loss: 4.934659957885742\n",
      "Epoch: 1, Batch: 2490, Loss: 5.185133457183838\n",
      "Epoch: 1, Batch: 2491, Loss: 5.12819242477417\n",
      "Epoch: 1, Batch: 2492, Loss: 4.941783905029297\n",
      "Epoch: 1, Batch: 2493, Loss: 4.9973955154418945\n",
      "Epoch: 1, Batch: 2494, Loss: 4.6874470710754395\n",
      "Epoch: 1, Batch: 2495, Loss: 4.991301536560059\n",
      "Epoch: 1, Batch: 2496, Loss: 4.972702503204346\n",
      "Epoch: 1, Batch: 2497, Loss: 4.779834747314453\n",
      "Epoch: 1, Batch: 2498, Loss: 4.876802444458008\n",
      "Epoch: 1, Batch: 2499, Loss: 5.094619274139404\n",
      "Epoch: 1, Batch: 2500, Loss: 4.935755729675293\n",
      "Epoch: 1, Batch: 2501, Loss: 4.782268047332764\n",
      "Epoch: 1, Batch: 2502, Loss: 4.920881271362305\n",
      "Epoch: 1, Batch: 2503, Loss: 4.723860263824463\n",
      "Epoch: 1, Batch: 2504, Loss: 4.940309524536133\n",
      "Epoch: 1, Batch: 2505, Loss: 4.757518768310547\n",
      "Epoch: 1, Batch: 2506, Loss: 4.650121688842773\n",
      "Epoch: 1, Batch: 2507, Loss: 4.987183570861816\n",
      "Epoch: 1, Batch: 2508, Loss: 4.905460357666016\n",
      "Epoch: 1, Batch: 2509, Loss: 4.7189459800720215\n",
      "Epoch: 1, Batch: 2510, Loss: 4.829482078552246\n",
      "Epoch: 1, Batch: 2511, Loss: 4.627717018127441\n",
      "Epoch: 1, Batch: 2512, Loss: 4.8400654792785645\n",
      "Epoch: 1, Batch: 2513, Loss: 4.6755475997924805\n",
      "Epoch: 1, Batch: 2514, Loss: 4.792815208435059\n",
      "Epoch: 1, Batch: 2515, Loss: 4.777791976928711\n",
      "Epoch: 1, Batch: 2516, Loss: 4.966084003448486\n",
      "Epoch: 1, Batch: 2517, Loss: 4.810955047607422\n",
      "Epoch: 1, Batch: 2518, Loss: 4.623938083648682\n",
      "Epoch: 1, Batch: 2519, Loss: 5.014402389526367\n",
      "Epoch: 1, Batch: 2520, Loss: 4.916085720062256\n",
      "Epoch: 1, Batch: 2521, Loss: 5.003619194030762\n",
      "Epoch: 1, Batch: 2522, Loss: 4.7267842292785645\n",
      "Epoch: 1, Batch: 2523, Loss: 4.828393936157227\n",
      "Epoch: 1, Batch: 2524, Loss: 4.646383285522461\n",
      "Epoch: 1, Batch: 2525, Loss: 4.765781879425049\n",
      "Epoch: 1, Batch: 2526, Loss: 4.852227210998535\n",
      "Epoch: 1, Batch: 2527, Loss: 4.806304454803467\n",
      "Epoch: 1, Batch: 2528, Loss: 4.663541793823242\n",
      "Epoch: 1, Batch: 2529, Loss: 4.656862735748291\n",
      "Epoch: 1, Batch: 2530, Loss: 4.561956882476807\n",
      "Epoch: 1, Batch: 2531, Loss: 4.943781852722168\n",
      "Epoch: 1, Batch: 2532, Loss: 4.718113422393799\n",
      "Epoch: 1, Batch: 2533, Loss: 4.792255401611328\n",
      "Epoch: 1, Batch: 2534, Loss: 4.720053195953369\n",
      "Epoch: 1, Batch: 2535, Loss: 4.9588942527771\n",
      "Epoch: 1, Batch: 2536, Loss: 4.87855339050293\n",
      "Epoch: 1, Batch: 2537, Loss: 4.921383857727051\n",
      "Epoch: 1, Batch: 2538, Loss: 4.780636310577393\n",
      "Epoch: 1, Batch: 2539, Loss: 4.6496710777282715\n",
      "Epoch: 1, Batch: 2540, Loss: 4.7698822021484375\n",
      "Epoch: 1, Batch: 2541, Loss: 4.766362190246582\n",
      "Epoch: 1, Batch: 2542, Loss: 4.715424537658691\n",
      "Epoch: 1, Batch: 2543, Loss: 4.992903709411621\n",
      "Epoch: 1, Batch: 2544, Loss: 4.998817443847656\n",
      "Epoch: 1, Batch: 2545, Loss: 4.97489070892334\n",
      "Epoch: 1, Batch: 2546, Loss: 4.727240562438965\n",
      "Epoch: 1, Batch: 2547, Loss: 4.906561374664307\n",
      "Epoch: 1, Batch: 2548, Loss: 4.924164772033691\n",
      "Epoch: 1, Batch: 2549, Loss: 4.871617794036865\n",
      "Epoch: 1, Batch: 2550, Loss: 4.785305500030518\n",
      "Epoch: 1, Batch: 2551, Loss: 4.964869976043701\n",
      "Epoch: 1, Batch: 2552, Loss: 4.761704444885254\n",
      "Epoch: 1, Batch: 2553, Loss: 4.9174604415893555\n",
      "Epoch: 1, Batch: 2554, Loss: 4.933882236480713\n",
      "Epoch: 1, Batch: 2555, Loss: 4.9034905433654785\n",
      "Epoch: 1, Batch: 2556, Loss: 4.8964080810546875\n",
      "Epoch: 1, Batch: 2557, Loss: 4.959503173828125\n",
      "Epoch: 1, Batch: 2558, Loss: 4.668763160705566\n",
      "Epoch: 1, Batch: 2559, Loss: 4.6866536140441895\n",
      "Epoch: 1, Batch: 2560, Loss: 4.80220890045166\n",
      "Epoch: 1, Batch: 2561, Loss: 4.734933376312256\n",
      "Epoch: 1, Batch: 2562, Loss: 4.846180438995361\n",
      "Epoch: 1, Batch: 2563, Loss: 4.803886413574219\n",
      "Epoch: 1, Batch: 2564, Loss: 4.939658164978027\n",
      "Epoch: 1, Batch: 2565, Loss: 4.7887043952941895\n",
      "Epoch: 1, Batch: 2566, Loss: 4.839582443237305\n",
      "Epoch: 1, Batch: 2567, Loss: 4.834540367126465\n",
      "Epoch: 1, Batch: 2568, Loss: 4.8738932609558105\n",
      "Epoch: 1, Batch: 2569, Loss: 5.095611095428467\n",
      "Epoch: 1, Batch: 2570, Loss: 4.967075347900391\n",
      "Epoch: 1, Batch: 2571, Loss: 4.870216369628906\n",
      "Epoch: 1, Batch: 2572, Loss: 4.680992603302002\n",
      "Epoch: 1, Batch: 2573, Loss: 4.720126152038574\n",
      "Epoch: 1, Batch: 2574, Loss: 4.981514930725098\n",
      "Epoch: 1, Batch: 2575, Loss: 4.548008918762207\n",
      "Epoch: 1, Batch: 2576, Loss: 4.7072649002075195\n",
      "Epoch: 1, Batch: 2577, Loss: 4.774106979370117\n",
      "Epoch: 1, Batch: 2578, Loss: 4.875395774841309\n",
      "Epoch: 1, Batch: 2579, Loss: 4.849695682525635\n",
      "Epoch: 1, Batch: 2580, Loss: 4.5458269119262695\n",
      "Epoch: 1, Batch: 2581, Loss: 4.682458400726318\n",
      "Epoch: 1, Batch: 2582, Loss: 4.765321731567383\n",
      "Epoch: 1, Batch: 2583, Loss: 4.949682712554932\n",
      "Epoch: 1, Batch: 2584, Loss: 4.588103294372559\n",
      "Epoch: 1, Batch: 2585, Loss: 5.0251688957214355\n",
      "Epoch: 1, Batch: 2586, Loss: 5.027743339538574\n",
      "Epoch: 1, Batch: 2587, Loss: 5.149788856506348\n",
      "Epoch: 1, Batch: 2588, Loss: 4.77899694442749\n",
      "Epoch: 1, Batch: 2589, Loss: 4.678531169891357\n",
      "Epoch: 1, Batch: 2590, Loss: 4.701253414154053\n",
      "Epoch: 1, Batch: 2591, Loss: 4.670918941497803\n",
      "Epoch: 1, Batch: 2592, Loss: 4.97542142868042\n",
      "Epoch: 1, Batch: 2593, Loss: 4.676461219787598\n",
      "Epoch: 1, Batch: 2594, Loss: 4.441428184509277\n",
      "Epoch: 1, Batch: 2595, Loss: 4.889538288116455\n",
      "Epoch: 1, Batch: 2596, Loss: 4.9356889724731445\n",
      "Epoch: 1, Batch: 2597, Loss: 4.872046947479248\n",
      "Epoch: 1, Batch: 2598, Loss: 4.671037673950195\n",
      "Epoch: 1, Batch: 2599, Loss: 4.8185038566589355\n",
      "Epoch: 1, Batch: 2600, Loss: 4.958536624908447\n",
      "Epoch: 1, Batch: 2601, Loss: 4.793498516082764\n",
      "Epoch: 1, Batch: 2602, Loss: 4.670391082763672\n",
      "Epoch: 1, Batch: 2603, Loss: 4.854864120483398\n",
      "Epoch: 1, Batch: 2604, Loss: 4.810844898223877\n",
      "Epoch: 1, Batch: 2605, Loss: 4.997735023498535\n",
      "Epoch: 1, Batch: 2606, Loss: 4.856333255767822\n",
      "Epoch: 1, Batch: 2607, Loss: 5.013263702392578\n",
      "Epoch: 1, Batch: 2608, Loss: 4.702647686004639\n",
      "Epoch: 1, Batch: 2609, Loss: 4.833383560180664\n",
      "Epoch: 1, Batch: 2610, Loss: 4.72345495223999\n",
      "Epoch: 1, Batch: 2611, Loss: 4.6963090896606445\n",
      "Epoch: 1, Batch: 2612, Loss: 4.680840492248535\n",
      "Epoch: 1, Batch: 2613, Loss: 4.714591026306152\n",
      "Epoch: 1, Batch: 2614, Loss: 4.927783966064453\n",
      "Epoch: 1, Batch: 2615, Loss: 4.917491912841797\n",
      "Epoch: 1, Batch: 2616, Loss: 4.569050312042236\n",
      "Epoch: 1, Batch: 2617, Loss: 5.001551151275635\n",
      "Epoch: 1, Batch: 2618, Loss: 4.718272686004639\n",
      "Epoch: 1, Batch: 2619, Loss: 5.033083915710449\n",
      "Epoch: 1, Batch: 2620, Loss: 4.851443767547607\n",
      "Epoch: 1, Batch: 2621, Loss: 4.860572338104248\n",
      "Epoch: 1, Batch: 2622, Loss: 4.8387651443481445\n",
      "Epoch: 1, Batch: 2623, Loss: 4.798525810241699\n",
      "Epoch: 1, Batch: 2624, Loss: 4.761422634124756\n",
      "Epoch: 1, Batch: 2625, Loss: 4.9441304206848145\n",
      "Epoch: 1, Batch: 2626, Loss: 4.727841377258301\n",
      "Epoch: 1, Batch: 2627, Loss: 4.796599388122559\n",
      "Epoch: 1, Batch: 2628, Loss: 4.839443206787109\n",
      "Epoch: 1, Batch: 2629, Loss: 4.6966423988342285\n",
      "Epoch: 1, Batch: 2630, Loss: 4.764802932739258\n",
      "Epoch: 1, Batch: 2631, Loss: 4.778889179229736\n",
      "Epoch: 1, Batch: 2632, Loss: 5.026126384735107\n",
      "Epoch: 1, Batch: 2633, Loss: 4.890202045440674\n",
      "Epoch: 1, Batch: 2634, Loss: 4.816679954528809\n",
      "Epoch: 1, Batch: 2635, Loss: 4.6792826652526855\n",
      "Epoch: 1, Batch: 2636, Loss: 4.698732376098633\n",
      "Epoch: 1, Batch: 2637, Loss: 4.84659481048584\n",
      "Epoch: 1, Batch: 2638, Loss: 4.846202850341797\n",
      "Epoch: 1, Batch: 2639, Loss: 4.672939777374268\n",
      "Epoch: 1, Batch: 2640, Loss: 4.696591854095459\n",
      "Epoch: 1, Batch: 2641, Loss: 4.853942394256592\n",
      "Epoch: 1, Batch: 2642, Loss: 4.664852142333984\n",
      "Epoch: 1, Batch: 2643, Loss: 4.869297981262207\n",
      "Epoch: 1, Batch: 2644, Loss: 4.839288234710693\n",
      "Epoch: 1, Batch: 2645, Loss: 4.811361312866211\n",
      "Epoch: 1, Batch: 2646, Loss: 4.9405646324157715\n",
      "Epoch: 1, Batch: 2647, Loss: 4.558839797973633\n",
      "Epoch: 1, Batch: 2648, Loss: 4.597585678100586\n",
      "Epoch: 1, Batch: 2649, Loss: 4.980900287628174\n",
      "Epoch: 1, Batch: 2650, Loss: 4.7806878089904785\n",
      "Epoch: 1, Batch: 2651, Loss: 5.114148139953613\n",
      "Epoch: 1, Batch: 2652, Loss: 4.893580436706543\n",
      "Epoch: 1, Batch: 2653, Loss: 4.857833385467529\n",
      "Epoch: 1, Batch: 2654, Loss: 4.9018402099609375\n",
      "Epoch: 1, Batch: 2655, Loss: 4.933248996734619\n",
      "Epoch: 1, Batch: 2656, Loss: 4.687466144561768\n",
      "Epoch: 1, Batch: 2657, Loss: 4.868878364562988\n",
      "Epoch: 1, Batch: 2658, Loss: 4.847595691680908\n",
      "Epoch: 1, Batch: 2659, Loss: 4.645774841308594\n",
      "Epoch: 1, Batch: 2660, Loss: 5.016209602355957\n",
      "Epoch: 1, Batch: 2661, Loss: 4.623586177825928\n",
      "Epoch: 1, Batch: 2662, Loss: 4.996998310089111\n",
      "Epoch: 1, Batch: 2663, Loss: 4.851227760314941\n",
      "Epoch: 1, Batch: 2664, Loss: 4.686529159545898\n",
      "Epoch: 1, Batch: 2665, Loss: 4.67491340637207\n",
      "Epoch: 1, Batch: 2666, Loss: 4.739675521850586\n",
      "Epoch: 1, Batch: 2667, Loss: 4.762645721435547\n",
      "Epoch: 1, Batch: 2668, Loss: 4.8201398849487305\n",
      "Epoch: 1, Batch: 2669, Loss: 4.730285167694092\n",
      "Epoch: 1, Batch: 2670, Loss: 4.767602443695068\n",
      "Epoch: 1, Batch: 2671, Loss: 4.804533958435059\n",
      "Epoch: 1, Batch: 2672, Loss: 4.632800579071045\n",
      "Epoch: 1, Batch: 2673, Loss: 4.988785743713379\n",
      "Epoch: 1, Batch: 2674, Loss: 4.697498798370361\n",
      "Epoch: 1, Batch: 2675, Loss: 4.9643096923828125\n",
      "Epoch: 1, Batch: 2676, Loss: 4.858538627624512\n",
      "Epoch: 1, Batch: 2677, Loss: 4.718198299407959\n",
      "Epoch: 1, Batch: 2678, Loss: 4.702899932861328\n",
      "Epoch: 1, Batch: 2679, Loss: 4.773589611053467\n",
      "Epoch: 1, Batch: 2680, Loss: 4.341660499572754\n",
      "Epoch: 1, Batch: 2681, Loss: 4.751410961151123\n",
      "Epoch: 1, Batch: 2682, Loss: 4.756497859954834\n",
      "Epoch: 1, Batch: 2683, Loss: 4.678847789764404\n",
      "Epoch: 1, Batch: 2684, Loss: 4.5726542472839355\n",
      "Epoch: 1, Batch: 2685, Loss: 5.064831733703613\n",
      "Epoch: 1, Batch: 2686, Loss: 4.873964309692383\n",
      "Epoch: 1, Batch: 2687, Loss: 4.966323375701904\n",
      "Epoch: 1, Batch: 2688, Loss: 4.569249153137207\n",
      "Epoch: 1, Batch: 2689, Loss: 4.883242607116699\n",
      "Epoch: 1, Batch: 2690, Loss: 4.678173065185547\n",
      "Epoch: 1, Batch: 2691, Loss: 4.931577205657959\n",
      "Epoch: 1, Batch: 2692, Loss: 4.658545017242432\n",
      "Epoch: 1, Batch: 2693, Loss: 4.9050750732421875\n",
      "Epoch: 1, Batch: 2694, Loss: 4.9529314041137695\n",
      "Epoch: 1, Batch: 2695, Loss: 5.035980224609375\n",
      "Epoch: 1, Batch: 2696, Loss: 4.583569526672363\n",
      "Epoch: 1, Batch: 2697, Loss: 4.72313117980957\n",
      "Epoch: 1, Batch: 2698, Loss: 4.73185396194458\n",
      "Epoch: 1, Batch: 2699, Loss: 4.79503059387207\n",
      "Epoch: 1, Batch: 2700, Loss: 4.760558128356934\n",
      "Epoch: 1, Batch: 2701, Loss: 4.77951717376709\n",
      "Epoch: 1, Batch: 2702, Loss: 4.66572380065918\n",
      "Epoch: 1, Batch: 2703, Loss: 4.584920883178711\n",
      "Epoch: 1, Batch: 2704, Loss: 4.546980857849121\n",
      "Epoch: 1, Batch: 2705, Loss: 4.685451507568359\n",
      "Epoch: 1, Batch: 2706, Loss: 4.7645087242126465\n",
      "Epoch: 1, Batch: 2707, Loss: 4.738148212432861\n",
      "Epoch: 1, Batch: 2708, Loss: 4.744737148284912\n",
      "Epoch: 1, Batch: 2709, Loss: 4.738363742828369\n",
      "Epoch: 1, Batch: 2710, Loss: 4.8176493644714355\n",
      "Epoch: 1, Batch: 2711, Loss: 4.689678192138672\n",
      "Epoch: 1, Batch: 2712, Loss: 4.606689929962158\n",
      "Epoch: 1, Batch: 2713, Loss: 4.949295520782471\n",
      "Epoch: 1, Batch: 2714, Loss: 4.966814041137695\n",
      "Epoch: 1, Batch: 2715, Loss: 4.755833148956299\n",
      "Epoch: 1, Batch: 2716, Loss: 4.83717155456543\n",
      "Epoch: 1, Batch: 2717, Loss: 4.818953514099121\n",
      "Epoch: 1, Batch: 2718, Loss: 4.742919921875\n",
      "Epoch: 1, Batch: 2719, Loss: 4.849787712097168\n",
      "Epoch: 1, Batch: 2720, Loss: 4.687208652496338\n",
      "Epoch: 1, Batch: 2721, Loss: 4.564304828643799\n",
      "Epoch: 1, Batch: 2722, Loss: 4.847185134887695\n",
      "Epoch: 1, Batch: 2723, Loss: 4.898630619049072\n",
      "Epoch: 1, Batch: 2724, Loss: 4.801893711090088\n",
      "Epoch: 1, Batch: 2725, Loss: 4.933959484100342\n",
      "Epoch: 1, Batch: 2726, Loss: 4.799520015716553\n",
      "Epoch: 1, Batch: 2727, Loss: 4.670418739318848\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[485]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m ratings_train_batch = ratings_train[batch_indices]\n\u001b[32m     28\u001b[39m output:torch.Tensor = transformer(user_ids_batch.to(device=device), intervals_train_batch.to(device=device), genres_train_batch.to(device=device), years_train_batch.to(device=device), ratings_train_batch.to(device=device), movie_ids_src_train_batch.to(device=device), movie_ids_tgt_train_batch[:, :-\u001b[32m1\u001b[39m].to(device=device))\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m loss:torch.Tensor = criterion(output.contiguous().view(-\u001b[32m1\u001b[39m, movie_id_vocab_size), \u001b[43mmovie_ids_tgt_train_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m.contiguous().view(-\u001b[32m1\u001b[39m))\n\u001b[32m     31\u001b[39m loss.backward()\n\u001b[32m     32\u001b[39m optimizer.step()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 50    # number of epochs to run\n",
    "batch_size = 128  # size of each batch\n",
    "batches_per_epoch = movie_ids_src_train.shape[0] // batch_size\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.001)\n",
    "lr_scheduler = CosineWarmupScheduler(optimizer, warmup=50, max_iters=batches_per_epoch*n_epochs)\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    indices = torch.randperm(movie_ids_src_train.shape[0])\n",
    "\n",
    "    for i in range(batches_per_epoch):\n",
    "        optimizer.zero_grad()\n",
    "        start = i * batch_size\n",
    "        batch_indices = indices[start:start+batch_size]\n",
    "\n",
    "        movie_ids_src_train_batch = movie_ids_src_train[batch_indices]\n",
    "        movie_ids_tgt_train_batch = movie_ids_tgt_train[batch_indices]\n",
    "\n",
    "        user_ids_batch = user_ids_train[batch_indices]\n",
    "        intervals_train_batch = intervals_train[batch_indices]\n",
    "        genres_train_batch = genres_train[batch_indices].to(dtype=torch.float32)\n",
    "        years_train_batch = years_train[batch_indices]\n",
    "        ratings_train_batch = ratings_train[batch_indices]\n",
    "\n",
    "        output:torch.Tensor = transformer(user_ids_batch.to(device=device), intervals_train_batch.to(device=device), genres_train_batch.to(device=device), years_train_batch.to(device=device), ratings_train_batch.to(device=device), movie_ids_src_train_batch.to(device=device), movie_ids_tgt_train_batch[:, :-1].to(device=device))\n",
    "        loss:torch.Tensor = criterion(output.contiguous().view(-1, movie_id_vocab_size), movie_ids_tgt_train_batch[:, 1:].to(device=device).contiguous().view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1}, Batch: {i+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.groupby(by=[\"userId\"]).agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[2997, 2966, 2890, 3078, 2882, 541, 838, 1136,...</td>\n",
       "      <td>[4.0, 1.0, 4.0, 2.0, 1.0, 5.0, 5.0, 1.0, 5.0, ...</td>\n",
       "      <td>[943226846, 943226846, 943226916, 943226986, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[2012, 466, 2268, 168, 1544, 4306, 1485, 2617,...</td>\n",
       "      <td>[3.0, 1.0, 4.0, 3.5, 4.0, 3.5, 4.0, 4.0, 3.5, ...</td>\n",
       "      <td>[1084484354, 1084484362, 1084484382, 108448438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[48, 2006, 1954, 1909, 1690, 5218, 858, 733, 4...</td>\n",
       "      <td>[3.5, 2.0, 3.5, 2.5, 2.0, 4.0, 5.0, 4.5, 3.5, ...</td>\n",
       "      <td>[1169260535, 1169260570, 1169260574, 116926059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>[1196, 2571, 7153, 2353, 3994, 2006, 1198, 499...</td>\n",
       "      <td>[0.5, 2.0, 4.0, 4.5, 3.5, 1.0, 3.5, 4.0, 4.0, ...</td>\n",
       "      <td>[1517020327, 1517020360, 1517020362, 151702040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>[3252, 1894, 2467, 3159, 4823, 4681, 64839, 48...</td>\n",
       "      <td>[4.0, 0.5, 4.0, 4.5, 1.0, 4.0, 3.5, 3.0, 2.5, ...</td>\n",
       "      <td>[1251917373, 1251917516, 1251917545, 125191760...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200939</th>\n",
       "      <td>200940</td>\n",
       "      <td>[2020, 2915, 2064, 830, 637, 743, 2116, 3704, ...</td>\n",
       "      <td>[4.0, 3.5, 3.5, 2.5, 2.0, 2.0, 0.5, 1.0, 4.5, ...</td>\n",
       "      <td>[1194106282, 1194106296, 1194106299, 119410632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200942</th>\n",
       "      <td>200943</td>\n",
       "      <td>[1957, 4321, 2478, 2686, 1779, 2046, 2528, 309...</td>\n",
       "      <td>[3.0, 2.0, 1.0, 4.5, 2.0, 1.5, 2.0, 2.5, 2.0, ...</td>\n",
       "      <td>[1225217623, 1225217626, 1225217651, 122521766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200943</th>\n",
       "      <td>200944</td>\n",
       "      <td>[260, 1196, 318, 2571, 1291, 7153, 1210, 13413...</td>\n",
       "      <td>[4.0, 3.5, 5.0, 5.0, 3.5, 5.0, 4.0, 5.0, 3.0, ...</td>\n",
       "      <td>[1454247309, 1454247312, 1454247318, 145424732...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200944</th>\n",
       "      <td>200945</td>\n",
       "      <td>[318, 8874, 2762, 92259, 79132, 593, 1246, 168...</td>\n",
       "      <td>[5.0, 2.5, 4.0, 5.0, 5.0, 4.0, 3.5, 4.0, 4.0, ...</td>\n",
       "      <td>[1517070023, 1517070056, 1517070090, 151707009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200947</th>\n",
       "      <td>200948</td>\n",
       "      <td>[2300, 2616, 2431, 2137, 3450, 2384, 3986, 147...</td>\n",
       "      <td>[1.0, 2.5, 3.5, 2.5, 2.5, 3.0, 4.5, 5.0, 0.5, ...</td>\n",
       "      <td>[1203425370, 1203425388, 1203425392, 120342540...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79714 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId                                            movieId  \\\n",
       "0            1  [2997, 2966, 2890, 3078, 2882, 541, 838, 1136,...   \n",
       "2            3  [2012, 466, 2268, 168, 1544, 4306, 1485, 2617,...   \n",
       "9           10  [48, 2006, 1954, 1909, 1690, 5218, 858, 733, 4...   \n",
       "15          16  [1196, 2571, 7153, 2353, 3994, 2006, 1198, 499...   \n",
       "17          18  [3252, 1894, 2467, 3159, 4823, 4681, 64839, 48...   \n",
       "...        ...                                                ...   \n",
       "200939  200940  [2020, 2915, 2064, 830, 637, 743, 2116, 3704, ...   \n",
       "200942  200943  [1957, 4321, 2478, 2686, 1779, 2046, 2528, 309...   \n",
       "200943  200944  [260, 1196, 318, 2571, 1291, 7153, 1210, 13413...   \n",
       "200944  200945  [318, 8874, 2762, 92259, 79132, 593, 1246, 168...   \n",
       "200947  200948  [2300, 2616, 2431, 2137, 3450, 2384, 3986, 147...   \n",
       "\n",
       "                                                   rating  \\\n",
       "0       [4.0, 1.0, 4.0, 2.0, 1.0, 5.0, 5.0, 1.0, 5.0, ...   \n",
       "2       [3.0, 1.0, 4.0, 3.5, 4.0, 3.5, 4.0, 4.0, 3.5, ...   \n",
       "9       [3.5, 2.0, 3.5, 2.5, 2.0, 4.0, 5.0, 4.5, 3.5, ...   \n",
       "15      [0.5, 2.0, 4.0, 4.5, 3.5, 1.0, 3.5, 4.0, 4.0, ...   \n",
       "17      [4.0, 0.5, 4.0, 4.5, 1.0, 4.0, 3.5, 3.0, 2.5, ...   \n",
       "...                                                   ...   \n",
       "200939  [4.0, 3.5, 3.5, 2.5, 2.0, 2.0, 0.5, 1.0, 4.5, ...   \n",
       "200942  [3.0, 2.0, 1.0, 4.5, 2.0, 1.5, 2.0, 2.5, 2.0, ...   \n",
       "200943  [4.0, 3.5, 5.0, 5.0, 3.5, 5.0, 4.0, 5.0, 3.0, ...   \n",
       "200944  [5.0, 2.5, 4.0, 5.0, 5.0, 4.0, 3.5, 4.0, 4.0, ...   \n",
       "200947  [1.0, 2.5, 3.5, 2.5, 2.5, 3.0, 4.5, 5.0, 0.5, ...   \n",
       "\n",
       "                                                timestamp  \n",
       "0       [943226846, 943226846, 943226916, 943226986, 9...  \n",
       "2       [1084484354, 1084484362, 1084484382, 108448438...  \n",
       "9       [1169260535, 1169260570, 1169260574, 116926059...  \n",
       "15      [1517020327, 1517020360, 1517020362, 151702040...  \n",
       "17      [1251917373, 1251917516, 1251917545, 125191760...  \n",
       "...                                                   ...  \n",
       "200939  [1194106282, 1194106296, 1194106299, 119410632...  \n",
       "200942  [1225217623, 1225217626, 1225217651, 122521766...  \n",
       "200943  [1454247309, 1454247312, 1454247318, 145424732...  \n",
       "200944  [1517070023, 1517070056, 1517070090, 151707009...  \n",
       "200947  [1203425370, 1203425388, 1203425392, 120342540...  \n",
       "\n",
       "[79714 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.movieId.apply(len) > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4294967296"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = torch.tensor(df2['userId'].tolist(), dtype=torch.uint32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2.loc[1, 'movieId'][-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids_src, movie_ids_tgt = [], []\n",
    "for i in range(df2.shape[0]):\n",
    "    h = df2.loc[i, 'movieId'][-100:]\n",
    "    h = h + [0]*(100-len(h))\n",
    "    movie_ids_src += [h[:50]]\n",
    "    movie_ids_tgt += [h[50:]]\n",
    "    \n",
    "movie_ids_src = torch.tensor(movie_ids_src, dtype=torch.uint32)\n",
    "movie_ids_tgt = torch.tensor(movie_ids_tgt, dtype=torch.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_src, ts_tgt = [], []\n",
    "for i in range(df2.shape[0]):\n",
    "    h = df2.loc[i, 'timestamp'][-100:]\n",
    "    for j in range(len(h)-1, 0, -1):\n",
    "        h[j] = h[j]-h[j-1]+1\n",
    "    h[0] = 1\n",
    "    h = h + [0]*(100-len(h))\n",
    "    ts_src += [h[:50]]\n",
    "    ts_tgt += [h[50:]]\n",
    "    \n",
    "ts_src = torch.tensor(ts_src, dtype=torch.uint64)\n",
    "ts_tgt = torch.tensor(ts_tgt, dtype=torch.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,   2,   1,  36,   1,   1,   1,  30,   1,   1,  19,  25,   1,   1,\n",
       "        122,   1,  17,   1,   1,  25,  44,   1,  91,   1,  23,  54, 194,   1,\n",
       "          1,  17,   1,   1,  17,   1,  20,   1,  15,  25,  12,  15,   1,  15,\n",
       "          1,  13,  18,   1,  53,   1,  13,  19,  17, 117,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0], dtype=torch.uint64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = df2.shape[0]\n",
    "m = int(0.8*n)\n",
    "\n",
    "user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserNetwork(nn.Module):\n",
    "    def __init__(self, user_vocab_size, user_d_model, user_ffd, dropout=0.0) -> None:\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.user_embedding = nn.Embedding(user_vocab_size, user_d_model)\n",
    "\n",
    "        self.ffn_1 = nn.Linear(user_d_model, user_ffd)\n",
    "        self.ffn_2 = nn.Linear(user_ffd, user_d_model)\n",
    "\n",
    "        init_weights(self.ffn_1)\n",
    "        init_weights(self.ffn_2)\n",
    "\n",
    "        self.ffn = \\\n",
    "            nn.Sequential(\n",
    "                self.ffn_1,\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(inplace=True),\n",
    "                self.ffn_2\n",
    "            ) \n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        user_embed = self.user_embedding(x)\n",
    "        return self.ffn(user_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id, predict next sequence of movies to watch\n",
    "user_id, predict next sequence of movies to watch (attention scores weighted by ratings)\n",
    "user_id  predict rating for next movie based on watch history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest increasing subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_increasing_subsequence(arr):\n",
    "    f = [float(\"inf\")]*len(arr) # f[i] - smallest value corresponding to last element for i+1 length increasing subsequence\n",
    "    g = [0]*len(arr)\n",
    "\n",
    "    max_p = 0\n",
    "    for i in range(len(arr)):\n",
    "        u = arr[i]\n",
    "        left, right = 0, len(f)-1\n",
    "        p = -1\n",
    "        while left <= right:\n",
    "            mid = int((left+right)/2)\n",
    "            if f[mid] <= u:\n",
    "                p = mid\n",
    "                left = mid+1\n",
    "            else:\n",
    "                right = mid-1\n",
    "\n",
    "        f[p+1] = min(f[p+1], u)\n",
    "        max_p = max(max_p, p+2)\n",
    "        g[i] = p+2\n",
    "\n",
    "    out = []\n",
    "    h = max_p\n",
    "    for i in range(len(arr)-1, -1, -1):\n",
    "        if g[i] == h and (len(out) == 0 or arr[i] <= out[-1]):\n",
    "            out += [arr[i]]\n",
    "            h -= 1\n",
    "\n",
    "    return out[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[501, 925, 159, 179, 292, 610, 643, 234, 553, 793, 742, 132, 842, 250, 770, 348, 758, 624, 236, 650, 435, 815, 790, 558, 51, 823, 923, 35, 153, 708, 178, 623, 930, 756, 182, 666, 781, 693, 652, 773, 894, 996, 319, 711, 822, 133, 748, 575, 354, 998, 45, 792, 49, 492, 52, 131, 297, 549, 255, 601, 215, 352, 785, 281, 266, 999, 599, 715, 527, 683, 72, 130, 302, 224, 543, 873, 759, 936, 197, 468, 430, 926, 96, 37, 412, 136, 315, 256, 583, 422, 491, 434, 723, 617, 864, 476, 544, 698, 561, 363]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "h = random.sample(range(1, 1000), k=100)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[159, 179, 234, 250, 348, 435, 558, 623, 666, 693, 711, 748, 785, 873, 926]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_increasing_subsequence(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
