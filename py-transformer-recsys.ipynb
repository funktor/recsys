{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amondal/recsys/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import math\n",
    "import os\n",
    "import urllib.request\n",
    "from functools import partial\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.set_cmap(\"cividis\")\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(seq_len, d_model) # (seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # sin(position * (10000 ** (2i / d_model)) # (seq_len, d_model)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # cos(position * (10000 ** (2i / d_model)) # (seq_len, d_model)\n",
    "        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "        self.register_buffer('pe', pe, persistent=False)\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False) # (batch, seq_len, d_model)   \n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q:torch.Tensor, k:torch.Tensor, v:torch.Tensor, mask=None):\n",
    "    d_k = q.size()[-1] # q,k,v : (batch, head, seq_len, embed_size_per_head)\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1)) # (batch, head, seq_len, seq_len)\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v) # (batch, head, seq_len, embed_size_per_head)\n",
    "    return values, attention\n",
    "\n",
    "def init_weights(x:nn.Linear):\n",
    "    with torch.no_grad():\n",
    "        nn.init.xavier_uniform_(x.weight)\n",
    "        x.bias.data.fill_(0)\n",
    "\n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self, input_dim:int, d_model: int, h: int) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "\n",
    "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
    "\n",
    "        self.d_k = d_model // h\n",
    "\n",
    "        self.w_q = nn.Linear(input_dim, d_model) # Wq\n",
    "        self.w_k = nn.Linear(input_dim, d_model) # Wk\n",
    "        self.w_v = nn.Linear(input_dim, d_model) # Wv\n",
    "        self.w_o = nn.Linear(d_model, d_model) # Wo\n",
    "\n",
    "        init_weights(self.w_q)\n",
    "        init_weights(self.w_k)\n",
    "        init_weights(self.w_v)\n",
    "        init_weights(self.w_o)\n",
    "\n",
    "    def forward(self, q_x:torch.Tensor, k_x:torch.Tensor, v_x:torch.Tensor, mask=None):\n",
    "        q:torch.Tensor = self.w_q(q_x) # (batch, seq_len, d_model)\n",
    "        k:torch.Tensor = self.w_k(k_x) # (batch, seq_len, d_model)\n",
    "        v:torch.Tensor = self.w_v(v_x) # (batch, seq_len, d_model)\n",
    "\n",
    "        q_h = q.reshape(q.shape[0], q.shape[1], self.h, self.d_k).transpose(1, 2) # (batch, head, seq_len, d_k)\n",
    "        k_h = k.reshape(k.shape[0], k.shape[1], self.h, self.d_k).transpose(1, 2) # (batch, head, seq_len, d_k)\n",
    "        v_h = v.reshape(v.shape[0], v.shape[1], self.h, self.d_k).transpose(1, 2) # (batch, head, seq_len, d_k)\n",
    "\n",
    "        attn_out, _ = attention(q_h, k_h, v_h, mask) # (batch, head, seq_len, embed_size_per_head)\n",
    "        attn_out = attn_out.transpose(1, 2) # (batch, seq_len, head, embed_size_per_head)\n",
    "        attn_out = attn_out.reshape(attn_out.shape[0], attn_out.shape[1], attn_out.shape[2]*attn_out.shape[3]) # (batch, seq_len, d_model)\n",
    "\n",
    "        return self.w_o(attn_out) # (batch, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadAttentionBlock(input_dim, input_dim, num_heads)\n",
    "\n",
    "        self.ffn_1 = nn.Linear(input_dim, dim_feedforward)\n",
    "        self.ffn_2 = nn.Linear(dim_feedforward, input_dim)\n",
    "\n",
    "        init_weights(self.ffn_1)\n",
    "        init_weights(self.ffn_2)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            self.ffn_1,\n",
    "            nn.Dropout(dropout),\n",
    "            nn.GELU(),\n",
    "            self.ffn_2,\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_out = self.self_attn(x, x, x, mask=mask) # (batch, seq_len, input_dim)\n",
    "        x = x + self.dropout(attn_out) # (batch, seq_len, input_dim)\n",
    "        x = self.norm1(x) # (batch, seq_len, input_dim)\n",
    "\n",
    "        ffn_out = self.ffn(x) # (batch, seq_len, input_dim)\n",
    "        x = x + self.dropout(ffn_out) # (batch, seq_len, input_dim)\n",
    "        x = self.norm2(x) # (batch, seq_len, input_dim)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dim_feedforward, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderBlock(d_model, num_heads, dim_feedforward, dropout) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask=mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0)->None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadAttentionBlock(input_dim, input_dim, num_heads)\n",
    "        self.crss_attn = MultiHeadAttentionBlock(input_dim, input_dim, num_heads)\n",
    "\n",
    "        self.ffn_1 = nn.Linear(input_dim, dim_feedforward)\n",
    "        self.ffn_2 = nn.Linear(dim_feedforward, input_dim)\n",
    "\n",
    "        init_weights(self.ffn_1)\n",
    "        init_weights(self.ffn_2)\n",
    "        \n",
    "        self.ffn = nn.Sequential(\n",
    "            self.ffn_1,\n",
    "            nn.Dropout(dropout),\n",
    "            nn.GELU(),\n",
    "            self.ffn_2,\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.norm3 = nn.LayerNorm(input_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, pred_mask, pad_mask):\n",
    "        self_attn_out = self.self_attn(x, x, x, mask=pred_mask) # (batch, seq_len, input_dim)\n",
    "        x = x + self.dropout(self_attn_out) # (batch, seq_len, input_dim)\n",
    "        x = self.norm1(x) # (batch, seq_len, input_dim)\n",
    "\n",
    "        crss_attn_out = self.crss_attn(x, encoder_output, encoder_output, mask=pad_mask) # (batch, seq_len, input_dim)\n",
    "        x = x + self.dropout(crss_attn_out) # (batch, seq_len, input_dim)\n",
    "        x = self.norm2(x) # (batch, seq_len, input_dim)\n",
    "\n",
    "        ffn_out = self.ffn(x) # (batch, seq_len, input_dim)\n",
    "        x = x + self.dropout(ffn_out) # (batch, seq_len, input_dim)\n",
    "        x = self.norm3(x) # (batch, seq_len, input_dim)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([DecoderBlock(d_model, num_heads, dim_feedforward, dropout) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, encoder_output, pred_mask=None, pad_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, pred_mask, pad_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieEncoder(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            movie_vocab_size, \n",
    "            genres_vocab_size, \n",
    "            years_vocab_size, \n",
    "            embedding_size, \n",
    "            dropout=0.0\n",
    "        ) -> None:\n",
    "        \n",
    "        super(MovieEncoder, self).__init__()\n",
    "        \n",
    "        self.movie_embedding_layer = nn.Embedding(movie_vocab_size, embedding_size)\n",
    "        self.years_embedding_layer = nn.Embedding(years_vocab_size, 32)\n",
    "\n",
    "        self.genres_encoder_layer = nn.Linear(genres_vocab_size, 4)\n",
    "        init_weights(self.genres_encoder_layer)\n",
    "\n",
    "        self.fc_concat = nn.Linear(embedding_size + 36, embedding_size)\n",
    "        init_weights(self.fc_concat)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            self.fc_concat,\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(embedding_size)\n",
    "\n",
    "    def forward(self, movies, genres, years):\n",
    "        movie_embedding = self.movie_embedding_layer(movies) # (batch, ..., embedding_size)\n",
    "        genres_embedding = self.genres_encoder_layer(genres) # (batch, ..., 4)\n",
    "        years_embedding = self.years_embedding_layer(years) # (batch, ..., 32)\n",
    "\n",
    "        movie_embedding = torch.concat([movie_embedding, genres_embedding, years_embedding], dim=-1) # (batch, ..., embedding_size + 36)\n",
    "        movie_embedding = self.fc(movie_embedding) # (batch, ..., embedding_size)\n",
    "        movie_embedding = self.dropout(movie_embedding) # (batch, ..., embedding_size)\n",
    "        movie_embedding = self.norm(movie_embedding) # (batch, ..., embedding_size)\n",
    "\n",
    "        return movie_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            user_vocab_size, \n",
    "            movie_vocab_size, \n",
    "            genres_vocab_size, \n",
    "            years_vocab_size, \n",
    "            embedding_size, \n",
    "            movie_seq_len, \n",
    "            num_encoder_layers, \n",
    "            num_heads, \n",
    "            dim_ff,\n",
    "            dropout=0.0\n",
    "        ) -> None:\n",
    "\n",
    "        super(UserEncoder, self).__init__()\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.movie_seq_len = movie_seq_len\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_ff = dim_ff\n",
    "\n",
    "        self.user_embedding_layer = nn.Embedding(user_vocab_size, embedding_size)\n",
    "        self.movie_encoder = MovieEncoder(movie_vocab_size, genres_vocab_size, years_vocab_size, embedding_size, dropout)\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(embedding_size, movie_seq_len, dropout)\n",
    "        self.encoder_block = Encoder(num_encoder_layers, embedding_size, num_heads, dim_ff, dropout)\n",
    "\n",
    "        self.fc_concat = nn.Linear(2*embedding_size, embedding_size)\n",
    "        init_weights(self.fc_concat)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            self.fc_concat,\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(embedding_size)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            user_ids, \n",
    "            rated_movie_ids, \n",
    "            rated_movie_genres, \n",
    "            rated_movie_years, \n",
    "            rated_movie_ratings):\n",
    "        \n",
    "        user_embedding = self.user_embedding_layer(user_ids) # (batch, 1, embedding_size)\n",
    "        \n",
    "        movie_embeddings = self.movie_encoder(rated_movie_ids, rated_movie_genres, rated_movie_years) # (batch, movie_seq_len, embedding_size)\n",
    "        movie_embeddings = self.positional_encoding(movie_embeddings) # (batch, movie_seq_len, embedding_size)\n",
    "        movie_embeddings = self.encoder_block(movie_embeddings, None) # (batch, movie_seq_len, embedding_size)\n",
    "\n",
    "        rated_movie_ratings = F.softmax(rated_movie_ratings, dim=-1) # (batch, movie_seq_len)\n",
    "        rated_movie_ratings = rated_movie_ratings.unsqueeze(1) # (batch, 1, movie_seq_len)\n",
    "        movie_embeddings_weighted = torch.matmul(rated_movie_ratings, movie_embeddings) # (batch, 1, embedding_size)\n",
    "\n",
    "        user_embedding = torch.concat([user_embedding, movie_embeddings_weighted], dim=-1) # (batch, 1, 2*embedding_size)\n",
    "        user_embedding = self.fc(user_embedding) # (batch, 1, embedding_size)\n",
    "        user_embedding = self.dropout(user_embedding) # (batch, 1, embedding_size)\n",
    "        user_embedding = self.norm(user_embedding) # (batch, 1, embedding_size)\n",
    "\n",
    "        return user_embedding, movie_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderSystem(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            user_vocab_size, \n",
    "            movie_vocab_size, \n",
    "            genres_vocab_size, \n",
    "            years_vocab_size, \n",
    "            embedding_size, \n",
    "            movie_seq_len, \n",
    "            num_encoder_layers, \n",
    "            num_heads, \n",
    "            dim_ff,\n",
    "            dropout=0.0\n",
    "        ) -> None:\n",
    "\n",
    "        super(RecommenderSystem, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.movie_seq_len = movie_seq_len\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_ff = dim_ff\n",
    "\n",
    "        self.movie_encoder = \\\n",
    "            MovieEncoder\\\n",
    "            (\n",
    "                movie_vocab_size, \n",
    "                genres_vocab_size, \n",
    "                years_vocab_size, \n",
    "                embedding_size, \n",
    "                dropout\n",
    "            )\n",
    "        \n",
    "        self.user_encoder = \\\n",
    "            UserEncoder\\\n",
    "            (\n",
    "                user_vocab_size, \n",
    "                movie_vocab_size, \n",
    "                genres_vocab_size, \n",
    "                years_vocab_size, \n",
    "                embedding_size, \n",
    "                movie_seq_len, \n",
    "                num_encoder_layers, \n",
    "                num_heads, \n",
    "                dim_ff,\n",
    "                dropout\n",
    "            )\n",
    "        \n",
    "        self.cross_attn = MultiHeadAttentionBlock(embedding_size, embedding_size, num_heads)\n",
    "\n",
    "        self.fc_concat1 = nn.Linear(2*embedding_size, embedding_size)\n",
    "        init_weights(self.fc_concat1)\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            self.fc_concat1,\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.fc_concat2 = nn.Linear(2*embedding_size, embedding_size)\n",
    "        init_weights(self.fc_concat2)\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            self.fc_concat2,\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.fc_ratings_linear = nn.Linear(embedding_size, 1)\n",
    "        init_weights(self.fc_ratings_linear)\n",
    "\n",
    "        self.fc_ratings = nn.Sequential(\n",
    "            self.fc_ratings_linear,\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embedding_size)\n",
    "        self.norm2 = nn.LayerNorm(embedding_size)\n",
    "        self.norm3 = nn.LayerNorm(embedding_size)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            user_ids, \n",
    "            movie_ids, \n",
    "            rated_movie_ids, \n",
    "            rated_movie_genres, \n",
    "            rated_movie_years, \n",
    "            rated_movie_ratings, \n",
    "            movie_genres, \n",
    "            movie_years):\n",
    "        \n",
    "        movie_embeddings = \\\n",
    "            self.movie_encoder(movie_ids, movie_genres, movie_years) # (batch, 1, embedding_size)\n",
    "        \n",
    "        user_embeddings, rated_movie_embeddings = \\\n",
    "            self.user_encoder\\\n",
    "                (\n",
    "                    user_ids, \n",
    "                    rated_movie_ids, \n",
    "                    rated_movie_genres, \n",
    "                    rated_movie_years, \n",
    "                    rated_movie_ratings\n",
    "                )                     # (batch, 1, embedding_size), (batch, movie_seq_len, embedding_size)\n",
    "        \n",
    "        crss_attn_out = self.cross_attn(movie_embeddings, rated_movie_embeddings, rated_movie_embeddings, mask=None) # (batch, 1, embedding_size)\n",
    "        rated_movie_embeddings = movie_embeddings + self.dropout(crss_attn_out) # (batch, 1, embedding_size)\n",
    "        rated_movie_embeddings = self.norm1(rated_movie_embeddings) # (batch, 1, embedding_size)\n",
    "\n",
    "        movie_embeddings = torch.concat([movie_embeddings, rated_movie_embeddings], dim=-1) # (batch, 1, 2*embedding_size)\n",
    "        movie_embeddings = self.fc1(movie_embeddings) # (batch, 1, embedding_size)\n",
    "        movie_embeddings = self.dropout(movie_embeddings) # (batch, 1, embedding_size)\n",
    "        movie_embeddings = self.norm2(movie_embeddings) # (batch, 1, embedding_size)\n",
    "        \n",
    "        encoded = torch.concat([user_embeddings, movie_embeddings], dim=-1) # (batch, 1, 2*embedding_size)\n",
    "        encoded = self.fc2(encoded) # (batch, 1, embedding_size)\n",
    "        encoded = self.dropout(encoded) # (batch, 1, embedding_size)\n",
    "        encoded = self.norm3(encoded) # (batch, 1, embedding_size)\n",
    "\n",
    "        output = self.fc_ratings(encoded) # (batch, 1, 1)\n",
    "        output = torch.clamp(output, min=0.0, max=5.0).squeeze(1) # (batch, 1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup, max_iters):\n",
    "        self.warmup = warmup\n",
    "        self.max_num_iters = max_iters\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
    "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
    "\n",
    "    def get_lr_factor(self, epoch):\n",
    "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))\n",
    "        if epoch <= self.warmup:\n",
    "            lr_factor *= epoch * 1.0 / self.warmup\n",
    "        return lr_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred:torch.Tensor, y_true:torch.Tensor):\n",
    "        y_pred = F.softmax(y_pred, dim=-1)\n",
    "        y_pred_mask = (y_pred > 0)\n",
    "        y_pred = y_pred.where(y_pred_mask, 1.0e-15)\n",
    "\n",
    "        y_true = F.one_hot(y_true, num_classes=y_pred.shape[2])\n",
    "\n",
    "        # ratings = F.softmax(ratings, dim=-1)\n",
    "        # return ((-y_true*torch.log(y_pred)).sum(dim=-1)*ratings).sum()/y_pred.shape[0]\n",
    "        return (-y_true*torch.log(y_pred)).sum()/(y_pred.shape[0]*y_pred.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred:torch.Tensor, y_true:torch.Tensor, ratings:torch.Tensor):\n",
    "        y_pred = F.softmax(y_pred, dim=-1)\n",
    "        y_pred_mask = (y_pred > 0)\n",
    "        y_pred = y_pred.where(y_pred_mask, 1.0e-15)\n",
    "\n",
    "        y_true = F.one_hot(y_true, num_classes=y_pred.shape[2])\n",
    "\n",
    "        ratings = F.softmax(ratings, dim=-1)\n",
    "        return ((-y_true*torch.log(y_pred)).sum(dim=-1)*ratings).sum()/y_pred.shape[0]\n",
    "        # return (-y_true*torch.log(y_pred)).sum()/(y_pred.shape[0]*y_pred.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings_path = '/Users/amondal/recsys/datasets/ml-32m/ratings.csv'\n",
    "genres_path = '/Users/amondal/recsys/datasets/ml-32m/movies.csv'\n",
    "\n",
    "rating_column_names = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "genres_column_names = ['movieId', 'title', 'genres']\n",
    "\n",
    "df_rating = pd.read_csv(ratings_path, sep=',', names=rating_column_names, dtype={'userId':'int32', 'movieId':'int32', 'rating':float, 'timestamp':'int64'}, header=0)\n",
    "df_genres = pd.read_csv(genres_path, sep=',', names=genres_column_names, dtype={'movieId':'int32', 'title':'object', 'genres':'object'}, header=0)\n",
    "\n",
    "df_rating.dropna(inplace=True, subset=['userId', 'movieId', 'rating'])\n",
    "df_genres.dropna(inplace=True, subset=['movieId', 'title', 'genres'])\n",
    "\n",
    "df_genres['genres'] = df_genres['genres'].apply(lambda x: x.split('|'))\n",
    "df_genres['movie_year'] = df_genres['title'].str.extract(r'\\((\\d{4})\\)').fillna(\"2025\").astype('int')\n",
    "df_genres.drop(columns=['title'], inplace=True)\n",
    "\n",
    "df = df_rating.merge(df_genres, on=['movieId'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = df['genres'].tolist()\n",
    "\n",
    "genres_set = set()\n",
    "for x in all_genres:\n",
    "    genres_set.update(set(x))\n",
    "\n",
    "genres_set = list(genres_set)\n",
    "inv_idx = {genres_set[i]:i for i in range(len(genres_set))}\n",
    "\n",
    "genres_mh = []\n",
    "for x in all_genres:\n",
    "    h = [0]*len(genres_set)\n",
    "    for y in x:\n",
    "        h[inv_idx[y]] = 1\n",
    "    genres_mh += [h]\n",
    "\n",
    "df['genres_mh'] = genres_mh\n",
    "df.drop(columns=['genres'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='timestamp')\n",
    "df2 = df[[\"userId\", \"movieId\"]].groupby(by=[\"userId\"]).agg(list).reset_index()\n",
    "df2 = df2[df2.movieId.apply(len) > 10]\n",
    "df = df.merge(df2, on=[\"userId\"], how=\"inner\", suffixes=(\"\", \"_right\"))\n",
    "df.drop(columns=['movieId_right'], inplace=True)\n",
    "\n",
    "n = df.shape[0]\n",
    "m = int(0.8*n)\n",
    "\n",
    "df_train_val = df[:m]\n",
    "df_test = df[m:]\n",
    "\n",
    "k = int(0.8*m)\n",
    "df_train = df_train_val[:k]\n",
    "df_val = df_train_val[k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "prev_seq_len = 10\n",
    "\n",
    "def get_movies_data(df:pd.DataFrame):\n",
    "    df2 = df.groupby(by=[\"userId\"]).agg(list).reset_index()\n",
    "\n",
    "    user_ids, movie_ids, genres, years, ratings = [], [], [], [], []\n",
    "    prev_movie_ids = []\n",
    "    prev_movie_genres = []\n",
    "    prev_movie_years = []\n",
    "    prev_movie_ratings = []\n",
    "\n",
    "    for i in range(df2.shape[0]):\n",
    "        movie_ids_seq = df2.loc[i, 'movieId']\n",
    "        user_id = df2.loc[i, 'userId']\n",
    "        genres_seq = df2.loc[i, 'genres_mh']\n",
    "        ratings_seq = df2.loc[i, 'rating']\n",
    "        years_seq = df2.loc[i, 'movie_year']\n",
    "\n",
    "        m = len(movie_ids_seq)-prev_seq_len\n",
    "        if m > 0:\n",
    "            indices = random.sample(range(prev_seq_len, len(movie_ids_seq)), k=min(m, 20))\n",
    "\n",
    "            for j in indices:\n",
    "                rated_movie_ids = movie_ids_seq[max(0, j-prev_seq_len):j]\n",
    "                rated_movie_genres = genres_seq[max(0, j-prev_seq_len):j]\n",
    "                rated_movie_years = years_seq[max(0, j-prev_seq_len):j]\n",
    "                rated_movie_ratings = ratings_seq[max(0, j-prev_seq_len):j]\n",
    "\n",
    "                user_ids += [user_id]\n",
    "                movie_ids += [movie_ids_seq[j]]\n",
    "                genres += [genres_seq[j]]\n",
    "                years += [years_seq[j]]\n",
    "                ratings += [ratings_seq[j]]\n",
    "\n",
    "                prev_movie_ids += [rated_movie_ids]\n",
    "                prev_movie_genres += [rated_movie_genres]\n",
    "                prev_movie_years += [rated_movie_years]\n",
    "                prev_movie_ratings += [rated_movie_ratings]\n",
    "    \n",
    "    user_ids = torch.tensor(user_ids, dtype=torch.int32)\n",
    "    movie_ids = torch.tensor(movie_ids, dtype=torch.int32)\n",
    "    genres = torch.tensor(genres, dtype=torch.int8)\n",
    "    years = torch.tensor(years, dtype=torch.int32)\n",
    "    ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "\n",
    "    prev_movie_ids = torch.tensor(prev_movie_ids, dtype=torch.int32)\n",
    "    prev_movie_genres = torch.tensor(prev_movie_genres, dtype=torch.int8)\n",
    "    prev_movie_years = torch.tensor(prev_movie_years, dtype=torch.int32)\n",
    "    prev_movie_ratings = torch.tensor(prev_movie_ratings, dtype=torch.float32)\n",
    "\n",
    "    return user_ids, movie_ids, genres, years, ratings, prev_movie_ids, prev_movie_genres, prev_movie_years, prev_movie_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_vocab_size = int(df_train[\"userId\"].max()+1)\n",
    "movie_id_vocab_size = int(df_train[\"movieId\"].max()+1)\n",
    "genres_vocab_size = len(genres_set)\n",
    "years_vocab_size = int(df_train[\"movie_year\"].max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    user_ids_train, \n",
    "    movie_ids_train, \n",
    "    genres_train, \n",
    "    years_train, \n",
    "    ratings_train, \n",
    "    prev_movie_ids_train, \n",
    "    prev_movie_genres_train, \n",
    "    prev_movie_years_train, \n",
    "    prev_movie_ratings_train\n",
    "    \n",
    ") = get_movies_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    user_ids_test, \n",
    "    movie_ids_test, \n",
    "    genres_test, \n",
    "    years_test, \n",
    "    ratings_test, \n",
    "    prev_movie_ids_test, \n",
    "    prev_movie_genres_test, \n",
    "    prev_movie_years_test, \n",
    "    prev_movie_ratings_test\n",
    "    \n",
    ") = get_movies_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    user_ids_val, \n",
    "    movie_ids_val, \n",
    "    genres_val, \n",
    "    years_val, \n",
    "    ratings_val, \n",
    "    prev_movie_ids_val, \n",
    "    prev_movie_genres_val, \n",
    "    prev_movie_years_val, \n",
    "    prev_movie_ratings_val\n",
    "    \n",
    ") = get_movies_data(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "movie_seq_len = 10\n",
    "num_encoder_layers = 4\n",
    "num_heads = 4\n",
    "dropout = 0.0\n",
    "dff = 32\n",
    "\n",
    "rec = \\\n",
    "    RecommenderSystem\\\n",
    "    (\n",
    "        user_id_vocab_size, \n",
    "        movie_id_vocab_size, \n",
    "        genres_vocab_size, \n",
    "        years_vocab_size, \n",
    "        embedding_size, \n",
    "        movie_seq_len, \n",
    "        num_encoder_layers, \n",
    "        num_heads, \n",
    "        dff, \n",
    "        dropout\n",
    "    ).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.0766538381576538\n",
      "Epoch: 1, Batch: 200, Loss: 0.9862989187240601\n",
      "Epoch: 1, Batch: 300, Loss: 0.9468784332275391\n",
      "Epoch: 1, Batch: 400, Loss: 0.9463402032852173\n",
      "Epoch: 1, Batch: 500, Loss: 1.0055279731750488\n",
      "Epoch: 1, Batch: 600, Loss: 1.0259501934051514\n",
      "Epoch: 1, Batch: 700, Loss: 1.1393749713897705\n",
      "Epoch: 1, Batch: 800, Loss: 0.9425355792045593\n",
      "Epoch: 1, Batch: 900, Loss: 0.9335076212882996\n",
      "Epoch: 1, Batch: 1000, Loss: 1.0166608095169067\n",
      "Epoch: 1, Batch: 1100, Loss: 0.8819131255149841\n",
      "Epoch: 1, Batch: 1200, Loss: 0.867583155632019\n",
      "Epoch: 1, Batch: 1300, Loss: 0.9509823322296143\n",
      "Epoch: 1, Batch: 1400, Loss: 0.9531517028808594\n",
      "Epoch: 1, Batch: 1500, Loss: 0.9788060188293457\n",
      "Epoch: 1, Batch: 1600, Loss: 0.9777872562408447\n",
      "Epoch: 1, Batch: 1700, Loss: 0.9393941164016724\n",
      "Epoch: 1, Batch: 1800, Loss: 0.8768765926361084\n",
      "Epoch: 1, Batch: 1900, Loss: 1.0202564001083374\n",
      "Epoch: 1, Batch: 2000, Loss: 0.8542932271957397\n",
      "Epoch: 1, Batch: 2100, Loss: 0.9982452392578125\n",
      "Epoch: 1, Batch: 2200, Loss: 0.9785407185554504\n",
      "Epoch: 1, Batch: 2300, Loss: 0.8013995885848999\n",
      "Epoch: 1, Batch: 2400, Loss: 0.9574637413024902\n",
      "Epoch: 1, Batch: 2500, Loss: 0.9087380170822144\n",
      "Epoch: 1, Batch: 2600, Loss: 0.9733870029449463\n",
      "Epoch: 1, Batch: 2700, Loss: 0.8933075666427612\n",
      "Epoch: 1, Batch: 2800, Loss: 0.9374184012413025\n",
      "Epoch: 1, Batch: 2900, Loss: 0.871517539024353\n",
      "Epoch: 1, Batch: 3000, Loss: 0.8073099851608276\n",
      "Epoch: 1, Batch: 3100, Loss: 0.9174078702926636\n",
      "Epoch: 1, Batch: 3200, Loss: 0.8957729935646057\n",
      "Epoch: 1, Batch: 3300, Loss: 0.899468183517456\n",
      "Epoch: 1, Batch: 3400, Loss: 0.7730083465576172\n",
      "Epoch: 1, Batch: 3500, Loss: 0.9066988229751587\n",
      "Epoch: 1, Batch: 3600, Loss: 0.8939758539199829\n",
      "Epoch: 1, Batch: 3700, Loss: 0.903008222579956\n",
      "Epoch: 1, Batch: 3800, Loss: 0.9693700075149536\n",
      "Epoch: 1, Batch: 3900, Loss: 0.7915194034576416\n",
      "Epoch: 1, Batch: 4000, Loss: 0.8210055828094482\n",
      "Epoch: 1, Batch: 4100, Loss: 0.7918294072151184\n",
      "Epoch: 1, Batch: 4200, Loss: 0.9217036962509155\n",
      "Epoch: 1, Batch: 4300, Loss: 0.812250018119812\n",
      "Epoch: 1, Batch: 4400, Loss: 0.7561497688293457\n",
      "Epoch: 1, Batch: 4500, Loss: 0.8529801368713379\n",
      "Epoch: 1, Batch: 4600, Loss: 0.8878838419914246\n",
      "Epoch: 1, Batch: 4700, Loss: 0.8859543204307556\n",
      "Epoch: 1, Batch: 4800, Loss: 0.9695383310317993\n",
      "Epoch: 1, Batch: 4900, Loss: 0.8552561402320862\n",
      "Epoch: 1, Batch: 5000, Loss: 0.8204833269119263\n",
      "Epoch: 1, Batch: 5100, Loss: 0.9652542471885681\n",
      "Epoch: 1, Batch: 5200, Loss: 0.8237557411193848\n",
      "Validation Loss: 1.0763168219338082\n",
      "\n",
      "Epoch: 2, Batch: 100, Loss: 0.8342350125312805\n",
      "Epoch: 2, Batch: 200, Loss: 0.8583348393440247\n",
      "Epoch: 2, Batch: 300, Loss: 0.7475318908691406\n",
      "Epoch: 2, Batch: 400, Loss: 0.6671851873397827\n",
      "Epoch: 2, Batch: 500, Loss: 0.7815759181976318\n",
      "Epoch: 2, Batch: 600, Loss: 0.9172990918159485\n",
      "Epoch: 2, Batch: 700, Loss: 0.9182677268981934\n",
      "Epoch: 2, Batch: 800, Loss: 0.7296607494354248\n",
      "Epoch: 2, Batch: 900, Loss: 0.8221569657325745\n",
      "Epoch: 2, Batch: 1000, Loss: 0.7862937450408936\n",
      "Epoch: 2, Batch: 1100, Loss: 0.8126602172851562\n",
      "Epoch: 2, Batch: 1200, Loss: 0.7900218963623047\n",
      "Epoch: 2, Batch: 1300, Loss: 0.843880295753479\n",
      "Epoch: 2, Batch: 1400, Loss: 0.9077959060668945\n",
      "Epoch: 2, Batch: 1500, Loss: 0.7826828956604004\n",
      "Epoch: 2, Batch: 1600, Loss: 0.8088032603263855\n",
      "Epoch: 2, Batch: 1700, Loss: 0.7562369108200073\n",
      "Epoch: 2, Batch: 1800, Loss: 0.7349221110343933\n",
      "Epoch: 2, Batch: 1900, Loss: 0.728990912437439\n",
      "Epoch: 2, Batch: 2000, Loss: 0.7773892879486084\n",
      "Epoch: 2, Batch: 2100, Loss: 0.7663838863372803\n",
      "Epoch: 2, Batch: 2200, Loss: 0.7042251825332642\n",
      "Epoch: 2, Batch: 2300, Loss: 0.7947730422019958\n",
      "Epoch: 2, Batch: 2400, Loss: 0.7641967535018921\n",
      "Epoch: 2, Batch: 2500, Loss: 0.7378613948822021\n",
      "Epoch: 2, Batch: 2600, Loss: 0.8106527328491211\n",
      "Epoch: 2, Batch: 2700, Loss: 0.7762157917022705\n",
      "Epoch: 2, Batch: 2800, Loss: 0.6761513948440552\n",
      "Epoch: 2, Batch: 2900, Loss: 0.833599328994751\n",
      "Epoch: 2, Batch: 3000, Loss: 0.7517285346984863\n",
      "Epoch: 2, Batch: 3100, Loss: 0.8082607984542847\n",
      "Epoch: 2, Batch: 3200, Loss: 0.9175122976303101\n",
      "Epoch: 2, Batch: 3300, Loss: 0.7786756157875061\n",
      "Epoch: 2, Batch: 3400, Loss: 0.9205126762390137\n",
      "Epoch: 2, Batch: 3500, Loss: 0.8220046758651733\n",
      "Epoch: 2, Batch: 3600, Loss: 0.7748106122016907\n",
      "Epoch: 2, Batch: 3700, Loss: 0.7046399116516113\n",
      "Epoch: 2, Batch: 3800, Loss: 0.8883044123649597\n",
      "Epoch: 2, Batch: 3900, Loss: 0.7237167954444885\n",
      "Epoch: 2, Batch: 4000, Loss: 0.7662383317947388\n",
      "Epoch: 2, Batch: 4100, Loss: 0.7276787757873535\n",
      "Epoch: 2, Batch: 4200, Loss: 0.7771807909011841\n",
      "Epoch: 2, Batch: 4300, Loss: 0.7604584693908691\n",
      "Epoch: 2, Batch: 4400, Loss: 0.7871829271316528\n",
      "Epoch: 2, Batch: 4500, Loss: 0.838414192199707\n",
      "Epoch: 2, Batch: 4600, Loss: 0.7758476138114929\n",
      "Epoch: 2, Batch: 4700, Loss: 0.7686727643013\n",
      "Epoch: 2, Batch: 4800, Loss: 0.7476519346237183\n",
      "Epoch: 2, Batch: 4900, Loss: 0.7778035402297974\n",
      "Epoch: 2, Batch: 5000, Loss: 0.706687331199646\n",
      "Epoch: 2, Batch: 5100, Loss: 0.7717559337615967\n",
      "Epoch: 2, Batch: 5200, Loss: 0.7606788873672485\n",
      "Validation Loss: 1.0693517735386344\n",
      "\n",
      "Epoch: 3, Batch: 100, Loss: 0.762968897819519\n",
      "Epoch: 3, Batch: 200, Loss: 0.702970027923584\n",
      "Epoch: 3, Batch: 300, Loss: 0.7912654876708984\n",
      "Epoch: 3, Batch: 400, Loss: 0.7573827505111694\n",
      "Epoch: 3, Batch: 500, Loss: 0.9141769409179688\n",
      "Epoch: 3, Batch: 600, Loss: 0.6909835934638977\n",
      "Epoch: 3, Batch: 700, Loss: 0.7822931408882141\n",
      "Epoch: 3, Batch: 800, Loss: 0.7745771408081055\n",
      "Epoch: 3, Batch: 900, Loss: 0.7035504579544067\n",
      "Epoch: 3, Batch: 1000, Loss: 0.7508544921875\n",
      "Epoch: 3, Batch: 1100, Loss: 0.7814593315124512\n",
      "Epoch: 3, Batch: 1200, Loss: 0.7315306067466736\n",
      "Epoch: 3, Batch: 1300, Loss: 0.7646105885505676\n",
      "Epoch: 3, Batch: 1400, Loss: 0.7161210179328918\n",
      "Epoch: 3, Batch: 1500, Loss: 0.7416059374809265\n",
      "Epoch: 3, Batch: 1600, Loss: 0.8257826566696167\n",
      "Epoch: 3, Batch: 1700, Loss: 0.8891221284866333\n",
      "Epoch: 3, Batch: 1800, Loss: 0.7810590267181396\n",
      "Epoch: 3, Batch: 1900, Loss: 0.8617583513259888\n",
      "Epoch: 3, Batch: 2000, Loss: 0.7111494541168213\n",
      "Epoch: 3, Batch: 2100, Loss: 0.7338897585868835\n",
      "Epoch: 3, Batch: 2200, Loss: 0.8757995367050171\n",
      "Epoch: 3, Batch: 2300, Loss: 0.7294206619262695\n",
      "Epoch: 3, Batch: 2400, Loss: 0.7922706604003906\n",
      "Epoch: 3, Batch: 2500, Loss: 0.699874997138977\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m loss:torch.Tensor = criterion(output.contiguous(), ratings_batch.contiguous())\n\u001b[32m     43\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m lr_scheduler.step()\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (i+\u001b[32m1\u001b[39m) % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/recsys/.venv/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:124\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m opt = opt_ref()\n\u001b[32m    123\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/recsys/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/recsys/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/recsys/.venv/lib/python3.13/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/recsys/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/recsys/.venv/lib/python3.13/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/recsys/.venv/lib/python3.13/site-packages/torch/optim/adam.py:456\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    454\u001b[39m         exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m.addcmul_(grad, grad, value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[32m    459\u001b[39m     step = step_t\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10    # number of epochs to run\n",
    "batch_size = 512  # size of each batch\n",
    "batches_per_epoch = user_ids_train.shape[0] // batch_size\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(rec.parameters(), lr=0.001)\n",
    "lr_scheduler = CosineWarmupScheduler(optimizer, warmup=50, max_iters=batches_per_epoch*n_epochs)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    indices = torch.randperm(user_ids_train.shape[0])\n",
    "\n",
    "    rec.train()\n",
    "    for i in range(batches_per_epoch):\n",
    "        optimizer.zero_grad()\n",
    "        start = i * batch_size\n",
    "        batch_indices = indices[start:start+batch_size]\n",
    "\n",
    "        user_ids_batch = user_ids_train[batch_indices].unsqueeze(1).to(device=device)\n",
    "        movie_ids_batch = movie_ids_train[batch_indices].unsqueeze(1).to(device=device)\n",
    "        genres_batch = genres_train[batch_indices].unsqueeze(1).to(dtype=torch.float32).to(device=device)\n",
    "        years_batch = years_train[batch_indices].unsqueeze(1).to(device=device)\n",
    "        ratings_batch = ratings_train[batch_indices].unsqueeze(1).to(device=device)\n",
    "\n",
    "        prev_movie_ids_batch = prev_movie_ids_train[batch_indices].to(device=device)\n",
    "        prev_movie_genres_batch = prev_movie_genres_train[batch_indices].to(dtype=torch.float32).to(device=device)\n",
    "        prev_movie_ids_years = prev_movie_years_train[batch_indices].to(device=device)\n",
    "        prev_movie_ids_ratings = prev_movie_ratings_train[batch_indices].to(device=device)\n",
    "\n",
    "        output:torch.Tensor = \\\n",
    "            rec(\n",
    "                user_ids_batch, \n",
    "                movie_ids_batch, \n",
    "                prev_movie_ids_batch, \n",
    "                prev_movie_genres_batch, \n",
    "                prev_movie_ids_years, \n",
    "                prev_movie_ids_ratings, \n",
    "                genres_batch, \n",
    "                years_batch\n",
    "            )\n",
    "        \n",
    "        loss:torch.Tensor = criterion(output.contiguous(), ratings_batch.contiguous())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch: {epoch+1}, Batch: {i+1}, Loss: {loss.item()}\")\n",
    "    \n",
    "    rec.eval()\n",
    "    s = 0.0\n",
    "    for i in range(0, user_ids_val.shape[0], batch_size):\n",
    "        batch_indices = list(range(i, min(i+batch_size, user_ids_val.shape[0])))\n",
    "\n",
    "        user_ids_batch = user_ids_val[batch_indices].unsqueeze(1).to(device=device)\n",
    "        movie_ids_batch = movie_ids_val[batch_indices].unsqueeze(1).to(device=device)\n",
    "        genres_batch = genres_val[batch_indices].unsqueeze(1).to(dtype=torch.float32).to(device=device)\n",
    "        years_batch = years_val[batch_indices].unsqueeze(1).to(device=device)\n",
    "        ratings_batch = ratings_val[batch_indices].unsqueeze(1).to(device=device)\n",
    "\n",
    "        prev_movie_ids_batch = prev_movie_ids_val[batch_indices].to(device=device)\n",
    "        prev_movie_genres_batch = prev_movie_genres_val[batch_indices].to(dtype=torch.float32).to(device=device)\n",
    "        prev_movie_ids_years = prev_movie_years_val[batch_indices].to(device=device)\n",
    "        prev_movie_ids_ratings = prev_movie_ratings_val[batch_indices].to(device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output:torch.Tensor = \\\n",
    "                rec(\n",
    "                    user_ids_batch, \n",
    "                    movie_ids_batch, \n",
    "                    prev_movie_ids_batch, \n",
    "                    prev_movie_genres_batch, \n",
    "                    prev_movie_ids_years, \n",
    "                    prev_movie_ids_ratings, \n",
    "                    genres_batch, \n",
    "                    years_batch\n",
    "                )\n",
    "        \n",
    "            loss:torch.Tensor = criterion(output.contiguous(), ratings_batch.contiguous())\n",
    "            s += output.shape[0]*loss.item()\n",
    "    \n",
    "    print(f\"Validation Loss: {s/user_ids_val.shape[0]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.eval()\n",
    "\n",
    "batch_size = 1024\n",
    "s = 0.0\n",
    "\n",
    "for i in range(0, user_ids_test.shape[0], batch_size):\n",
    "    batch_indices = list(range(i, min(i+batch_size, user_ids_test.shape[0])))\n",
    "\n",
    "    user_ids_batch = user_ids_test[batch_indices].unsqueeze(1).to(device=device)\n",
    "    movie_ids_batch = movie_ids_test[batch_indices].unsqueeze(1).to(device=device)\n",
    "    genres_batch = genres_test[batch_indices].unsqueeze(1).to(dtype=torch.float32).to(device=device)\n",
    "    years_batch = years_test[batch_indices].unsqueeze(1).to(device=device)\n",
    "    ratings_batch = ratings_test[batch_indices].unsqueeze(1).to(device=device)\n",
    "\n",
    "    prev_movie_ids_batch = prev_movie_ids_test[batch_indices].to(device=device)\n",
    "    prev_movie_genres_batch = prev_movie_genres_test[batch_indices].to(dtype=torch.float32).to(device=device)\n",
    "    prev_movie_ids_years = prev_movie_years_test[batch_indices].to(device=device)\n",
    "    prev_movie_ids_ratings = prev_movie_ratings_test[batch_indices].to(device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output:torch.Tensor = \\\n",
    "            rec(\n",
    "                user_ids_batch, \n",
    "                movie_ids_batch, \n",
    "                prev_movie_ids_batch, \n",
    "                prev_movie_genres_batch, \n",
    "                prev_movie_ids_years, \n",
    "                prev_movie_ids_ratings, \n",
    "                genres_batch, \n",
    "                years_batch\n",
    "            )\n",
    "    \n",
    "        loss:torch.Tensor = criterion(output.contiguous(), ratings_batch.contiguous())\n",
    "        s += output.shape[0]*loss.item()\n",
    "\n",
    "        if device == 'mps':\n",
    "            torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0897221863853048\n"
     ]
    }
   ],
   "source": [
    "print(s/user_ids_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
