{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet \"pytorch-lightning >=2.0,<2.6\" \"matplotlib\" \"torch >=1.8.1,<2.8\" \"seaborn\" \"torchmetrics >=1.0,<1.8\" \"numpy <3.0\" \"torchvision\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import math\n",
    "import os\n",
    "import urllib.request\n",
    "from functools import partial\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.set_cmap(\"cividis\")\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q:torch.Tensor, k:torch.Tensor, v:torch.Tensor, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attn_logits, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " tensor([[ 0.3367,  0.1288],\n",
      "        [ 0.2345,  0.2303],\n",
      "        [-1.1229, -0.1863]])\n",
      "K\n",
      " tensor([[ 2.2082, -0.6380],\n",
      "        [ 0.4617,  0.2674],\n",
      "        [ 0.5349,  0.8094]])\n",
      "V\n",
      " tensor([[ 1.1103, -1.6898],\n",
      "        [-0.9890,  0.9580],\n",
      "        [ 1.3221,  0.8172]])\n",
      "Values\n",
      " tensor([[ 0.5698, -0.1520],\n",
      "        [ 0.5379, -0.0265],\n",
      "        [ 0.2246,  0.5556]])\n",
      "Attention\n",
      " tensor([[0.4028, 0.2886, 0.3086],\n",
      "        [0.3538, 0.3069, 0.3393],\n",
      "        [0.1303, 0.4630, 0.4067]])\n"
     ]
    }
   ],
   "source": [
    "seq_len, d_k = 3, 2\n",
    "pl.seed_everything(42)\n",
    "q = torch.randn(seq_len, d_k)\n",
    "k = torch.randn(seq_len, d_k)\n",
    "v = torch.randn(seq_len, d_k)\n",
    "values, attention = scaled_dot_product(q, k, v)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"Values\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        # Stack all weight matrices 1...h together for efficiency\n",
    "        # Note that in many implementations you see \"bias=False\" which is optional\n",
    "        self.qkv_proj = nn.Linear(input_dim, 3 * embed_dim)\n",
    "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        # Original Transformer initialization, see PyTorch documentation\n",
    "        nn.init.xavier_uniform_(self.qkv_proj.weight)\n",
    "        self.qkv_proj.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
    "        self.o_proj.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x:torch.Tensor, mask=None, return_attention=False):\n",
    "        batch_size, seq_length, embed_dim = x.size()\n",
    "        qkv:torch.Tensor = self.qkv_proj(x)\n",
    "\n",
    "        # Separate Q, K, V from linear output\n",
    "        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3 * self.head_dim)\n",
    "        qkv = qkv.permute(0, 2, 1, 3)  # [Batch, Head, SeqLen, Dims]\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        # Determine value outputs\n",
    "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
    "        values = values.permute(0, 2, 1, 3)  # [Batch, SeqLen, Head, Dims]\n",
    "        values = values.reshape(batch_size, seq_length, embed_dim)\n",
    "        o = self.o_proj(values)\n",
    "\n",
    "        if return_attention:\n",
    "            return o, attention\n",
    "        else:\n",
    "            return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n",
    "        \"\"\"EncoderBlock.\n",
    "\n",
    "        Args:\n",
    "            input_dim: Dimensionality of the input\n",
    "            num_heads: Number of heads to use in the attention block\n",
    "            dim_feedforward: Dimensionality of the hidden layer in the MLP\n",
    "            dropout: Dropout probability to use in the dropout layers\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Attention layer\n",
    "        self.self_attn = MultiheadAttention(input_dim, input_dim, num_heads)\n",
    "\n",
    "        # Two-layer MLP\n",
    "        self.linear_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, dim_feedforward),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(dim_feedforward, input_dim),\n",
    "        )\n",
    "\n",
    "        # Layers to apply in between the main layers\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Attention part\n",
    "        attn_out = self.self_attn(x, mask=mask)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # MLP part\n",
    "        linear_out = self.linear_net(x)\n",
    "        x = x + self.dropout(linear_out)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, num_layers, **block_args):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderBlock(**block_args) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask=mask)\n",
    "        return x\n",
    "\n",
    "    def get_attention_maps(self, x, mask=None):\n",
    "        attention_maps = []\n",
    "        for layer in self.layers:\n",
    "            _, attn_map = layer.self_attn(x, mask=mask, return_attention=True)\n",
    "            attention_maps.append(attn_map)\n",
    "            x = layer(x)\n",
    "        return attention_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        \"\"\"Positional Encoding.\n",
    "\n",
    "        Args:\n",
    "            d_model: Hidden dimensionality of the input.\n",
    "            max_len: Maximum length of a sequence to expect.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
    "        # Used for tensors that need to be on the same device as the module.\n",
    "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
    "        self.register_buffer(\"pe\", pe, persistent=False)\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "d_model = 32\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "pe = pe.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[:, :20].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup, max_iters):\n",
    "        self.warmup = warmup\n",
    "        self.max_num_iters = max_iters\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
    "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
    "\n",
    "    def get_lr_factor(self, epoch):\n",
    "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))\n",
    "        if epoch <= self.warmup:\n",
    "            lr_factor *= epoch * 1.0 / self.warmup\n",
    "        return lr_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPredictor(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        model_dim,\n",
    "        num_classes,\n",
    "        num_heads,\n",
    "        num_layers,\n",
    "        lr,\n",
    "        warmup,\n",
    "        max_iters,\n",
    "        dropout=0.0,\n",
    "        input_dropout=0.0,\n",
    "    ):\n",
    "        \"\"\"TransformerPredictor.\n",
    "\n",
    "        Args:\n",
    "            input_dim: Hidden dimensionality of the input\n",
    "            model_dim: Hidden dimensionality to use inside the Transformer\n",
    "            num_classes: Number of classes to predict per sequence element\n",
    "            num_heads: Number of heads to use in the Multi-Head Attention blocks\n",
    "            num_layers: Number of encoder blocks to use.\n",
    "            lr: Learning rate in the optimizer\n",
    "            warmup: Number of warmup steps. Usually between 50 and 500\n",
    "            max_iters: Number of maximum iterations the model is trained for. This is needed for the CosineWarmup scheduler\n",
    "            dropout: Dropout to apply inside the model\n",
    "            input_dropout: Dropout to apply on the input features\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self._create_model()\n",
    "\n",
    "    def _create_model(self):\n",
    "        # Input dim -> Model dim\n",
    "        self.input_net = nn.Sequential(\n",
    "            nn.Dropout(self.hparams.input_dropout), nn.Linear(self.hparams.input_dim, self.hparams.model_dim)\n",
    "        )\n",
    "        # Positional encoding for sequences\n",
    "        self.positional_encoding = PositionalEncoding(d_model=self.hparams.model_dim)\n",
    "        # Transformer\n",
    "        self.transformer = TransformerEncoder(\n",
    "            num_layers=self.hparams.num_layers,\n",
    "            input_dim=self.hparams.model_dim,\n",
    "            dim_feedforward=2 * self.hparams.model_dim,\n",
    "            num_heads=self.hparams.num_heads,\n",
    "            dropout=self.hparams.dropout,\n",
    "        )\n",
    "        # Output classifier per sequence element\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.Linear(self.hparams.model_dim, self.hparams.model_dim),\n",
    "            nn.LayerNorm(self.hparams.model_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(self.hparams.dropout),\n",
    "            nn.Linear(self.hparams.model_dim, self.hparams.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None, add_positional_encoding=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input features of shape [Batch, SeqLen, input_dim]\n",
    "            mask: Mask to apply on the attention outputs (optional)\n",
    "            add_positional_encoding: If True, we add the positional encoding to the input.\n",
    "                                      Might not be desired for some tasks.\n",
    "        \"\"\"\n",
    "        x = self.input_net(x)\n",
    "        if add_positional_encoding:\n",
    "            x = self.positional_encoding(x)\n",
    "        x = self.transformer(x, mask=mask)\n",
    "        x = self.output_net(x)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attention_maps(self, x, mask=None, add_positional_encoding=True):\n",
    "        \"\"\"Function for extracting the attention matrices of the whole Transformer for a single batch.\n",
    "\n",
    "        Input arguments same as the forward pass.\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.input_net(x)\n",
    "        if add_positional_encoding:\n",
    "            x = self.positional_encoding(x)\n",
    "        attention_maps = self.transformer.get_attention_maps(x, mask=mask)\n",
    "        return attention_maps\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "        # We don't return the lr scheduler because we need to apply it per iteration, not per epoch\n",
    "        self.lr_scheduler = CosineWarmupScheduler(\n",
    "            optimizer, warmup=self.hparams.warmup, max_iters=self.hparams.max_iters\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def optimizer_step(self, *args, **kwargs):\n",
    "        super().optimizer_step(*args, **kwargs)\n",
    "        self.lr_scheduler.step()  # Step per iteration\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseDataset(data.Dataset):\n",
    "    def __init__(self, num_categories, seq_len, size):\n",
    "        super().__init__()\n",
    "        self.num_categories = num_categories\n",
    "        self.seq_len = seq_len\n",
    "        self.size = size\n",
    "\n",
    "        self.data = torch.randint(self.num_categories, size=(self.size, self.seq_len))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp_data = self.data[idx]\n",
    "        labels = torch.flip(inp_data, dims=(0,))\n",
    "        return inp_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = partial(ReverseDataset, 10, 16)\n",
    "train_loader = data.DataLoader(dataset(50000), batch_size=128, shuffle=True, drop_last=True, pin_memory=True)\n",
    "val_loader = data.DataLoader(dataset(1000), batch_size=128)\n",
    "test_loader = data.DataLoader(dataset(10000), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: tensor([9, 6, 2, 0, 6, 2, 7, 9, 7, 3, 3, 4, 3, 7, 0, 9])\n",
      "Labels:     tensor([9, 0, 7, 3, 4, 3, 3, 7, 9, 7, 2, 6, 0, 2, 6, 9])\n"
     ]
    }
   ],
   "source": [
    "inp_data, labels = train_loader.dataset[0]\n",
    "print(\"Input data:\", inp_data)\n",
    "print(\"Labels:    \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReversePredictor(TransformerPredictor):\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        # Fetch data and transform categories to one-hot vectors\n",
    "        inp_data, labels = batch\n",
    "        inp_data = F.one_hot(inp_data, num_classes=self.hparams.num_classes).float()\n",
    "\n",
    "        # Perform prediction and calculate loss and accuracy\n",
    "        preds = self.forward(inp_data, add_positional_encoding=True)\n",
    "        loss = F.cross_entropy(preds.view(-1, preds.size(-1)), labels.view(-1))\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        # Logging\n",
    "        self.log(f\"{mode}_loss\", loss)\n",
    "        self.log(f\"{mode}_acc\", acc)\n",
    "        return loss, acc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _ = self._calculate_loss(batch, mode=\"train\")\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reverse(**kwargs):\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"mps\",\n",
    "        devices=1,\n",
    "        max_epochs=10,\n",
    "        gradient_clip_val=5,\n",
    "    )\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "    \n",
    "    model = ReversePredictor(max_iters=trainer.max_epochs * len(train_loader), **kwargs)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "    result = {\"test_acc\": test_result[0][\"test_acc\"], \"val_acc\": val_result[0][\"test_acc\"]}\n",
    "\n",
    "    model = model.to(device)\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | input_net           | Sequential         | 352    | train\n",
      "1 | positional_encoding | PositionalEncoding | 0      | train\n",
      "2 | transformer         | TransformerEncoder | 8.5 K  | train\n",
      "3 | output_net          | Sequential         | 1.4 K  | train\n",
      "-------------------------------------------------------------------\n",
      "10.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.3 K    Total params\n",
      "0.041     Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 390/390 [00:03<00:00, 128.20it/s, v_num=9]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 390/390 [00:03<00:00, 127.71it/s, v_num=9]\n",
      "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 281.36it/s]\n",
      "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:00<00:00, 385.64it/s]\n"
     ]
    }
   ],
   "source": [
    "reverse_model, reverse_result = train_reverse(\n",
    "    input_dim=train_loader.dataset.num_categories,\n",
    "    model_dim=32,\n",
    "    num_heads=1,\n",
    "    num_classes=train_loader.dataset.num_categories,\n",
    "    num_layers=1,\n",
    "    dropout=0.0,\n",
    "    lr=5e-4,\n",
    "    warmup=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy:  73.88%\n",
      "Test accuracy: 73.92%\n"
     ]
    }
   ],
   "source": [
    "print(\"Val accuracy:  %4.2f%%\" % (100.0 * reverse_result[\"val_acc\"]))\n",
    "print(\"Test accuracy: %4.2f%%\" % (100.0 * reverse_result[\"test_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"datasets/ml-32m\"\n",
    "\n",
    "ratings_path = os.path.join(folder, 'ratings.csv')\n",
    "genres_path = os.path.join(folder, 'movies.csv')\n",
    "tags_path = os.path.join(folder, 'tags.csv')\n",
    "\n",
    "rating_column_names = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "genres_column_names = ['movieId', 'title', 'genres']\n",
    "tags_column_names = ['userId', 'movieId', 'tag', 'timestamp']\n",
    "\n",
    "df_rating = pd.read_csv(ratings_path, sep=',', names=rating_column_names, dtype={'userId':'int32', 'movieId':'int32', 'rating':float, 'timestamp':'int64'}, header=0)\n",
    "df_genres = pd.read_csv(genres_path, sep=',', names=genres_column_names, dtype={'movieId':'int32', 'title':'object', 'genres':'object'}, header=0)\n",
    "df_tags = pd.read_csv(tags_path, sep=',', names=tags_column_names, dtype={'userId':'int32', 'movieId':'int32', 'tag':'object', 'timestamp':'int64'}, header=0)\n",
    "\n",
    "df_rating.dropna(inplace=True, subset=['userId', 'movieId', 'rating'])\n",
    "df_genres.dropna(inplace=True, subset=['movieId', 'title', 'genres'])\n",
    "df_tags.dropna(inplace=True, subset=['userId', 'movieId', 'tag'])\n",
    "df_tags.drop(columns=[\"userId\",\"timestamp\"], inplace=True)\n",
    "\n",
    "# Extract movie genres\n",
    "df_genres['genres'] = df_genres['genres'].apply(lambda x: x.lower().split('|'))\n",
    "\n",
    "# Extract movie year from title\n",
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "def remove_stop(x):\n",
    "    out = []\n",
    "    for y in x:\n",
    "        if len(y) > 0 and y not in stopwords:\n",
    "            out += [y]\n",
    "    return out\n",
    "\n",
    "def flatten_lists(x):\n",
    "    x = x[:20]\n",
    "    out = set()\n",
    "    for y in x:\n",
    "        out.update(y.split(\" \"))\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "df_genres['movie_year'] = df_genres['title'].str.extract(r'\\((\\d{4})\\)').fillna(\"2025\").astype('int')\n",
    "\n",
    "df_genres['title'] = df_genres['title'].str.replace(r'\\((\\d{4})\\)', '', regex=True)\n",
    "df_genres['title'] = df_genres['title'].str.replace(r'[^a-zA-Z0-9\\s]+', '', regex=True)\n",
    "df_genres['title'] = df_genres['title'].apply(lambda x: x.strip().lower().split(\" \"))\n",
    "df_genres['title'] = df_genres['title'].apply(lambda x: remove_stop(x))\n",
    "\n",
    "df_tags['tag'] = df_tags['tag'].str.replace(r'[^a-zA-Z0-9\\s]+', '', regex=True)\n",
    "df_tags['tag'] = df_tags['tag'].apply(lambda x: x.strip().lower())\n",
    "df_tags = df_tags.groupby(\"movieId\").agg(set).reset_index()\n",
    "df_tags['tag'] = df_tags['tag'].apply(list)\n",
    "df_tags['tag'] = df_tags['tag'].apply(lambda x: flatten_lists(x))\n",
    "df_tags['tag'] = df_tags['tag'].apply(lambda x: remove_stop(x))\n",
    "df_tags['tag'] = df_tags['tag'].astype(\"object\")\n",
    "\n",
    "df = df_rating.merge(df_genres, on=['movieId'], how='left')\n",
    "df = df.merge(df_tags, on=['movieId'], how='left')\n",
    "df[\"tag\"] = df[\"tag\"].fillna({i: [\"\"] for i in df.index})\n",
    "df[\"description\"] = df[\"title\"] + df[\"tag\"]\n",
    "df.drop(columns=[\"tag\"], inplace=True)\n",
    "df.drop(columns=[\"title\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "      <td>[drama, romance]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[sense, sensibility, decorum, 18th, bibliothek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "      <td>[drama, romance]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[leaving, las, vegas, existential, enough, lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "      <td>[adventure, drama, fantasy, mystery, sci-fi]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[city, lost, children, cit, des, enfants, perd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "      <td>[crime, drama]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[shanghai, triad, yao, yao, yao, dao, waipo, q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "      <td>[mystery, sci-fi, thriller]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[twelve, monkeys, aka, 12, monkeys, theater, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>1944</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943231120</td>\n",
       "      <td>[drama, romance, war]</td>\n",
       "      <td>1953</td>\n",
       "      <td>[eternity, military, prostitute, boxing, infid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>1952</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944253272</td>\n",
       "      <td>[drama]</td>\n",
       "      <td>1969</td>\n",
       "      <td>[midnight, cowboy, clash, sex, frontal, cultur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>1960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>943231236</td>\n",
       "      <td>[drama]</td>\n",
       "      <td>1987</td>\n",
       "      <td>[last, emperor, bibliothek, theater, better, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>1961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250182</td>\n",
       "      <td>[drama]</td>\n",
       "      <td>1988</td>\n",
       "      <td>[rain, man, love, savant, best, brief, story, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>1965</td>\n",
       "      <td>3.0</td>\n",
       "      <td>943228697</td>\n",
       "      <td>[comedy, sci-fi]</td>\n",
       "      <td>1984</td>\n",
       "      <td>[repo, man, repossession, dean, river, killer,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating  timestamp  \\\n",
       "0        1       17     4.0  944249077   \n",
       "1        1       25     1.0  944250228   \n",
       "2        1       29     2.0  943230976   \n",
       "3        1       30     5.0  944249077   \n",
       "4        1       32     5.0  943228858   \n",
       "..     ...      ...     ...        ...   \n",
       "95       1     1944     2.0  943231120   \n",
       "96       1     1952     4.0  944253272   \n",
       "97       1     1960     1.0  943231236   \n",
       "98       1     1961     1.0  944250182   \n",
       "99       1     1965     3.0  943228697   \n",
       "\n",
       "                                          genres  movie_year  \\\n",
       "0                               [drama, romance]        1995   \n",
       "1                               [drama, romance]        1995   \n",
       "2   [adventure, drama, fantasy, mystery, sci-fi]        1995   \n",
       "3                                 [crime, drama]        1995   \n",
       "4                    [mystery, sci-fi, thriller]        1995   \n",
       "..                                           ...         ...   \n",
       "95                         [drama, romance, war]        1953   \n",
       "96                                       [drama]        1969   \n",
       "97                                       [drama]        1987   \n",
       "98                                       [drama]        1988   \n",
       "99                              [comedy, sci-fi]        1984   \n",
       "\n",
       "                                          description  \n",
       "0   [sense, sensibility, decorum, 18th, bibliothek...  \n",
       "1   [leaving, las, vegas, existential, enough, lov...  \n",
       "2   [city, lost, children, cit, des, enfants, perd...  \n",
       "3   [shanghai, triad, yao, yao, yao, dao, waipo, q...  \n",
       "4   [twelve, monkeys, aka, 12, monkeys, theater, t...  \n",
       "..                                                ...  \n",
       "95  [eternity, military, prostitute, boxing, infid...  \n",
       "96  [midnight, cowboy, clash, sex, frontal, cultur...  \n",
       "97  [last, emperor, bibliothek, theater, better, c...  \n",
       "98  [rain, man, love, savant, best, brief, story, ...  \n",
       "99  [repo, man, repossession, dean, river, killer,...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ratings(df:pd.DataFrame):\n",
    "    df2 = df[[\"userId\", \"rating\"]].groupby(by=[\"userId\"]).agg(mean_user_rating=('rating', 'mean'), std_user_rating=('rating', 'std'))\n",
    "    df = df.merge(df2, on=[\"userId\"], how=\"inner\")\n",
    "    df[\"normalized_rating\"] = (df[\"rating\"] - df[\"mean_user_rating\"])/df[\"std_user_rating\"]\n",
    "    df[\"normalized_rating\"] = df[\"normalized_rating\"].fillna(df[\"rating\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize_ratings(df)\n",
    "df.drop(columns=[\"mean_user_rating\", \"std_user_rating\", \"rating\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>description</th>\n",
       "      <th>normalized_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>944249077</td>\n",
       "      <td>[drama, romance]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[sense, sensibility, decorum, 18th, bibliothek...</td>\n",
       "      <td>0.304372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>944250228</td>\n",
       "      <td>[drama, romance]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[leaving, las, vegas, existential, enough, lov...</td>\n",
       "      <td>-1.646377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>943230976</td>\n",
       "      <td>[adventure, drama, fantasy, mystery, sci-fi]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[city, lost, children, cit, des, enfants, perd...</td>\n",
       "      <td>-0.996127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>944249077</td>\n",
       "      <td>[crime, drama]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[shanghai, triad, yao, yao, yao, dao, waipo, q...</td>\n",
       "      <td>0.954622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>943228858</td>\n",
       "      <td>[mystery, sci-fi, thriller]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[twelve, monkeys, aka, 12, monkeys, theater, t...</td>\n",
       "      <td>0.954622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>1944</td>\n",
       "      <td>943231120</td>\n",
       "      <td>[drama, romance, war]</td>\n",
       "      <td>1953</td>\n",
       "      <td>[eternity, military, prostitute, boxing, infid...</td>\n",
       "      <td>-0.996127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>1952</td>\n",
       "      <td>944253272</td>\n",
       "      <td>[drama]</td>\n",
       "      <td>1969</td>\n",
       "      <td>[midnight, cowboy, clash, sex, frontal, cultur...</td>\n",
       "      <td>0.304372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>1960</td>\n",
       "      <td>943231236</td>\n",
       "      <td>[drama]</td>\n",
       "      <td>1987</td>\n",
       "      <td>[last, emperor, bibliothek, theater, better, c...</td>\n",
       "      <td>-1.646377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>1961</td>\n",
       "      <td>944250182</td>\n",
       "      <td>[drama]</td>\n",
       "      <td>1988</td>\n",
       "      <td>[rain, man, love, savant, best, brief, story, ...</td>\n",
       "      <td>-1.646377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>1965</td>\n",
       "      <td>943228697</td>\n",
       "      <td>[comedy, sci-fi]</td>\n",
       "      <td>1984</td>\n",
       "      <td>[repo, man, repossession, dean, river, killer,...</td>\n",
       "      <td>-0.345878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  timestamp                                        genres  \\\n",
       "0        1       17  944249077                              [drama, romance]   \n",
       "1        1       25  944250228                              [drama, romance]   \n",
       "2        1       29  943230976  [adventure, drama, fantasy, mystery, sci-fi]   \n",
       "3        1       30  944249077                                [crime, drama]   \n",
       "4        1       32  943228858                   [mystery, sci-fi, thriller]   \n",
       "..     ...      ...        ...                                           ...   \n",
       "95       1     1944  943231120                         [drama, romance, war]   \n",
       "96       1     1952  944253272                                       [drama]   \n",
       "97       1     1960  943231236                                       [drama]   \n",
       "98       1     1961  944250182                                       [drama]   \n",
       "99       1     1965  943228697                              [comedy, sci-fi]   \n",
       "\n",
       "    movie_year                                        description  \\\n",
       "0         1995  [sense, sensibility, decorum, 18th, bibliothek...   \n",
       "1         1995  [leaving, las, vegas, existential, enough, lov...   \n",
       "2         1995  [city, lost, children, cit, des, enfants, perd...   \n",
       "3         1995  [shanghai, triad, yao, yao, yao, dao, waipo, q...   \n",
       "4         1995  [twelve, monkeys, aka, 12, monkeys, theater, t...   \n",
       "..         ...                                                ...   \n",
       "95        1953  [eternity, military, prostitute, boxing, infid...   \n",
       "96        1969  [midnight, cowboy, clash, sex, frontal, cultur...   \n",
       "97        1987  [last, emperor, bibliothek, theater, better, c...   \n",
       "98        1988  [rain, man, love, savant, best, brief, story, ...   \n",
       "99        1984  [repo, man, repossession, dean, river, killer,...   \n",
       "\n",
       "    normalized_rating  \n",
       "0            0.304372  \n",
       "1           -1.646377  \n",
       "2           -0.996127  \n",
       "3            0.954622  \n",
       "4            0.954622  \n",
       "..                ...  \n",
       "95          -0.996127  \n",
       "96           0.304372  \n",
       "97          -1.646377  \n",
       "98          -1.646377  \n",
       "99          -0.345878  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df:pd.DataFrame, min_rated=10, test_ratio=0.8, val_ratio=0.8):\n",
    "    print(\"Splitting data into train test and validation...\")\n",
    "    # Split data into training, testing and validation\n",
    "    df = df.sort_values(by='timestamp')\n",
    "    df2 = df[[\"userId\", \"movieId\"]].groupby(by=[\"userId\"]).agg(list).reset_index()\n",
    "\n",
    "    # Filter all user_ids who have rated more than 'min_rated' movies\n",
    "    df2 = df2[df2.movieId.apply(len) > min_rated]\n",
    "    df = df.merge(df2, on=[\"userId\"], how=\"inner\", suffixes=(\"\", \"_right\"))\n",
    "    df.drop(columns=['movieId_right'], inplace=True)\n",
    "\n",
    "    n = df.shape[0]\n",
    "    m = int(test_ratio*n)\n",
    "\n",
    "    df_train_val = df[:m]\n",
    "    df_test = df[m:]\n",
    "\n",
    "    k = int(val_ratio*m)\n",
    "    df_train = df_train_val[:k]\n",
    "    df_val = df_train_val[k:]\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train test and validation...\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = split_train_test(df, min_rated=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x, vocab):\n",
    "    if isinstance(x, list):\n",
    "        out = []\n",
    "        for y in x:\n",
    "            out += [vocab[y]] if y in vocab else [0]\n",
    "        return out\n",
    "    else:\n",
    "        return vocab[x] if x in vocab else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_encoding(df:pd.DataFrame, col:str, max_vocab_size=1000):\n",
    "    all_vals = df[col].tolist()\n",
    "    unique_vals = {}\n",
    "\n",
    "    if len(all_vals) > 0 and isinstance(all_vals[0], list):\n",
    "        for v in all_vals:\n",
    "            for x in v:\n",
    "                if x not in unique_vals:\n",
    "                    unique_vals[x] = 0\n",
    "                unique_vals[x] += 1\n",
    "    else:\n",
    "        for x in all_vals:\n",
    "            if x not in unique_vals:\n",
    "                unique_vals[x] = 0\n",
    "            unique_vals[x] += 1\n",
    "    \n",
    "    unique_vals = sorted(unique_vals.items(), key=lambda item: item[1], reverse=True)\n",
    "    unique_vals = dict(unique_vals[:min(max_vocab_size, len(unique_vals))])\n",
    "    unique_vals = sorted(unique_vals.keys())\n",
    "    vocab = {unique_vals[i] : i+1 for i in range(len(unique_vals))}\n",
    "        \n",
    "    df[col] = df[col].apply(lambda x: transform(x, vocab))\n",
    "    return df[col], vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId\n",
      "movieId\n",
      "title\n",
      "genres\n",
      "movie_year\n"
     ]
    }
   ],
   "source": [
    "vocabulary = {}\n",
    "max_vocab_size = {'userId':1e100, 'movieId':1e100, 'title':1e6, 'genres':100, 'movie_year':1e100}\n",
    "\n",
    "for col in ['userId', 'movieId', 'title', 'genres', 'movie_year']:\n",
    "    print(col)\n",
    "    df_train[col], v = categorical_encoding(df_train, col, max_vocab_size[col])\n",
    "    vocabulary[col] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val.reset_index()\n",
    "for col in ['userId', 'movieId', 'title', 'genres', 'movie_year']:\n",
    "    print(col)\n",
    "    df_val[col] = df_val[col].apply(lambda x: transform(x, vocabulary[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId\n",
      "movieId\n",
      "title\n",
      "genres\n",
      "movie_year\n"
     ]
    }
   ],
   "source": [
    "df_test = df_test.reset_index()\n",
    "for col in ['userId', 'movieId', 'title', 'genres', 'movie_year']:\n",
    "    print(col)\n",
    "    df_test[col] = df_test[col].apply(lambda x: transform(x, vocabulary[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_test.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(vocabulary, \"vocabulary.pkl\")\n",
    "joblib.dump(df_train, \"df_train.pkl\")\n",
    "joblib.dump(df_val, \"df_val.pkl\")\n",
    "joblib.dump(df_test, \"df_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>normalized_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18045</td>\n",
       "      <td>1149</td>\n",
       "      <td>789652004</td>\n",
       "      <td>[12326, 24446, 45006, 12326, 45130, 10759, 455...</td>\n",
       "      <td>[9, 10, 16]</td>\n",
       "      <td>97</td>\n",
       "      <td>0.367212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22172</td>\n",
       "      <td>1053</td>\n",
       "      <td>789652009</td>\n",
       "      <td>[15214, 6782, 45686, 4086, 17848, 18863, 33258...</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>94</td>\n",
       "      <td>-0.484696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22172</td>\n",
       "      <td>47</td>\n",
       "      <td>789652009</td>\n",
       "      <td>[37792, 1482, 37218, 37448, 4821, 9882, 46613,...</td>\n",
       "      <td>[15, 18]</td>\n",
       "      <td>101</td>\n",
       "      <td>1.741315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22172</td>\n",
       "      <td>21</td>\n",
       "      <td>789652009</td>\n",
       "      <td>[16837, 38290, 31210, 14120, 18863, 14687, 115...</td>\n",
       "      <td>[6, 7, 18]</td>\n",
       "      <td>101</td>\n",
       "      <td>-0.484696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27825</td>\n",
       "      <td>2</td>\n",
       "      <td>822873600</td>\n",
       "      <td>[22045, 31210, 18863, 15192, 35686, 4857, 2836...</td>\n",
       "      <td>[3, 5, 10]</td>\n",
       "      <td>101</td>\n",
       "      <td>0.291454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>33616</td>\n",
       "      <td>66</td>\n",
       "      <td>823185246</td>\n",
       "      <td>[23938, 25738, 401, 4769, 10331, 17848, 18863,...</td>\n",
       "      <td>[2, 17, 18]</td>\n",
       "      <td>102</td>\n",
       "      <td>-0.243857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>33616</td>\n",
       "      <td>74</td>\n",
       "      <td>823185247</td>\n",
       "      <td>[4377, 35829, 15375, 35700, 46670, 15447, 3479...</td>\n",
       "      <td>[9, 16]</td>\n",
       "      <td>102</td>\n",
       "      <td>-0.243857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>33616</td>\n",
       "      <td>73</td>\n",
       "      <td>823185247</td>\n",
       "      <td>[27541, 24252, 23737, 29713, 1103, 31134, 2394...</td>\n",
       "      <td>[9, 19]</td>\n",
       "      <td>101</td>\n",
       "      <td>0.614943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33616</td>\n",
       "      <td>9</td>\n",
       "      <td>823185248</td>\n",
       "      <td>[40951, 10793, 17848, 18863, 20127, 32585, 146...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>101</td>\n",
       "      <td>-0.243857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>33616</td>\n",
       "      <td>40</td>\n",
       "      <td>823185249</td>\n",
       "      <td>[10107, 4538, 9702, 34041, 5582, 39603, 1301, ...</td>\n",
       "      <td>[9]</td>\n",
       "      <td>101</td>\n",
       "      <td>0.614943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  timestamp  \\\n",
       "0    18045     1149  789652004   \n",
       "1    22172     1053  789652009   \n",
       "2    22172       47  789652009   \n",
       "3    22172       21  789652009   \n",
       "4    27825        2  822873600   \n",
       "..     ...      ...        ...   \n",
       "95   33616       66  823185246   \n",
       "96   33616       74  823185247   \n",
       "97   33616       73  823185247   \n",
       "98   33616        9  823185248   \n",
       "99   33616       40  823185249   \n",
       "\n",
       "                                                title       genres  \\\n",
       "0   [12326, 24446, 45006, 12326, 45130, 10759, 455...  [9, 10, 16]   \n",
       "1   [15214, 6782, 45686, 4086, 17848, 18863, 33258...       [6, 7]   \n",
       "2   [37792, 1482, 37218, 37448, 4821, 9882, 46613,...     [15, 18]   \n",
       "3   [16837, 38290, 31210, 14120, 18863, 14687, 115...   [6, 7, 18]   \n",
       "4   [22045, 31210, 18863, 15192, 35686, 4857, 2836...   [3, 5, 10]   \n",
       "..                                                ...          ...   \n",
       "95  [23938, 25738, 401, 4769, 10331, 17848, 18863,...  [2, 17, 18]   \n",
       "96  [4377, 35829, 15375, 35700, 46670, 15447, 3479...      [9, 16]   \n",
       "97  [27541, 24252, 23737, 29713, 1103, 31134, 2394...      [9, 19]   \n",
       "98  [40951, 10793, 17848, 18863, 20127, 32585, 146...          [2]   \n",
       "99  [10107, 4538, 9702, 34041, 5582, 39603, 1301, ...          [9]   \n",
       "\n",
       "    movie_year  normalized_rating  \n",
       "0           97           0.367212  \n",
       "1           94          -0.484696  \n",
       "2          101           1.741315  \n",
       "3          101          -0.484696  \n",
       "4          101           0.291454  \n",
       "..         ...                ...  \n",
       "95         102          -0.243857  \n",
       "96         102          -0.243857  \n",
       "97         101           0.614943  \n",
       "98         101          -0.243857  \n",
       "99         101           0.614943  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_user_features(df:pd.DataFrame, max_hist=20):\n",
    "\tdf[\"seq_id\"] = list(range(df.shape[0]))\n",
    "\tdf2 = df[[\"seq_id\", \"userId\", \"movieId\", \"normalized_rating\", \"timestamp\"]].sort_values(by=[\"userId\", \"timestamp\"])\n",
    "\t\n",
    "\tdf2 = df2[[\"userId\", \"movieId\", \"normalized_rating\", \"seq_id\"]].groupby(by=[\"userId\"]).agg(list).reset_index()\n",
    "\tdf2.rename(columns={\"movieId\":\"prev_movie_ids\", \"normalized_rating\":\"prev_ratings\", \"seq_id\":\"prev_seq_ids\"}, inplace=True)\n",
    "\n",
    "\tuser_ids = []\n",
    "\tp_m_ids = []\n",
    "\tp_r_ids = []\n",
    "\tp_seq_ids = []\n",
    "\n",
    "\tfor i in range(df2.shape[0]):\n",
    "\t\tseq_id = df2.loc[i, \"prev_seq_ids\"]\n",
    "\t\tu_id   = df2.loc[i, \"userId\"]\n",
    "\t\tm_ids  = df2.loc[i, \"prev_movie_ids\"]\n",
    "\t\tr_ids  = df2.loc[i, \"prev_ratings\"]\n",
    "\n",
    "\t\tfor j in range(len(m_ids)):\n",
    "\t\t\tuser_ids += [u_id]\n",
    "\t\t\tp_seq_ids += [seq_id[j]]\n",
    "\t\t\tp_m_ids += [m_ids[:j][-max_hist:]] if j > 0 else [[]]\n",
    "\t\t\tp_r_ids += [r_ids[:j][-max_hist:]] if j > 0 else [[]]\n",
    "\t\n",
    "\tdf3 = pd.DataFrame({\"userId\":user_ids, \"prev_movie_ids\":p_m_ids, \"prev_ratings\":p_r_ids, \"seq_id\":p_seq_ids})\n",
    "\tdf = df.merge(df3, on=[\"userId\", \"seq_id\"], how=\"left\")\n",
    "\tdf.drop(columns=[\"seq_id\"], inplace=True)\n",
    "\t\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ml_32m_py\n",
    "import numpy as np\n",
    "\n",
    "importlib.reload(ml_32m_py)\n",
    "\n",
    "def get_historical_user_features_cpp(df:pd.DataFrame, max_hist=20):\n",
    "        user_ids = df['userId'].to_numpy().astype(np.uint32)\n",
    "        movie_ids = df['movieId'].to_numpy().astype(np.uint32)\n",
    "        ratings = df['normalized_rating'].to_numpy().astype(np.float32)\n",
    "        timestamps = df['timestamp'].to_numpy().astype(np.uint64)\n",
    "\n",
    "        a, b  = ml_32m_py.py_get_historical_features(user_ids, movie_ids, timestamps, ratings, df.shape[0], max_hist)\n",
    "\n",
    "        df[\"prev_movie_ids\"] = a\n",
    "        df[\"prev_ratings\"] = b\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "vocabulary = joblib.load(\"vocabulary.pkl\")\n",
    "df_train = joblib.load(\"df_train.pkl\")\n",
    "df_val = joblib.load(\"df_val.pkl\")\n",
    "df_test = joblib.load(\"df_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_train = get_historical_user_features_cpp(df_train)\n",
    "print(\"here1\")\n",
    "df_val = get_historical_user_features_cpp(df_val)\n",
    "print(\"here2\")\n",
    "df_test = get_historical_user_features_cpp(df_test)\n",
    "print(\"here3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(df_train, \"df_train.pkl\")\n",
    "joblib.dump(df_val, \"df_val.pkl\")\n",
    "joblib.dump(df_test, \"df_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>normalized_rating</th>\n",
       "      <th>prev_movie_ids</th>\n",
       "      <th>prev_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2905</td>\n",
       "      <td>943226846</td>\n",
       "      <td>[21839, 25689, 27697, 25787, 35686, 34951, 404...</td>\n",
       "      <td>[6, 9, 10]</td>\n",
       "      <td>105</td>\n",
       "      <td>0.304372</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2874</td>\n",
       "      <td>943226846</td>\n",
       "      <td>[40573, 40547, 34790, 27555, 489, 43580, 42083...</td>\n",
       "      <td>[3, 9]</td>\n",
       "      <td>105</td>\n",
       "      <td>-1.646377</td>\n",
       "      <td>[2905]</td>\n",
       "      <td>[0.3043722566393317]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2798</td>\n",
       "      <td>943226916</td>\n",
       "      <td>[42431, 22828, 22828, 9185, 9393, 20127, 12873...</td>\n",
       "      <td>[2, 3, 6, 9, 19]</td>\n",
       "      <td>105</td>\n",
       "      <td>0.304372</td>\n",
       "      <td>[2905, 2874]</td>\n",
       "      <td>[0.3043722566393317, -1.6463772063672941]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2985</td>\n",
       "      <td>943226986</td>\n",
       "      <td>[24401, 18835, 1189, 18789, 21685, 32055, 6138...</td>\n",
       "      <td>[9]</td>\n",
       "      <td>105</td>\n",
       "      <td>-0.996127</td>\n",
       "      <td>[2905, 2874, 2798]</td>\n",
       "      <td>[0.3043722566393317, -1.6463772063672941, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2790</td>\n",
       "      <td>943227458</td>\n",
       "      <td>[21424, 24375, 36963, 28874, 46289, 16876, 202...</td>\n",
       "      <td>[9]</td>\n",
       "      <td>105</td>\n",
       "      <td>-1.646377</td>\n",
       "      <td>[2905, 2874, 2798, 2985]</td>\n",
       "      <td>[0.3043722566393317, -1.6463772063672941, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>818</td>\n",
       "      <td>944248888</td>\n",
       "      <td>[15774, 22114, 24254, 1339, 11053, 15020, 4185...</td>\n",
       "      <td>[9]</td>\n",
       "      <td>102</td>\n",
       "      <td>-0.345878</td>\n",
       "      <td>[1796, 1054, 175, 2881, 2152, 2411, 1037, 913,...</td>\n",
       "      <td>[0.3043722566393317, -1.6463772063672941, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>601</td>\n",
       "      <td>944248943</td>\n",
       "      <td>[14614, 29541, 18863, 40209, 46432, 9934, 4645...</td>\n",
       "      <td>[6, 7, 9, 18]</td>\n",
       "      <td>102</td>\n",
       "      <td>-0.996127</td>\n",
       "      <td>[1054, 175, 2881, 2152, 2411, 1037, 913, 1238,...</td>\n",
       "      <td>[-1.6463772063672941, 0.3043722566393317, 0.95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>2177</td>\n",
       "      <td>944248943</td>\n",
       "      <td>[17337, 26815, 43604, 14120, 7283, 14769, 387,...</td>\n",
       "      <td>[7, 9, 18]</td>\n",
       "      <td>98</td>\n",
       "      <td>-1.646377</td>\n",
       "      <td>[175, 2881, 2152, 2411, 1037, 913, 1238, 1227,...</td>\n",
       "      <td>[0.3043722566393317, 0.9546220776415403, -1.64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>944248943</td>\n",
       "      <td>[46146, 3863, 3725, 37367, 17276, 11609, 8394,...</td>\n",
       "      <td>[5, 9]</td>\n",
       "      <td>101</td>\n",
       "      <td>0.954622</td>\n",
       "      <td>[2881, 2152, 2411, 1037, 913, 1238, 1227, 895,...</td>\n",
       "      <td>[0.9546220776415403, -1.6463772063672941, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>1145</td>\n",
       "      <td>944248943</td>\n",
       "      <td>[8247, 31054, 29733, 8247, 31054, 18605, 31924...</td>\n",
       "      <td>[9]</td>\n",
       "      <td>95</td>\n",
       "      <td>-0.345878</td>\n",
       "      <td>[2152, 2411, 1037, 913, 1238, 1227, 895, 221, ...</td>\n",
       "      <td>[-1.6463772063672941, -0.3458775643628769, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  timestamp  \\\n",
       "0        1     2905  943226846   \n",
       "1        1     2874  943226846   \n",
       "2        1     2798  943226916   \n",
       "3        1     2985  943226986   \n",
       "4        1     2790  943227458   \n",
       "..     ...      ...        ...   \n",
       "95       1      818  944248888   \n",
       "96       1      601  944248943   \n",
       "97       1     2177  944248943   \n",
       "98       1       80  944248943   \n",
       "99       1     1145  944248943   \n",
       "\n",
       "                                                title            genres  \\\n",
       "0   [21839, 25689, 27697, 25787, 35686, 34951, 404...        [6, 9, 10]   \n",
       "1   [40573, 40547, 34790, 27555, 489, 43580, 42083...            [3, 9]   \n",
       "2   [42431, 22828, 22828, 9185, 9393, 20127, 12873...  [2, 3, 6, 9, 19]   \n",
       "3   [24401, 18835, 1189, 18789, 21685, 32055, 6138...               [9]   \n",
       "4   [21424, 24375, 36963, 28874, 46289, 16876, 202...               [9]   \n",
       "..                                                ...               ...   \n",
       "95  [15774, 22114, 24254, 1339, 11053, 15020, 4185...               [9]   \n",
       "96  [14614, 29541, 18863, 40209, 46432, 9934, 4645...     [6, 7, 9, 18]   \n",
       "97  [17337, 26815, 43604, 14120, 7283, 14769, 387,...        [7, 9, 18]   \n",
       "98  [46146, 3863, 3725, 37367, 17276, 11609, 8394,...            [5, 9]   \n",
       "99  [8247, 31054, 29733, 8247, 31054, 18605, 31924...               [9]   \n",
       "\n",
       "    movie_year  normalized_rating  \\\n",
       "0          105           0.304372   \n",
       "1          105          -1.646377   \n",
       "2          105           0.304372   \n",
       "3          105          -0.996127   \n",
       "4          105          -1.646377   \n",
       "..         ...                ...   \n",
       "95         102          -0.345878   \n",
       "96         102          -0.996127   \n",
       "97          98          -1.646377   \n",
       "98         101           0.954622   \n",
       "99          95          -0.345878   \n",
       "\n",
       "                                       prev_movie_ids  \\\n",
       "0                                                  []   \n",
       "1                                              [2905]   \n",
       "2                                        [2905, 2874]   \n",
       "3                                  [2905, 2874, 2798]   \n",
       "4                            [2905, 2874, 2798, 2985]   \n",
       "..                                                ...   \n",
       "95  [1796, 1054, 175, 2881, 2152, 2411, 1037, 913,...   \n",
       "96  [1054, 175, 2881, 2152, 2411, 1037, 913, 1238,...   \n",
       "97  [175, 2881, 2152, 2411, 1037, 913, 1238, 1227,...   \n",
       "98  [2881, 2152, 2411, 1037, 913, 1238, 1227, 895,...   \n",
       "99  [2152, 2411, 1037, 913, 1238, 1227, 895, 221, ...   \n",
       "\n",
       "                                         prev_ratings  \n",
       "0                                                  []  \n",
       "1                                [0.3043722566393317]  \n",
       "2           [0.3043722566393317, -1.6463772063672941]  \n",
       "3   [0.3043722566393317, -1.6463772063672941, 0.30...  \n",
       "4   [0.3043722566393317, -1.6463772063672941, 0.30...  \n",
       "..                                                ...  \n",
       "95  [0.3043722566393317, -1.6463772063672941, 0.30...  \n",
       "96  [-1.6463772063672941, 0.3043722566393317, 0.95...  \n",
       "97  [0.3043722566393317, 0.9546220776415403, -1.64...  \n",
       "98  [0.9546220776415403, -1.6463772063672941, -0.3...  \n",
       "99  [-1.6463772063672941, -0.3458775643628769, -0....  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "num_parts = 32\n",
    "df_train[\"partition\"] = [random.randint(1, num_parts) for _ in range(len(df_train))]\n",
    "df_val[\"partition\"] = [random.randint(1, num_parts) for _ in range(len(df_val))]\n",
    "df_test[\"partition\"] = [random.randint(1, num_parts) for _ in range(len(df_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>normalized_rating</th>\n",
       "      <th>prev_movie_ids</th>\n",
       "      <th>prev_ratings</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2906</td>\n",
       "      <td>4.0</td>\n",
       "      <td>943226846</td>\n",
       "      <td>[466, 547]</td>\n",
       "      <td>[6, 9, 10]</td>\n",
       "      <td>118</td>\n",
       "      <td>0.304372</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>943226846</td>\n",
       "      <td>[0, 842]</td>\n",
       "      <td>[3, 9]</td>\n",
       "      <td>118</td>\n",
       "      <td>-1.646377</td>\n",
       "      <td>[2906]</td>\n",
       "      <td>[0.3043722566393317]</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2799</td>\n",
       "      <td>4.0</td>\n",
       "      <td>943226916</td>\n",
       "      <td>[879, 494]</td>\n",
       "      <td>[2, 3, 6, 9, 19]</td>\n",
       "      <td>118</td>\n",
       "      <td>0.304372</td>\n",
       "      <td>[2906, 2875]</td>\n",
       "      <td>[0.3043722566393317, -1.6463772063672941]</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2986</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943226986</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>118</td>\n",
       "      <td>-0.996127</td>\n",
       "      <td>[2906, 2875, 2799]</td>\n",
       "      <td>[0.3043722566393317, -1.6463772063672941, 0.30...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2791</td>\n",
       "      <td>1.0</td>\n",
       "      <td>943227458</td>\n",
       "      <td>[0, 523]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>118</td>\n",
       "      <td>-1.646377</td>\n",
       "      <td>[2906, 2875, 2799, 2986]</td>\n",
       "      <td>[0.3043722566393317, -1.6463772063672941, 0.30...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>818</td>\n",
       "      <td>3.0</td>\n",
       "      <td>944248888</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>115</td>\n",
       "      <td>-0.345878</td>\n",
       "      <td>[1797, 1054, 175, 2882, 2153, 2412, 1037, 913,...</td>\n",
       "      <td>[0.3043722566393317, -1.6463772063672941, 0.30...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>601</td>\n",
       "      <td>2.0</td>\n",
       "      <td>944248943</td>\n",
       "      <td>[298]</td>\n",
       "      <td>[6, 7, 9, 18]</td>\n",
       "      <td>115</td>\n",
       "      <td>-0.996127</td>\n",
       "      <td>[1054, 175, 2882, 2153, 2412, 1037, 913, 1238,...</td>\n",
       "      <td>[-1.6463772063672941, 0.3043722566393317, 0.95...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>2178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944248943</td>\n",
       "      <td>[366, 564]</td>\n",
       "      <td>[7, 9, 18]</td>\n",
       "      <td>111</td>\n",
       "      <td>-1.646377</td>\n",
       "      <td>[175, 2882, 2153, 2412, 1037, 913, 1238, 1227,...</td>\n",
       "      <td>[0.3043722566393317, 0.9546220776415403, -1.64...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944248943</td>\n",
       "      <td>[965, 0, 0, 0]</td>\n",
       "      <td>[5, 9]</td>\n",
       "      <td>114</td>\n",
       "      <td>0.954622</td>\n",
       "      <td>[2882, 2153, 2412, 1037, 913, 1238, 1227, 895,...</td>\n",
       "      <td>[0.9546220776415403, -1.6463772063672941, -0.3...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>1145</td>\n",
       "      <td>3.0</td>\n",
       "      <td>944248943</td>\n",
       "      <td>[164, 648, 0, 164, 648]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>108</td>\n",
       "      <td>-0.345878</td>\n",
       "      <td>[2153, 2412, 1037, 913, 1238, 1227, 895, 221, ...</td>\n",
       "      <td>[-1.6463772063672941, -0.3458775643628769, -0....</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating  timestamp                    title  \\\n",
       "0        1     2906     4.0  943226846               [466, 547]   \n",
       "1        1     2875     1.0  943226846                 [0, 842]   \n",
       "2        1     2799     4.0  943226916               [879, 494]   \n",
       "3        1     2986     2.0  943226986                   [0, 0]   \n",
       "4        1     2791     1.0  943227458                 [0, 523]   \n",
       "..     ...      ...     ...        ...                      ...   \n",
       "95       1      818     3.0  944248888                      [0]   \n",
       "96       1      601     2.0  944248943                    [298]   \n",
       "97       1     2178     1.0  944248943               [366, 564]   \n",
       "98       1       80     5.0  944248943           [965, 0, 0, 0]   \n",
       "99       1     1145     3.0  944248943  [164, 648, 0, 164, 648]   \n",
       "\n",
       "              genres  movie_year  normalized_rating  \\\n",
       "0         [6, 9, 10]         118           0.304372   \n",
       "1             [3, 9]         118          -1.646377   \n",
       "2   [2, 3, 6, 9, 19]         118           0.304372   \n",
       "3                [9]         118          -0.996127   \n",
       "4                [9]         118          -1.646377   \n",
       "..               ...         ...                ...   \n",
       "95               [9]         115          -0.345878   \n",
       "96     [6, 7, 9, 18]         115          -0.996127   \n",
       "97        [7, 9, 18]         111          -1.646377   \n",
       "98            [5, 9]         114           0.954622   \n",
       "99               [9]         108          -0.345878   \n",
       "\n",
       "                                       prev_movie_ids  \\\n",
       "0                                                  []   \n",
       "1                                              [2906]   \n",
       "2                                        [2906, 2875]   \n",
       "3                                  [2906, 2875, 2799]   \n",
       "4                            [2906, 2875, 2799, 2986]   \n",
       "..                                                ...   \n",
       "95  [1797, 1054, 175, 2882, 2153, 2412, 1037, 913,...   \n",
       "96  [1054, 175, 2882, 2153, 2412, 1037, 913, 1238,...   \n",
       "97  [175, 2882, 2153, 2412, 1037, 913, 1238, 1227,...   \n",
       "98  [2882, 2153, 2412, 1037, 913, 1238, 1227, 895,...   \n",
       "99  [2153, 2412, 1037, 913, 1238, 1227, 895, 221, ...   \n",
       "\n",
       "                                         prev_ratings  partition  \n",
       "0                                                  []          1  \n",
       "1                                [0.3043722566393317]         24  \n",
       "2           [0.3043722566393317, -1.6463772063672941]         24  \n",
       "3   [0.3043722566393317, -1.6463772063672941, 0.30...         21  \n",
       "4   [0.3043722566393317, -1.6463772063672941, 0.30...         31  \n",
       "..                                                ...        ...  \n",
       "95  [0.3043722566393317, -1.6463772063672941, 0.30...         29  \n",
       "96  [-1.6463772063672941, 0.3043722566393317, 0.95...         15  \n",
       "97  [0.3043722566393317, 0.9546220776415403, -1.64...         11  \n",
       "98  [0.9546220776415403, -1.6463772063672941, -0.3...         11  \n",
       "99  [-1.6463772063672941, -0.3458775643628769, -0....         18  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"parquet_dataset_ml_32m/\"\n",
    "df_train.to_parquet(out_path + \"train/\", partition_cols=[\"partition\"])\n",
    "df_val.to_parquet(out_path + \"validation/\", partition_cols=[\"partition\"])\n",
    "df_test.to_parquet(out_path + \"test/\", partition_cols=[\"partition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(vocabulary, f\"parquet_dataset_ml_32m/vocabulary.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: gsutil: command not found\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -R parquet_dataset_ml_32m gs://r6-ae-dev-adperf-adintelligence-data/amondal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amondal/recsys/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import uuid\n",
    "import joblib\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(\"Device:\", device)\n",
    "\n",
    "def checkpoint(model:nn.Module, optimizer:torch.optim.Optimizer, filename):\n",
    "    torch.save({'optimizer':optimizer.state_dict(), 'model':model.state_dict()}, filename)\n",
    "\n",
    "    \n",
    "def load_model(filename):\n",
    "    chkpt = torch.load(filename, weights_only=False)\n",
    "    return chkpt['model'], chkpt['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
